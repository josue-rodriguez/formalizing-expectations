
@article{aartssolution2014,
  title = {A Solution to Dependency: Using Multilevel Analysis to Accommodate Nested Data},
  shorttitle = {A Solution to Dependency},
  author = {Aarts, Emmeke and Verhage, Matthijs and Veenvliet, Jesse V and Dolan, Conor V and {van der Sluis}, Sophie},
  year = {2014},
  volume = {17},
  pages = {491--496},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.3648},
  abstract = {In neuroscience, experimental designs in which multiple observations are collected from a single research object (for example, multiple neurons from one animal) are common: 53\% of 314 reviewed papers from five renowned journals included this type of data. These so-called 'nested designs' yield data that cannot be considered to be independent, and so violate the independency assumption of conventional statistical methods such as the t test. Ignoring this dependency results in a probability of incorrectly concluding that an e ect is statistically significant that is far higher (up to 80\%) than the nominal a level (usually set at 5\%). We discuss the factors a ecting the type I error rate and the statistical power in nested data, methods that accommodate dependency between observations and ways to determine the optimal study design when data are nested. Notably, optimization of experimental designs nearly always concerns collection of more truly independent observations, rather than more observations from one research object.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AZJ5MU4T\\Aarts et al. - 2014 - A solution to dependency using multilevel analysi.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {4}
}

@article{adjeridBig2018,
  title = {Big Data in Psychology: {{A}} Framework for Research Advancement.},
  shorttitle = {Big Data in Psychology},
  author = {Adjerid, Idris and Kelley, Ken},
  year = {2018},
  volume = {73},
  pages = {899--917},
  issn = {1935-990X, 0003-066X},
  doi = {10.1037/amp0000190},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AQ3S88S4\\Adjerid and Kelley - 2018 - Big data in psychology A framework for research a.pdf},
  journal = {American Psychologist},
  language = {en},
  number = {7}
}

@article{afzalinetwork2017,
  title = {A Network Approach to the Comorbidity between Posttraumatic Stress Disorder and Major Depressive Disorder: {{The}} Role of Overlapping Symptoms},
  shorttitle = {A Network Approach to the Comorbidity between Posttraumatic Stress Disorder and Major Depressive Disorder},
  author = {Afzali, Mohammad H. and Sunderland, Matthew and Teesson, Maree and Carragher, Natacha and Mills, Katherine and Slade, Tim},
  year = {2017},
  volume = {208},
  pages = {490--496},
  issn = {0165-0327},
  doi = {10.1016/j.jad.2016.10.037},
  abstract = {Background
The role of symptom overlap between major depressive disorder and posttraumatic stress disorder in comorbidity between two disorders is unclear. The current study applied network analysis to map the structure of symptom associations between these disorders.
Methods
Data comes from a sample of 909 Australian adults with a lifetime history of trauma and depressive symptoms. Data analysis consisted of the construction of two comorbidity networks of PTSD/MDD with and without overlapping symptoms, identification of the bridging symptoms, and computation of the centrality measures.
Results
The prominent bridging role of four overlapping symptoms (i.e., sleep problems, irritability, concentration problems, and loss of interest) and five non-overlapping symptoms (i.e., feeling sad, feelings of guilt, psychomotor retardation, foreshortened future, and experiencing flashbacks) is highlighted.
Limitations
The current study uses DSM-IV criteria for PTSD and does not take into consideration significant changes made to PTSD criteria in DSM-5. Moreover, due to cross-sectional nature of the data, network estimates do not provide information on whether a symptom actively triggers other symptoms or whether a symptom mostly is triggered by other symptoms.
Conclusion
The results support the role of dysphoria-related symptoms in PTSD/MDD comorbidity. Moreover, Identification of central symptoms and bridge symptoms will provide useful targets for interventions that seek to intervene early in the development of comorbidity.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RPWAGNPW\\S0165032716309673.html},
  journal = {Journal of Affective Disorders},
  keywords = {Comorbidity,Depression,Network analysis,Posttraumatic stress disorder},
  language = {en}
}

@article{altayInferring2010,
  title = {Inferring the Conservative Causal Core of Gene Regulatory Networks},
  author = {Altay, G{\"o}kmen and {Emmert-Streib}, Frank},
  year = {2010},
  volume = {4},
  pages = {132},
  issn = {1752-0509},
  doi = {10.1186/1752-0509-4-132},
  abstract = {Inferring gene regulatory networks from large-scale expression data is an important problem that received much attention in recent years. These networks have the potential to gain insights into causal molecular interactions of biological processes. Hence, from a methodological point of view, reliable estimation methods based on observational data are needed to approach this problem practically.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\B9VNI4K3\\Altay and Emmert-Streib - 2010 - Inferring the conservative causal core of gene reg.pdf},
  journal = {BMC Systems Biology},
  language = {en},
  number = {1}
}

@book{americanpsychiatricassociationDiagnostic1994,
  title = {Diagnostic and Statistical Manual of Mental Disorders},
  author = {American Psychiatric Association},
  year = {1994},
  edition = {Fourth},
  publisher = {{Washington DC}}
}

@misc{Analyzing,
  title = {Analyzing Ordinal Data with Metric Models\_ {{What}} Could Possibly Go Wrong? | {{Elsevier Enhanced Reader}}},
  shorttitle = {Analyzing Ordinal Data with Metric Models\_ {{What}} Could Possibly Go Wrong?},
  doi = {10.1016/j.jesp.2018.08.009},
  file = {C\:\\Users\\josue\\Zotero\\storage\\D8QKE8HU\\Analyzing ordinal data with metric models_ What co.pdf;C\:\\Users\\josue\\Zotero\\storage\\DMUCYME4\\S0022103117307746.html},
  language = {en}
}

@techreport{andersonSplitSample2017,
  title = {Split-{{Sample Strategies}} for {{Avoiding False Discoveries}}},
  author = {Anderson, Michael and Magruder, Jeremy},
  year = {2017},
  pages = {w23544},
  address = {{Cambridge, MA}},
  institution = {{National Bureau of Economic Research}},
  doi = {10.3386/w23544},
  abstract = {Preanalysis plans (PAPs) have become an important tool for limiting false discoveries in field experiments. We evaluate the properties of an alternate approach which splits the data into two samples: An exploratory sample and a confirmation sample. When hypotheses are homogeneous, we describe an improved split-sample approach that achieves 90\% of the rejections of the optimal PAP without requiring preregistration or constraints on specification search in the exploratory sample. When hypotheses are heterogeneous in priors or intrinsic interest, we find that a hybrid approach which prespecifies hypotheses with high weights and priors and uses a split-sample approach to test additional hypotheses can have power gains over any pure PAP. We assess this approach using the community-driven development (CDD) application from Casey et al. (2012) and find that the use of a hybrid split-sample approach would have generated qualitatively different conclusions.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\A4E2NWN4\\Anderson and Magruder - 2017 - Split-Sample Strategies for Avoiding False Discove.pdf},
  language = {en},
  number = {w23544}
}

@article{andrewsPrior2013,
  title = {Prior Approval: {{The}} Growth of {{Bayesian}} Methods in Psychology},
  shorttitle = {Prior Approval},
  author = {Andrews, Mark and Baguley, Thom},
  year = {2013},
  volume = {66},
  pages = {1--7},
  issn = {2044-8317},
  doi = {10.1111/bmsp.12004},
  copyright = {\textcopyright{} 2013 The British Psychological Society},
  file = {C\:\\Users\\josue\\Zotero\\storage\\P63UZY54\\bmsp.html},
  journal = {British Journal of Mathematical and Statistical Psychology},
  language = {en},
  number = {1}
}

@article{armournetwork2017,
  title = {A Network Analysis of {{DSM}}-5 Posttraumatic Stress Disorder Symptoms and Correlates in {{U}}.{{S}}. Military Veterans},
  author = {Armour, Cherie and Fried, Eiko I. and Deserno, Marie K. and Tsai, Jack and Pietrzak, Robert H.},
  year = {2017},
  volume = {45},
  pages = {49--59},
  issn = {08876185},
  doi = {10.1016/j.janxdis.2016.11.008},
  abstract = {Objective: Recent developments in psychometrics enable the application of network models to analyze psychological disorders, such as PTSD. Instead of understanding symptoms as indicators of an underlying common cause, this approach suggests symptoms co-occur in syndromes due to causal interactions. The current study has two goals: (1) examine the network structure among the 20 DSM-5 PTSD symptoms, and (2) incorporate clinically relevant variables to the network to investigate whether PTSD symptoms exhibit differential relationships with suicidal ideation, depression, anxiety, physical functioning/quality of life (QoL), mental functioning/QoL, age, and sex.
Method: We utilized a nationally representative U.S. military veteran's sample; and analyzed the data from a subsample of 221 veterans who reported clinically significant DSM-5 PTSD symptoms. Networks were estimated using state-of-the-art regularized partial correlation models. Data and code are published along with the paper.
Results: The 20-item DSM-5 PTSD network revealed that symptoms were positively connected within the network. Especially strong connections emerged between nightmares and flashbacks; blame of self or others and negative trauma-related emotions, detachment and restricted affect; and hypervigilance and exaggerated startle response. The most central symptoms were negative trauma-related emotions, flashbacks, detachment, and physiological cue reactivity. Incorporation of clinically relevant covariates into the network revealed paths between self-destructive behavior and suicidal ideation; concentration difficulties and anxiety, depression, and mental QoL; and depression and restricted affect.
Conclusion: These results demonstrate the utility of a network approach in modeling the structure of DSM-5 PTSD symptoms, and suggest differential associations between specific DSM-5 PTSD symptoms and clinical outcomes in trauma survivors. Implications of these results for informing the assessment and treatment of this disorder, are discussed.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RWAZ2WRX\\Armour et al. - 2017 - A network analysis of DSM-5 posttraumatic stress d.pdf},
  journal = {Journal of Anxiety Disorders},
  language = {en}
}

@article{arnockyAltruism2017,
  title = {Altruism Predicts Mating Success in Humans},
  author = {Arnocky, Steven and Pich{\'e}, Tina and Albert, Graham and Ouellette, Danielle and Barclay, Pat},
  year = {2017},
  volume = {108},
  pages = {416--435},
  issn = {2044-8295},
  doi = {10.1111/bjop.12208},
  abstract = {In order for non-kin altruism to evolve, altruists must receive fitness benefits for their actions that outweigh the costs. Several researchers have suggested that altruism is a costly signal of desirable qualities, such that it could have evolved by sexual selection. In two studies, we show that altruism is broadly linked with mating success. In Study 1, participants who scored higher on a self-report altruism measure reported they were more desirable to the opposite sex, as well as reported having more sex partners, more casual sex partners, and having sex more often within relationships. Sex moderated some of these relationships, such that altruism mattered more for men's number of lifetime and casual sex partners. In Study 2, participants who were willing to donate potential monetary winnings (in a modified dictator dilemma) reported having more lifetime sex partners, more casual sex partners, and more sex partners over the past year. Men who were willing to donate also reported having more lifetime dating partners. Furthermore, these patterns persisted, even when controlling for narcissism, Big Five personality traits, and socially desirable responding. These results suggest that altruists have higher mating success than non-altruists and support the hypothesis that altruism is a sexually selected costly signal of difficult-to-observe qualities.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\MJQ3IWJH\\Arnocky et al. - 2017 - Altruism predicts mating success in humans.pdf;C\:\\Users\\josue\\Zotero\\storage\\KZGADPDD\\bjop.html},
  journal = {British Journal of Psychology},
  keywords = {casual sex partners,competitive altruism,costly signalling,evolution,mate value,mating success},
  language = {en},
  number = {2}
}

@article{assinkFitting2016,
  title = {Fitting Three-Level Meta-Analytic Models in {{R}}: {{A}} Step-by-Step Tutorial},
  shorttitle = {Fitting Three-Level Meta-Analytic Models in {{R}}},
  author = {Assink, Mark and Wibbelink, Carlijn J. M.},
  year = {2016},
  volume = {12},
  pages = {154--174},
  issn = {2292-1354},
  doi = {10.20982/tqmp.12.3.p154},
  abstract = {Applying a multilevel approach to meta-analysis is a strong method for dealing with dependency of effect sizes. However, this method is relatively unknown among researchers and, to date, has not been widely used in meta-analytic research. Therefore, the purpose of this tutorial was to show how a three-level random effects model can be applied to meta-analytic models in R using the rma.mv function of the metafor package. This application is illustrated by taking the reader through a step-by-step guide to the multilevel analyses comprising the steps of (1) organizing a data file; (2) setting up the R environment; (3) calculating an overall effect; (4) examining heterogeneity of within-study variance and between-study variance; (5) performing categorical and continuous moderator analyses; and (6) examining a multiple moderator model. By example, the authors demonstrate how the multilevel approach can be applied to meta-analytically examining the association between mental health disorders of juveniles and juvenile offender recidivism. In our opinion, the rma.mv function of the metafor package provides an easy and flexible way of applying a multi-level structure to meta-analytic models in R. Further, the multilevel meta-analytic models can be easily extended so that the potential moderating influence of variables can be examined.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\M6TIQTE2\\Assink and Wibbelink - 2016 - Fitting three-level meta-analytic models in R A s.pdf},
  journal = {The Quantitative Methods for Psychology},
  language = {en},
  number = {3}
}

@techreport{aubryDevelopment2018,
  title = {Development of Attentional Networks in Intellectually Gifted Children},
  author = {Aubry, Alexandre and Bourdin, B{\'e}atrice},
  year = {2018},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/fvcwz},
  abstract = {Intellectually gifted children have high performance in many domains of the attention than intellectually average children. However, few studies investigated the development of the alerting, orienting and executive control networks, in intellectually gifted children. The aim of our study is investigated the development of three attentional networks in intellectually gifted children.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\BCDLEB9M\\Aubry and Bourdin - 2018 - Development of attentional networks in intellectua.pdf},
  language = {en},
  type = {Preprint}
}

@article{baayenMixedeffects2008,
  title = {Mixed-Effects Modeling with Crossed Random Effects for Subjects and Items},
  author = {Baayen, R. H. and Davidson, D. J. and Bates, D. M.},
  year = {2008},
  volume = {59},
  pages = {390--412},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2007.12.005},
  abstract = {This paper provides an introduction to mixed-effects models for the analysis of repeated measurement data with subjects and items as crossed random effects. A worked-out example of how to use recent software for mixed-effects modeling is provided. Simulation studies illustrate the advantages offered by mixed-effects analyses compared to traditional analyses based on quasi-F tests, by-subjects analyses, combined by-subjects and by-items analyses, and random regression. Applications and possibilities across a range of domains of inquiry are discussed.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\LX4VEKZ9\\Baayen et al. - 2008 - Mixed-effects modeling with crossed random effects.pdf;C\:\\Users\\josue\\Zotero\\storage\\HV54DSLT\\S0749596X07001398.html},
  journal = {Journal of Memory and Language},
  keywords = {By-item,By-subject,Crossed random effects,Mixed-effects models,Quasi-F},
  number = {4},
  series = {Special {{Issue}}: {{Emerging Data Analysis}}}
}

@article{baayenSubjects2002,
  title = {The {{Subjects}} as a {{Simple Random Effect Fallacy}}: {{Subject Variability}} and {{Morphological Family Effects}} in the {{Mental Lexicon}}},
  shorttitle = {The {{Subjects}} as a {{Simple Random Effect Fallacy}}},
  author = {Baayen, R. H. and Tweedie, Fiona J. and Schreuder, Robert},
  year = {2002},
  volume = {81},
  pages = {55--65},
  issn = {0093934X},
  doi = {10.1006/brln.2001.2506},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RZTZNDS3\\Baayen et al. - 2002 - The Subjects as a Simple Random Effect Fallacy Su.pdf},
  journal = {Brain and Language},
  language = {en},
  number = {1-3}
}

@article{banichExecutive2009,
  title = {Executive {{Function}}: {{The Search}} for an {{Integrated Account}}},
  shorttitle = {Executive {{Function}}},
  author = {Banich, Marie T.},
  year = {2009},
  volume = {18},
  pages = {89--94},
  issn = {0963-7214},
  doi = {10.1111/j.1467-8721.2009.01615.x},
  abstract = {In general, executive function can be thought of as the set of abilities required to effortfully guide behavior toward a goal, especially in nonroutine situations. Psychologists are interested in expanding the understanding of executive function because it is thought to be a key process in intelligent behavior, it is compromised in a variety of psychiatric and neurological disorders, it varies across the life span, and it affects performance in complicated environments, such as the cockpits of advanced aircraft. This article provides a brief introduction to the concept of executive function and discusses how it is assessed and the conditions under which it is compromised. A short overview of the diverse theoretical viewpoints regarding its psychological and biological underpinnings is also provided. The article concludes with a consideration of how a multilevel approach may provide a more integrated account of executive function than has been previously available.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\PXXBRR2Z\\Banich - 2009 - Executive Function The Search for an Integrated A.pdf},
  journal = {Current Directions in Psychological Science},
  language = {en},
  number = {2}
}

@book{barlowBarlow1972,
  title = {Barlow, {{R}}. {{E}}., {{Bartholomew}}, {{D}}. {{J}}., {{Bremner}}, {{J}}. {{M}}., \& {{Brunk}}, {{H}}. {{D}}. (1972). {{Statistical}} Inference under Order Restrictions: {{The}} Theory and Application of Isotonic Regression ({{No}}. 04; {{QA278}}. 7, {{B3}}.). {{New York}}: {{Wiley}}.},
  author = {Barlow, R. E. and Bartholomew, D. J. and Bremner,, J. M. and Brunk, H. D.},
  year = {1972},
  publisher = {{Wiley}},
  address = {{New York}}
}

@article{barnardComment1974,
  title = {Comment on {{Cross}}-{{Validatory Choice}} and {{Assessment}} of {{Statistical Predictions}}},
  author = {Barnard, George A.},
  year = {1974},
  volume = {36},
  pages = {111--147},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  abstract = {A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  number = {2}
}

@article{barnardMODELING2000,
  title = {{{MODELING COVARIANCE MATRICES IN TERMS OF STANDARD DEVIATIONS AND CORRELATIONS}}, {{WITH APPLICATION TO SHRINKAGE}}},
  author = {Barnard, John and McCulloch, Robert and Meng, Xiao-Li},
  year = {2000},
  volume = {10},
  pages = {1281--1311},
  issn = {1017-0405},
  abstract = {The covariance matrix plays an important role in statistical inference, yet modeling a covariance matrix is often a difficult task in practice due to its dimensionality and the non-negative definite constraint. In order to model a covariance matrix effectively, it is typically broken down into components based on modeling considerations or mathematical convenience. Decompositions that have received recent research attention include variance components, spectral decomposition, Cholesky decomposition, and matrix logarithm. In this paper we study a statistically motivated decomposition which appears to be relatively unexplored for the purpose of modeling. We model a covariance matrix in terms of its corresponding standard deviations and correlation matrix. We discuss two general modeling situations where this approach is useful: shrinkage estimation of regression coefficients, and a general location-scale model for both categorical and continuous variables. We present some simple choices for priors in terms of standard deviations and the correlation matrix, and describe a straightforward computational strategy for obtaining the posterior of the covariance matrix. We apply our method to real and simulated data sets in the context of shrinkage estimation.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KCQ2RUFB\\Barnard et al. - 2000 - MODELING COVARIANCE MATRICES IN TERMS OF STANDARD .pdf},
  journal = {Statistica Sinica},
  number = {4}
}

@article{barrRandom2013,
  title = {Random Effects Structure for Confirmatory Hypothesis Testing: {{Keep}} It Maximal},
  shorttitle = {Random Effects Structure for Confirmatory Hypothesis Testing},
  author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
  year = {2013},
  volume = {68},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2012.11.001},
  abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the `gold standard' for confirmatory hypothesis testing in psycholinguistics and beyond.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RRV6HBHS\\Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf},
  journal = {Journal of memory and language},
  number = {3},
  pmcid = {PMC3881361},
  pmid = {24403724}
}

@article{bauerEvaluating2011,
  title = {Evaluating {{Individual Differences}} in {{Psychological Processes}}},
  author = {Bauer, Daniel J.},
  year = {2011},
  volume = {20},
  pages = {115--118},
  issn = {0963-7214, 1467-8721},
  doi = {10.1177/0963721411402670},
  abstract = {Better understanding individual differences in social, cognitive, and behavioral processes is a core goal of much psychological theory and research. Although great progress has been made toward this goal, I argue here that the classical design and analysis approach that dominates individual difference research, namely, the collection of single-time-point data and application of standard linear regression models, potentially limits further advances. In particular, the opportunity to evaluate individual differences in psychological processes is restricted by the estimation of a single effect to represent the relationship between variables. I discuss alternative analysis and design options that offer the opportunity to more fully examine individual differences in psychological processes.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\FU29SRHZ\\Bauer - 2011 - Evaluating Individual Differences in Psychological.pdf},
  journal = {Current Directions in Psychological Science},
  language = {en},
  number = {2}
}

@article{beardNetwork2016,
  title = {Network Analysis of Depression and Anxiety Symptom Relationships in a Psychiatric Sample},
  author = {Beard, C. and Millner, A. J. and Forgeard, M. J. C. and Fried, E. I. and Hsu, K. J. and Treadway, M. T. and Leonard, C. V. and Kertz, S. J. and Bj{\"o}rgvinsson, T.},
  year = {2016},
  volume = {46},
  pages = {3359--3369},
  issn = {0033-2917, 1469-8978},
  doi = {10.1017/S0033291716002300},
  abstract = {Background
              Researchers have studied psychological disorders extensively from a common cause perspective, in which symptoms are treated as independent indicators of an underlying disease. In contrast, the causal systems perspective seeks to understand the importance of individual symptoms and symptom-to-symptom relationships. In the current study, we used network analysis to examine the relationships between and among depression and anxiety symptoms from the causal systems perspective.
            
            
              Method
              
                We utilized data from a large psychiatric sample at admission and discharge from a partial hospital program (
                N
                = 1029, mean treatment duration = 8 days). We investigated features of the depression/anxiety network including topology, network centrality, stability of the network at admission and discharge, as well as change in the network over the course of treatment.
              
            
            
              Results
              Individual symptoms of depression and anxiety were more related to other symptoms within each disorder than to symptoms between disorders. Sad mood and worry were among the most central symptoms in the network. The network structure was stable both at admission and between admission and discharge, although the overall strength of symptom relationships increased as symptom severity decreased over the course of treatment.
            
            
              Conclusions
              Examining depression and anxiety symptoms as dynamic systems may provide novel insights into the maintenance of these mental health problems.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\NJ5RJSRM\\Beard et al. - 2016 - Network analysis of depression and anxiety symptom.pdf},
  journal = {Psychological Medicine},
  language = {en},
  number = {16}
}

@article{belandshort2012,
  title = {A Short Introduction into {{Bayesian}} Evaluation of Informative Hypotheses as an Alternative to Exploratory Comparisons of Multiple Group Means},
  author = {B{\'e}land, S{\'e}bastien and Klugkist, Irene and Ra{\^i}che, Gilles and Magis, David},
  year = {2012},
  volume = {8},
  pages = {122--126},
  issn = {1913-4126},
  doi = {10.20982/tqmp.08.2.p122},
  file = {C\:\\Users\\josue\\Zotero\\storage\\YUHJRGUQ\\Béland et al. - 2012 - A short introduction into Bayesian evaluation of i.pdf},
  journal = {Tutorials in Quantitative Methods for Psychology},
  language = {en},
  number = {2}
}

@incollection{bemWriting2004,
  title = {Writing the Empirical Journal Article},
  booktitle = {The Compleat Academic: {{A}} Career Guide, 2nd Ed},
  author = {Bem, Daryl J.},
  year = {2004},
  pages = {185--219},
  publisher = {{American Psychological Association}},
  address = {{Washington, DC, US}},
  abstract = {The purpose of this chapter is to enhance the chances that academic psychologists get their empirical articles published. Because I write, review, and edit primarily for journals in personality and social psychology, I have drawn most of my examples from those areas. Colleagues assure me, however, that the guidelines set forth are also pertinent for articles in experimental psychology and biopsychology. Similarly, this chapter focuses on an empirical study, but the general writing suggestions apply as well to the theoretical articles, literature reviews, and methodological contributions that also appear in psychology journals. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C\:\\Users\\josue\\Zotero\\storage\\5ZEC9MQC\\2003-06256-010.html},
  isbn = {978-1-59147-035-9},
  keywords = {Experimental Psychology,Scientific Communication,Written Communication}
}

@article{bentlerMultivariate1980,
  title = {Multivariate {{Analysis}} with {{Latent Variables}}: {{Causal Modeling}}},
  shorttitle = {Multivariate {{Analysis}} with {{Latent Variables}}},
  author = {Bentler, P M},
  year = {1980},
  volume = {31},
  pages = {419--456},
  doi = {10.1146/annurev.ps.31.020180.002223},
  file = {C\:\\Users\\josue\\Zotero\\storage\\FE8NM4BH\\Bentler - 1980 - Multivariate Analysis with Latent Variables Causa.pdf},
  journal = {Annual Review of Psychology},
  note = {\_eprint: https://doi.org/10.1146/annurev.ps.31.020180.002223},
  number = {1}
}

@article{bergeBridging2017,
  title = {Bridging Centrality as an Indicator to Measure the `Bridging Role' of Actors in Networks: {{An}} Application to the {{European Nanotechnology}} Co-Publication Network},
  shorttitle = {Bridging Centrality as an Indicator to Measure the `Bridging Role' of Actors in Networks},
  author = {Berg{\'e}, Laurent and Scherngell, Thomas and Wanzenb{\"o}ck, Iris},
  year = {2017},
  volume = {11},
  pages = {1031--1042},
  issn = {17511577},
  doi = {10.1016/j.joi.2017.09.004},
  journal = {Journal of Informetrics},
  language = {en},
  number = {4}
}

@article{bergerIntrinsic1996,
  title = {The {{Intrinsic Bayes Factor}} for {{Model Selection}} and {{Prediction}}},
  author = {Berger, James O. and Pericchi, Luis R.},
  year = {1996},
  volume = {91},
  pages = {109--122},
  issn = {0162-1459},
  doi = {10.1080/01621459.1996.10476668},
  abstract = {In the Bayesian approach to model selection or hypothesis testing with models or hypotheses of differing dimensions, it is typically not possible to utilize standard noninformative (or default) prior distributions. This has led Bayesians to use conventional proper prior distributions or crude approximations to Bayes factors. In this article we introduce a new criterion called the intrinsic Bayes factor, which is fully automatic in the sense of requiring only standard noninformative priors for its computation and yet seems to correspond to very reasonable actual Bayes factors. The criterion can be used for nested or nonnested models and for multiple model comparison and prediction. From another perspective, the development suggests a general definition of a ``reference prior'' for model comparison.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\M8EX89BZ\\Berger and Pericchi - 1996 - The Intrinsic Bayes Factor for Model Selection and.pdf;C\:\\Users\\josue\\Zotero\\storage\\2HDIR4BK\\01621459.1996.html},
  journal = {Journal of the American Statistical Association},
  keywords = {Asymptotic Bayes factors,Hypothesis testing,Noninformative prior,Posterior probability,Training sample},
  number = {433}
}

@article{bernardoNonCentered,
  title = {Non-{{Centered Parameterisations}} for {{Hierarchical Models}} and {{Data Augmentation}}},
  author = {Bernardo, J. M. and Bayarri, M. J. and Berger, J. O. and Dawid, A. P. and Heckerman, D. and Smith, A. F. M. and West (eds, M. and Papaspiliopoulos, Omiros and Roberts, Gareth O. and Sk \textasciidieresis{}old, Martin},
  abstract = {In this paper, we will compare centered and non-centered parameterisations for classes of hierar-chical models. Our examples will include variance component models, random effect models, hidden Markov process models, and partially observed diffusion models. We will investigate the construction of non-centered methods by the use of state space expansion techniques, and will introduce methods for devising partially non-centered parameterisations, many of which are data-dependent.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IQ3BGG9E\\Bernardo et al. - Summary.pdf;C\:\\Users\\josue\\Zotero\\storage\\D9K4SWGX\\summary.html}
}

@article{boccalettiComplex2006,
  title = {Complex Networks: {{Structure}} and Dynamics},
  shorttitle = {Complex Networks},
  author = {Boccaletti, S. and Latora, V. and Moreno, Y. and Chavez, M. and Hwang, D. -U.},
  year = {2006},
  volume = {424},
  pages = {175--308},
  issn = {0370-1573},
  doi = {10.1016/j.physrep.2005.10.009},
  abstract = {Coupled biological and chemical systems, neural networks, social interacting species, the Internet and the World Wide Web, are only a few examples of systems composed by a large number of highly interconnected dynamical units. The first approach to capture the global properties of such systems is to model them as graphs whose nodes represent the dynamical units, and whose links stand for the interactions between them. On the one hand, scientists have to cope with structural issues, such as characterizing the topology of a complex wiring architecture, revealing the unifying principles that are at the basis of real networks, and developing models to mimic the growth of a network and reproduce its structural properties. On the other hand, many relevant questions arise when studying complex networks' dynamics, such as learning how a large ensemble of dynamical systems that interact through a complex wiring topology can behave collectively. We review the major concepts and results recently achieved in the study of the structure and dynamics of complex networks, and summarize the relevant applications of these ideas in many different disciplines, ranging from nonlinear science to biology, from statistical mechanics to medicine and engineering.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\3TFTLX9E\\S037015730500462X.html},
  journal = {Physics Reports},
  language = {en},
  number = {4}
}

@article{boing-messingBayes2020,
  title = {Bayes {{Factors}} for {{Testing Order Constraints}} on {{Variances}} of {{Dependent Outcomes}}},
  author = {{B{\"o}ing-Messing}, Florian and Mulder, Joris},
  year = {2020},
  pages = {1--10},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2020.1715257},
  abstract = {In statistical practice, researchers commonly focus on patterns in the means of multiple dependent outcomes while treating variances as nuisance parameters. However, in fact, there are often substantive reasons to expect certain patterns in the variances of dependent outcomes as well. For example, in a repeated measures study, one may expect the variance of the outcome to increase over time if the difference between subjects becomes more pronounced over time because the subjects respond differently to a given treatment. Such expectations can be formulated as order constrained hypotheses on the variances of the dependent outcomes. Currently, however, no methods exist for testing such hypotheses in a direct manner. To fill this gap, we develop a Bayes factor for this challenging testing problem. Our Bayes factor is based on the multivariate normal distribution with an unstructured covariance matrix, which is often used to model dependent outcomes. Order constrained hypotheses can then be formulated on the variances on the diagonal of the covariance matrix. To compute Bayes factors between multiple order constrained hypotheses, a prior distribution needs to be specified under every hypothesis to be tested. Here, we use the encompassing prior approach in which priors under order constrained hypotheses are truncations of the prior under the unconstrained hypothesis. The resulting Bayes factor is fully automatic in the sense that no subjective priors need to be specified by the user.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\V4BQBKPQ\\Böing-Messing and Mulder - 2020 - Bayes Factors for Testing Order Constraints on Var.pdf},
  journal = {The American Statistician},
  language = {en}
}

@article{boing-messingBayesian2017,
  title = {Bayesian Evaluation of Constrained Hypotheses on Variances of Multiple Independent Groups.},
  author = {{B{\"o}ing-Messing}, Florian and {van Assen}, Marcel A. L. M. and Hofman, Abe D. and Hoijtink, Herbert and Mulder, Joris},
  year = {2017},
  volume = {22},
  pages = {262--287},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000116},
  abstract = {Research has shown that independent groups often differ not only in their means, but also in their variances. Comparing and testing variances is therefore of crucial importance to understand the effect of a grouping variable on an outcome variable. Researchers may have specific expectations concerning the relations between the variances of multiple groups. Such expectations can be translated into hypotheses with inequality and/or equality constraints on the group variances. Currently, however, no methods are available for testing (in)equality constrained hypotheses on variances. This article proposes a novel Bayesian approach to this challenging testing problem. Our approach has the following useful properties: First, it can be used to simultaneously test multiple (non)nested hypotheses with equality as well as inequality constraints on the variances. Second, our approach is fully automatic in the sense that no subjective prior specification is needed. Only the hypotheses need to be provided. Third, a user-friendly software application is included that can be used to perform this Bayesian test in an easy manner.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\JIW3P6SL\\Böing-Messing et al. - 2017 - Bayesian evaluation of constrained hypotheses on v.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {2}
}

@article{boisgontieranova2016,
  title = {The Anova to Mixed Model Transition},
  author = {Boisgontier, Matthieu P. and Cheval, Boris},
  year = {2016},
  volume = {68},
  pages = {1004--1005},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2016.05.034},
  abstract = {A transition towards mixed models is underway in science. This transition started up because the requirements for using analyses of variances are often not met and mixed models clearly provide a better framework. Neuroscientists have been slower than others in changing their statistical habits and are now urged to act.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\NYFL6WRA\\Boisgontier and Cheval - 2016 - The anova to mixed model transition.pdf;C\:\\Users\\josue\\Zotero\\storage\\BIGMWV54\\S0149763416301634.html},
  journal = {Neuroscience \& Biobehavioral Reviews},
  keywords = {Analysis of variance,Linear mixed-effects models,Neuroscience,Statistics}
}

@article{bollenLatent2002,
  title = {Latent {{Variables}} in {{Psychology}} and the {{Social Sciences}}},
  author = {Bollen, Kenneth A.},
  year = {2002},
  volume = {53},
  pages = {605--634},
  doi = {10.1146/annurev.psych.53.100901.135239},
  abstract = {The paper discusses the use of latent variables in psychology and social science research. Local independence, expected value true scores, and nondeterministic functions of observed variables are three types of definitions for latent variables. These definitions are reviewed and an alternative ``sample realizations'' definition is presented. Another section briefly describes identification, latent variable indeterminancy, and other properties common to models with latent variables. The paper then reviews the role of latent variables in multiple regression, probit and logistic regression, factor analysis, latent curve models, item response theory, latent class analysis, and structural equation models. Though these application areas are diverse, the paper highlights the similarities as well as the differences in the manner in which the latent variables are defined and used. It concludes with an evaluation of the different definitions of latent variables and their properties.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\SKTDMCNF\\Bollen - 2002 - Latent Variables in Psychology and the Social Scie.pdf},
  journal = {Annual Review of Psychology},
  note = {\_eprint: https://doi.org/10.1146/annurev.psych.53.100901.135239},
  number = {1},
  pmid = {11752498}
}

@book{bonatePharmacokineticpharmacodynamic2011,
  title = {Pharmacokinetic-Pharmacodynamic Modeling and Simulation},
  author = {Bonate, Peter L.},
  year = {2011},
  edition = {2. ed},
  publisher = {{Springer}},
  address = {{New York}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ZTBXUG44\\Bonate - 2011 - Pharmacokinetic-pharmacodynamic modeling and simul.pdf},
  isbn = {978-1-4419-9484-4 978-1-4419-9485-1},
  language = {en},
  note = {OCLC: 748651873}
}

@article{borellainterference2013,
  title = {Beyond Interference Control Impairment in {{ADHD}}: {{Evidence}} from Increased Intraindividual Variability in the Color-Stroop Test},
  shorttitle = {Beyond Interference Control Impairment in {{ADHD}}},
  author = {Borella, Erika and de Ribaupierre, Anik and Cornoldi, Cesare and Chicherio, Christian},
  year = {2013},
  volume = {19},
  pages = {495--515},
  issn = {0929-7049},
  doi = {10.1080/09297049.2012.696603},
  abstract = {The present study investigates intraindividual variability (IIV) in the Color-Stroop test and in a simple reaction time (SRT) task. Performance level and variability in reaction times (RTs)\textemdash{}quantified with different measures such as individual standard deviation (ISD) and coefficient of variation (ICV), as well as ex-Gaussian parameters (mu, sigma, tau)\textemdash{}were analyzed in 24 children with attention deficit/hyperactivity disorder (ADHD) and 24 typically developing children (TDC). Children with ADHD and TDC presented equivalent Color-Stroop interference effects when mean RTs were considered, and the two groups did not differ in the SRT task. Interestingly, compared to TDC, children with ADHD were more variable in their responses, showing increased ISD and ICV in the Color-Stroop interference condition and in the SRT task. Moreover, children with ADHD exhibited higher tau values\textemdash{}that is, more frequent abnormally long RTs\textemdash{}in the Color-Stroop interference condition than did the TDC, but comparable tau values in the SRT, suggesting more variable responses. These results speak in favor of a general deficit in more basic and central processes that only secondarily may affect the efficiency of inhibitory processes in children with ADHD. Overall the present findings confirm the role of IIV as a cornerstone in the ADHD cognitive profile and support the search for fine-grained analysis of performance fluctuations.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\37ZAIP3N\\Borella et al. - 2013 - Beyond interference control impairment in ADHD Ev.pdf;C\:\\Users\\josue\\Zotero\\storage\\P2BTVJUQ\\09297049.2012.html},
  journal = {Child Neuropsychology},
  keywords = {ADHD,Color-Stroop test,Inhibition,Intraindividual variability,Response time distributions},
  number = {5},
  pmid = {22738031}
}

@article{borgattiCentrality2005,
  title = {Centrality and Network Flow},
  author = {Borgatti, Stephen P.},
  year = {2005},
  volume = {27},
  pages = {55--71},
  issn = {0378-8733},
  doi = {10.1016/j.socnet.2004.11.008},
  abstract = {Centrality measures, or at least popular interpretations of these measures, make implicit assumptions about the manner in which traffic flows through a network. For example, some measures count only geodesic paths, apparently assuming that whatever flows through the network only moves along the shortest possible paths. This paper lays out a typology of network flows based on two dimensions of variation, namely the kinds of trajectories that traffic may follow (geodesics, paths, trails, or walks) and the method of spread (broadcast, serial replication, or transfer). Measures of centrality are then matched to the kinds of flows that they are appropriate for. Simulations are used to examine the relationship between type of flow and the differential importance of nodes with respect to key measurements such as speed of reception of traffic and frequency of receiving traffic. It is shown that the off-the-shelf formulas for centrality measures are fully applicable only for the specific flow processes they are designed for, and that when they are applied to other flow processes they get the ``wrong'' answer. It is noted that the most commonly used centrality measures are not appropriate for most of the flows we are routinely interested in. A key claim made in this paper is that centrality measures can be regarded as generating expected values for certain kinds of node outcomes (such as speed and frequency of reception) given implicit models of how traffic flows, and that this provides a new and useful way of thinking about centrality.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ABGVRPHW\\Borgatti - 2005 - Centrality and network flow.pdf;C\:\\Users\\josue\\Zotero\\storage\\2U7YQQ5B\\S0378873304000693.html},
  journal = {Social Networks},
  keywords = {Centrality,Network flow,Typology},
  language = {en},
  number = {1}
}

@article{borgnote2018,
  title = {A Note on the Positive Manifold Hypothesis},
  author = {Borg, Ingwer},
  year = {2018},
  volume = {134},
  pages = {13--15},
  issn = {0191-8869},
  doi = {10.1016/j.paid.2018.05.041},
  abstract = {The positive manifold hypothesis is closely related to intelligence research and to factor analysis. It comes in different versions: (1) the inter-correlations of a set of test items are all positive and (2) the configuration of vectors representing these test items in common factor space can be rotated so that the loadings of all vectors are positive. We here show that positive intercorrelations are only a necessary but by far not a sufficient condition in case of more than two factors.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RQFUY6J6\\S0191886918302952.html},
  journal = {Personality and Individual Differences},
  keywords = {Factor analysis,Intelligence,Positive manifold},
  language = {en}
}

@article{borsboomConcept2004,
  title = {The {{Concept}} of {{Validity}}.},
  author = {Borsboom, Denny and Mellenbergh, Gideon J. and {van Heerden}, Jaap},
  year = {2004},
  volume = {111},
  pages = {1061--1071},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.111.4.1061},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VBXF4DZC\\Borsboom et al. - 2004 - The Concept of Validity..pdf},
  journal = {Psychological Review},
  language = {en},
  number = {4}
}

@article{borsboomNetwork2013,
  title = {Network {{Analysis}}: {{An Integrative Approach}} to the {{Structure}} of {{Psychopathology}}},
  shorttitle = {Network {{Analysis}}},
  author = {Borsboom, Denny and Cramer, Ang{\'e}lique O.J.},
  year = {2013},
  volume = {9},
  pages = {91--121},
  doi = {10.1146/annurev-clinpsy-050212-185608},
  abstract = {In network approaches to psychopathology, disorders result from the causal interplay between symptoms (e.g., worry \textrightarrow{} insomnia \textrightarrow{} fatigue), possibly involving feedback loops (e.g., a person may engage in substance abuse to forget the problems that arose due to substance abuse). The present review examines methodologies suited to identify such symptom networks and discusses network analysis techniques that may be used to extract clinically and scientifically useful information from such networks (e.g., which symptom is most central in a person's network). The authors also show how network analysis techniques may be used to construct simulation models that mimic symptom dynamics. Network approaches naturally explain the limited success of traditional research strategies, which are typically based on the idea that symptoms are manifestations of some common underlying factor, while offering promising methodological alternatives. In addition, these techniques may offer possibilities to guide and evaluate therapeutic interventions.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\QNLCHPZC\\Borsboom and Cramer - 2013 - Network Analysis An Integrative Approach to the S.pdf},
  journal = {Annual Review of Clinical Psychology},
  number = {1}
}

@article{borsboomnetwork2017,
  title = {A Network Theory of Mental Disorders},
  author = {Borsboom, Denny},
  year = {2017},
  volume = {16},
  pages = {5--13},
  issn = {2051-5545},
  doi = {10.1002/wps.20375},
  abstract = {In recent years, the network approach to psychopathology has been advanced as an alternative way of conceptualizing mental disorders. In this approach, mental disorders arise from direct interactions between symptoms. Although the network approach has led to many novel methodologies and substantive applications, it has not yet been fully articulated as a scientific theory of mental disorders. The present paper aims to develop such a theory, by postulating a limited set of theoretical principles regarding the structure and dynamics of symptom networks. At the heart of the theory lies the notion that symptoms of psychopathology are causally connected through myriads of biological, psychological and societal mechanisms. If these causal relations are sufficiently strong, symptoms can generate a level of feedback that renders them self-sustaining. In this case, the network can get stuck in a disorder state. The network theory holds that this is a general feature of mental disorders, which can therefore be understood as alternative stable states of strongly connected symptom networks. This idea naturally leads to a comprehensive model of psychopathology, encompassing a common explanatory model for mental disorders, as well as novel definitions of associated concepts such as mental health, resilience, vulnerability and liability. In addition, the network theory has direct implications for how to understand diagnosis and treatment, and suggests a clear agenda for future research in psychiatry and associated disciplines.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\TGLDFPAM\\Borsboom - 2017 - A network theory of mental disorders.pdf;C\:\\Users\\josue\\Zotero\\storage\\2XBIQWB5\\wps.html},
  journal = {World Psychiatry},
  keywords = {diagnosis,mental disorders,mental health,network approach,Psychopathology,resilience,symptom networks,treatment,vulnerability},
  language = {en},
  number = {1}
}

@article{borsboomSmall2011,
  title = {The {{Small World}} of {{Psychopathology}}},
  author = {Borsboom, Denny and Cramer, Ang{\'e}lique O. J. and Schmittmann, Verena D. and Epskamp, Sacha and Waldorp, Lourens J.},
  year = {2011},
  volume = {6},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0027407},
  abstract = {Background
Mental disorders are highly comorbid: people having one disorder are likely to have another as well. We explain empirical comorbidity patterns based on a network model of psychiatric symptoms, derived from an analysis of symptom overlap in the Diagnostic and Statistical Manual of Mental Disorders-IV (DSM-IV).

Principal Findings
We show that a) half of the symptoms in the DSM-IV network are connected, b) the architecture of these connections conforms to a small world structure, featuring a high degree of clustering but a short average path length, and c) distances between disorders in this structure predict empirical comorbidity rates. Network simulations of Major Depressive Episode and Generalized Anxiety Disorder show that the model faithfully reproduces empirical population statistics for these disorders.

Conclusions
In the network model, mental disorders are inherently complex. This explains the limited successes of genetic, neuroscientific, and etiological approaches to unravel their causes. We outline a psychosystems approach to investigate the structure and dynamics of mental disorders.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\PMLDCDKD\\Borsboom et al. - 2011 - The Small World of Psychopathology.pdf},
  journal = {PLoS ONE},
  number = {11},
  pmcid = {PMC3219664},
  pmid = {22114671}
}

@techreport{borsboomTheory2020,
  title = {Theory {{Construction Methodology}}: {{A}} Practical Framework for Theory Formation in Psychology},
  shorttitle = {Theory {{Construction Methodology}}},
  author = {Borsboom, Denny and {van der Maas}, Han and Dalege, Jonas and Kievit, Rogier and Haig, Brian},
  year = {2020},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/w5tp8},
  abstract = {This paper aims to improve theory formation in psychology by developing a practical methodology for constructing explanatory theories: Theory Construction Methodology (TCM). TCM is a sequence of five steps. First, the theorist identifies empirical phenomena to become the target of explanation. Second, the theorist constructs a proto-theory: a set of theoretical principles that potentially explain these phenomena. Third, the proto-theory is used to construct a formal model: a set of model equations or simulation models that encode the explanatory principles. Fourth, the theorist investigates this model's explanatory adequacy. This is done by formalizing the empirical phenomena in terms of the model, and assessing whether the model indeed reproduces them. Fifth, the theorist studies the overall adequacy of the theory by evaluating whether phenomena are indeed reproduced faithfully, whether explanatory principles are parsimonious and substantively plausible, and whether the theory implies new predictions to promote further research. We illustrate TCM with an example taken from the intelligence literature (the mutualism model of intelligence), discuss the place of TCM in the larger scheme of scientific research, and propose an outline for a university curriculum that can systematically educate psychologists in the process of theory formation.},
  type = {Preprint}
}

@article{boschlooProspective2016,
  title = {A {{Prospective Study}} on {{How Symptoms}} in a {{Network Predict}} the {{Onset}} of {{Depression}}},
  author = {Boschloo, Lynn and {van Borkulo}, Claudia D. and Borsboom, Denny and Schoevers, Robert A.},
  year = {2016},
  volume = {85},
  pages = {183--184},
  issn = {1423-0348},
  doi = {10.1159/000442001},
  file = {C\:\\Users\\josue\\Zotero\\storage\\2LIX9ZTF\\Boschloo et al. - 2016 - A Prospective Study on How Symptoms in a Network P.pdf},
  journal = {Psychotherapy and Psychosomatics},
  keywords = {Case-Control Studies,Depression,Depressive Disorder; Major,Follow-Up Studies,Humans,Logistic Models,Prospective Studies,Psychiatric Status Rating Scales,Risk Factors},
  language = {eng},
  number = {3},
  pmid = {27043457}
}

@article{bottcherDistance2019,
  title = {Distance Multivariance: {{New}} Dependence Measures for Random Vectors},
  shorttitle = {Distance Multivariance},
  author = {B{\"o}ttcher, Bj{\"o}rn and {Keller-Ressel}, Martin and Schilling, Ren{\'e} L.},
  year = {2019},
  volume = {47},
  pages = {2757--2789},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/18-AOS1764},
  abstract = {We introduce two new measures for the dependence of n{$\geq$}2n{$\geq$}2n\textbackslash{}ge2 random variables: distance multivariance and total distance multivariance. Both measures are based on the weighted L2L2L\^\{2\}-distance of quantities related to the characteristic functions of the underlying random variables. These extend distance covariance (introduced by Sz{\'e}kely, Rizzo and Bakirov) from pairs of random variables to nnn-tuplets of random variables. We show that total distance multivariance can be used to detect the independence of nnn random variables and has a simple finite-sample representation in terms of distance matrices of the sample points, where distance is measured by a continuous negative definite function. Under some mild moment conditions, this leads to a test for independence of multiple random vectors which is consistent against all alternatives.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\M7C3TDJK\\Böttcher et al. - 2019 - Distance multivariance New dependence measures fo.pdf;C\:\\Users\\josue\\Zotero\\storage\\LJB7EYRP\\1564797863.html},
  journal = {The Annals of Statistics},
  keywords = {characteristic function,Dependence measure,Gaussian random field,negative definite function,statistical test of independence,stochastic independence},
  language = {EN},
  mrnumber = {MR3988772},
  number = {5},
  zmnumber = {07114928}
}

@article{bradleyCorrelation1979,
  title = {Correlation in {{Polynomial Regression}}},
  author = {Bradley, Ralph A. and Srivastava, Sushil S.},
  year = {1979},
  volume = {33},
  pages = {11--14},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.1979.10482644},
  journal = {The American Statistician},
  language = {en},
  number = {1}
}

@article{braekenRelative2015,
  title = {Relative {{Effects}} at {{Work}}: {{Bayes Factors}} for {{Order Hypotheses}}},
  shorttitle = {Relative {{Effects}} at {{Work}}},
  author = {Braeken, Johan and Mulder, Joris and Wood, Stephen},
  year = {2015},
  volume = {41},
  pages = {544--573},
  issn = {0149-2063},
  doi = {10.1177/0149206314525206},
  abstract = {Assessing the relative importance of predictors has been of historical importance in a variety of disciplines including management, medicine, economics, and psychology. When approaching hypotheses on the relative ordering of the magnitude of predicted effects (e.g., the effects of discrimination from managers and coworkers are larger than that from clients), one quickly runs into problems within a traditional frequentist framework. Null hypothesis significance testing does not allow researchers to directly map research hypotheses on to results and suffers from a multiple testing problem that leads to low statistical power. Furthermore, all traditional structural equation modeling fit indices lose much of their suitability for model comparison, because order hypotheses are not countable in terms of degrees of freedom. To adequately tackle order hypotheses, we advocate a Bayesian method that provides a single internally consistent solution for estimation and inference. The key element in the proposed model comparison approach is the use of the Bayes factor and the incorporation of order constraints by means of a smart formulation of prior distributions. An easy-to-use software package BIEMS (Bayesian inequality and equality constrained model selection) is introduced and two empirical examples in the organizational behavior area are provided to showcase the method, both offering new findings that have implications for theory: the first on the differential impact of discrimination in the workplace from insiders and outsiders to the organization on employees' well-being, and the second on Karasek's stressor\textendash{}strain theory about how the relative order of magnitude of the effects of job control and demands depends on the specific well-being outcome dimension.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\7QZLZIU9\\Braeken et al. - 2015 - Relative Effects at Work Bayes Factors for Order .pdf},
  journal = {Journal of Management},
  language = {en},
  number = {2}
}

@article{breimanStatistical,
  title = {Statistical {{Modeling}}: {{The Two Cultures}}},
  author = {Breiman, Leo},
  pages = {33},
  abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HQ8HNHS8\\Breiman - Statistical Modeling The Two Cultures.pdf},
  journal = {THE TWO CULTURES},
  language = {en}
}

@article{bringmannDon2018,
  title = {Don't Blame the Model: {{Reconsidering}} the Network Approach to Psychopathology.},
  shorttitle = {Don't Blame the Model},
  author = {Bringmann, Laura F. and Eronen, Markus I.},
  year = {2018},
  volume = {125},
  pages = {606--615},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/rev0000108},
  file = {C\:\\Users\\josue\\Zotero\\storage\\22VC9YZK\\Bringmann and Eronen - 2018 - Don’t blame the model Reconsidering the network a.pdf},
  journal = {Psychological Review},
  language = {en},
  number = {4}
}

@article{bringmannNetwork2013,
  title = {A {{Network Approach}} to {{Psychopathology}}: {{New Insights}} into {{Clinical Longitudinal Data}}},
  shorttitle = {A {{Network Approach}} to {{Psychopathology}}},
  author = {Bringmann, Laura F. and Vissers, Nathalie and Wichers, Marieke and Geschwind, Nicole and Kuppens, Peter and Peeters, Frenk and Borsboom, Denny and Tuerlinckx, Francis},
  year = {2013},
  volume = {8},
  pages = {e60188},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0060188},
  abstract = {In the network approach to psychopathology, disorders are conceptualized as networks of mutually interacting symptoms (e.g., depressed mood) and transdiagnostic factors (e.g., rumination). This suggests that it is necessary to study how symptoms dynamically interact over time in a network architecture. In the present paper, we show how such an architecture can be constructed on the basis of time-series data obtained through Experience Sampling Methodology (ESM). The proposed methodology determines the parameters for the interaction between nodes in the network by estimating a multilevel vector autoregression (VAR) model on the data. The methodology allows combining between-subject and within-subject information in a multilevel framework. The resulting network architecture can subsequently be analyzed through network analysis techniques. In the present study, we apply the method to a set of items that assess mood-related factors. We show that the analysis generates a plausible and replicable network architecture, the structure of which is related to variables such as neuroticism; that is, for subjects who score high on neuroticism, worrying plays a more central role in the network. Implications and extensions of the methodology are discussed.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\6AGY7B6W\\Bringmann et al. - 2013 - A Network Approach to Psychopathology New Insight.pdf;C\:\\Users\\josue\\Zotero\\storage\\SEHIBCD2\\article.html},
  journal = {PLOS ONE},
  keywords = {Centrality,Depression,Emotions,Fear,Network analysis,Neural networks,Relaxation (psychology),Statistical data},
  language = {en},
  number = {4}
}

@article{bringmannWhat2019,
  title = {What Do Centrality Measures Measure in Psychological Networks?},
  author = {Bringmann, Laura F. and Elmer, Timon and Epskamp, Sacha and Krause, Robert W. and Schoch, David and Wichers, Marieke and Wigman, Johanna T. W. and Snippe, Evelien},
  year = {2019},
  volume = {128},
  pages = {892--903},
  issn = {1939-1846, 0021-843X},
  doi = {10.1037/abn0000446},
  abstract = {Centrality indices are a popular tool to analyze structural aspects of psychological networks. As centrality indices were originally developed in the context of social networks, it is unclear to what extent these indices are suitable in a psychological network context. In this paper we critically examine several issues with the use of the most popular centrality indices in psychological networks: degree, betweenness, and closeness centrality. We show that problems with centrality indices discussed in the social network literature also apply to the psychological networks. Assumptions underlying centrality indices, such as presence of a flow and shortest paths, may not correspond with a general theory of how psychological variables relate to one another. Furthermore, the assumptions of node distinctiveness and node exchangeability may not hold in psychological networks. We conclude that, for psychological networks, betweenness and closeness centrality seem especially unsuitable as measures of node importance. We therefore suggest three ways forward: (1) using centrality measures that are tailored to the psychological network context, (2) reconsidering existing measures of importance used in statistical models underlying psychological networks, and (3) discarding the concept of node centrality entirely. Foremost, we argue that one has to make explicit what one means when one states that a node is central, and what assumptions the centrality measure of choice entails, to make sure that there is a match between the process under study and the centrality measure that is used.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\SM8KCS4A\\Bringmann et al. - 2019 - What do centrality measures measure in psychologic.pdf},
  journal = {Journal of Abnormal Psychology},
  language = {en},
  number = {8}
}

@article{brooksissues1998,
  title = {Some Issues for Monitoring Convergence of Iterative Simulations},
  author = {Brooks, Stephen and Gelman, Andrew},
  year = {1998},
  pages = {30--36},
  file = {C\:\\Users\\josue\\Zotero\\storage\\YMQ7NX6P\\brooks-gelman.pdf},
  journal = {Computing Science and Statistics}
}

@article{brovermanCognitive1960,
  title = {Cognitive Style and Intra-Individual Variation in Abilities},
  author = {Broverman, Donald M.},
  year = {1960},
  volume = {28},
  pages = {240--256},
  issn = {1467-6494(Electronic),0022-3506(Print)},
  doi = {10.1111/j.1467-6494.1960.tb01616.x},
  abstract = {"This study demonstrates that abilities vary within individuals as functions of their cognitive styles. The intra-individual ability variations were measured through the use of ipsative scores\ldots{} which reflect deviations in performance on particular tasks from the person's general level of performance on a large battery of tasks\ldots{} . The implications of these findings for personality research and stress methodology were discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C\:\\Users\\josue\\Zotero\\storage\\6266PE2F\\1961-02195-001.html},
  journal = {Journal of Personality}
}

@article{brunton-smithDetecting2017,
  title = {Detecting and Understanding Interviewer Effects on Survey Data by Using a Cross-Classified Mixed Effects Location\textendash{}Scale Model},
  author = {Brunton-Smith, Ian and Sturgis, Patrick and Leckie, George},
  year = {2017},
  volume = {180},
  pages = {551--568},
  issn = {1467-985X},
  doi = {10.1111/rssa.12205},
  abstract = {We propose a cross-classified mixed effects location\textendash{}scale model for the analysis of interviewer effects in survey data. The model extends the standard two-way cross-classified random-intercept model (respondents nested in interviewers crossed with areas) by specifying the residual variance to be a function of covariates and an additional interviewer random effect. This extension provides a way to study interviewers' effects on not just the `location' (mean) of respondents' responses, but additionally on their `scale' (variability). It therefore allows researchers to address new questions such as `Do interviewers influence the variability of their respondents' responses in addition to their average, and if so why?'. In doing so, the model facilitates a more complete and flexible assessment of the factors that are associated with interviewer error. We illustrate this model by using data from wave 3 of the UK Household Longitudinal Survey, which we link to a range of interviewer characteristics measured in an independent survey of interviewers. By identifying both interviewer characteristics in general, but also specific interviewers who are associated with unusually high or low or homogeneous or heterogeneous responses, the model provides a way to inform improvements to survey quality.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ATQIVWYK\\Brunton‐Smith et al. - 2017 - Detecting and understanding interviewer effects on.pdf;C\:\\Users\\josue\\Zotero\\storage\\DHTI67B2\\rssa.html},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  keywords = {Interviewer effect,Measurement error,Mixed effects location–scale model,Stat-JR software,Understanding society},
  language = {en},
  number = {2}
}

@article{brysbaertPower2018,
  title = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}: {{A Tutorial}}},
  shorttitle = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}},
  author = {Brysbaert, Marc and Stevens, Micha{\"e}l},
  year = {2018},
  volume = {1},
  pages = {9},
  issn = {2514-4820},
  doi = {10.5334/joc.10},
  abstract = {Article: Power Analysis and Effect Size in Mixed Effects Models: A Tutorial},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\XS2VTGT8\\Brysbaert and Stevens - 2018 - Power Analysis and Effect Size in Mixed Effects Mo.pdf;C\:\\Users\\josue\\Zotero\\storage\\EHK8I9WT\\joc.html},
  journal = {Journal of Cognition},
  language = {en},
  number = {1}
}

@article{burknerbrms2017,
  title = {Brms : {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  shorttitle = {{\textbf{Brms}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  volume = {80},
  issn = {1548-7660},
  doi = {10.18637/jss.v080.i01},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit \textendash{} among others \textendash{} linear, robust linear, binomial, Poisson, survival, response times, ordinal, quantile, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as metaanalytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared using posterior-predictive checks and leave-one-out crossvalidation. If you use brms, please cite this article as published in the Journal of Statistical Software (Bu\textasciidieresis{}rkner 2017).},
  file = {C\:\\Users\\josue\\Zotero\\storage\\74LC8Z6Q\\Bürkner - 2017 - bbrmsb  An iRi Package for Bayesian Mul.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{burnhamKullbackLeibler2001,
  title = {Kullback-{{Leibler}} Information as a Basis for Strong Inference in Ecological Studies},
  author = {Burnham, Kenneth P. and Anderson, David R.},
  year = {2001},
  volume = {28},
  pages = {111},
  issn = {1035-3712},
  doi = {10.1071/WR99107},
  abstract = {We describe an information-theoretic paradigm for analysis of ecological data, based on Kullback\textendash{}Leibler information, that is an extension of likelihood theory and avoids the pitfalls of null hypothesis testing. Information-theoretic approaches emphasise a deliberate focus on the a priori science in developing a set of multiple working hypotheses or models. Simple methods then allow these hypotheses (models) to be ranked from best to worst and scaled to reflect a strength of evidence using the likelihood of each model (gi), given the data and the models in the set (i.e. L(gi | data)). In addition, a variance component due to model-selection uncertainty is included in estimates of precision. There are many cases where formal inference can be based on all the models in the a priori set and this multi-model inference represents a powerful, new approach to valid inference. Finally, we strongly recommend inferences based on a priori considerations be carefully separated from those resulting from some form of data dredging. An example is given for questions related to age- and sex-dependent rates of tag loss in elephant seals (Mirounga leonina).},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4P9DQGC8\\Burnham and Anderson - 2001 - Kullback-Leibler information as a basis for strong.pdf},
  journal = {Wildlife Research},
  language = {en},
  number = {2}
}

@article{burnhamMultimodel2004,
  title = {Multimodel {{Inference}}: {{Understanding AIC}} and {{BIC}} in {{Model Selection}}},
  shorttitle = {Multimodel {{Inference}}},
  author = {Burnham, Kenneth P. and Anderson, David R.},
  year = {2004},
  volume = {33},
  pages = {261--304},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/0049124104268644},
  file = {C\:\\Users\\josue\\Zotero\\storage\\X76XLIFZ\\Burnham and Anderson - 2004 - Multimodel Inference Understanding AIC and BIC in.pdf},
  journal = {Sociological Methods \& Research},
  language = {en},
  number = {2}
}

@article{castroDifferential2019,
  title = {The {{Differential Role}} of {{Central}} and {{Bridge Symptoms}} in {{Deactivating Psychopathological Networks}}},
  author = {Castro, Daniel and Ferreira, Filipa and {de Castro}, In{\^e}s and Rodrigues, Ana Rita and Correia, Marta and Ribeiro, Josefina and Ferreira, Tiago Bento},
  year = {2019},
  volume = {10},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.02448},
  abstract = {The network model of psychopathology suggests that central and bridge symptoms represent promising treatment targets because they may accelerate the deactivation of the network of interactions between the symptoms of mental disorders. However, the evidence confirming this hypothesis is scarce. This study re-analyzed a convenience sample of 51 cross-sectional psychopathological networks published in previous studies addressing diverse mental disorders or clinically relevant problems. In order to address the hypothesis that central and bridge symptoms are valuable treatment targets, this study simulated five distinct attack conditions on the psychopathological networks by deactivating symptoms based on two characteristics of central symptoms (degree and strength), two characteristics of bridge symptoms (overlap and bridgeness), and at random. The differential impact of the characteristics of these symptoms was assessed in terms of the magnitude and the extent of the attack required to achieve a maximum impact on the number of components, average path length, and connectivity. Only moderate evidence was obtained to sustain the hypothesis that central and bridge symptoms constitute preferential treatment targets. The results suggest that the degree, strength, and bridgeness attack conditions are more effective than the random attack condition only in increasing the number of components of the psychopathological networks. The degree attack condition seemed to perform better than the strength, bridgeness, and overlap attack conditions. Overlapping symptoms evidenced limited impact on the psychopathological networks. The need to address the basic mechanisms underlying the structure and dynamics of psychopathological networks through the expansion of the current methodological framework and its consolidation in more robust theories is stressed.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\58KPG22B\\Castro et al. - 2019 - The Differential Role of Central and Bridge Sympto.pdf},
  journal = {Frontiers in Psychology},
  pmcid = {PMC6849493},
  pmid = {31827450}
}

@inproceedings{chandtuning2012,
  title = {On Tuning Parameter Selection of Lasso-Type Methods - a Monte Carlo Study},
  booktitle = {Proceedings of 2012 9th {{International Bhurban Conference}} on {{Applied Sciences Technology}} ({{IBCAST}})},
  author = {Chand, Sohail},
  year = {2012},
  pages = {120--129},
  issn = {2151-1411},
  doi = {10.1109/IBCAST.2012.6177542},
  abstract = {In regression analysis, variable selection is a challenging task. Over the last decade, the lasso-type methods have become popular method for variable selection due to their property of shrinking some of the model coefficients to exactly zero. Theory says that lasso-type methods are able to do consistent variable selection but it is hard to achieve this property in practice. This consistent variable selection highly depends on the right choice of the tuning parameter. In this paper, we show that selection of tuning parameter by cross validation almost always fail to achieve consistent variable selection. We have also shown that lasso-type methods with a BIC-type tuning parameter selector, under certain conditions, can do the consistent variable selection. We have also made a novel suggestion for choosing the value of Cn, a weight on estimated model size, in BIC. Our results show that with this choice of Cn, the lasso-type methods can do consistent variable selection.In regression analysis, variable selection is a challenging task. Over the last decade, the lasso-type methods have become popular method for variable selection due to their property of shrinking some of the model coefficients to exactly zero. Theory says that lasso-type methods are able to do consistent variable selection but it is hard to achieve this property in practice. This consistent variable selection highly depends on the right choice of the tuning parameter. In this paper, we show that selection of tuning parameter by cross validation almost always fail to achieve consistent variable selection. We have also shown that lasso-type methods with a BIC-type tuning parameter selector, under certain conditions, can do the consistent variable selection. We have also made a novel suggestion for choosing the value of Cn, a weight on estimated model size, in BIC. Our results show that with this choice of Cn, the lasso-type methods can do consistent variable selection.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\CXRIPB3L\\Chand - 2012 - On tuning parameter selection of lasso-type method.pdf;C\:\\Users\\josue\\Zotero\\storage\\BDWY3VHG\\6177542.html},
  keywords = {BIC-type tuning parameter selector,consistent variable selection,cross validation,Lasso-type methods,model coefficients,Monte Carlo methods,Monte Carlo study,regression analysis,Tuning,tuning parameter selection}
}

@article{chenExtended2008,
  title = {Extended {{Bayesian}} Information Criteria for Model Selection with Large Model Spaces},
  author = {Chen, J. and Chen, Z.},
  year = {2008},
  volume = {95},
  pages = {759--771},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asn034},
  abstract = {The ordinary Bayesian information criterion is too liberal for model selection when the model space is large. In this paper, we re-examine the Bayesian paradigm for model selection and propose an extended family of Bayesian information criteria, which take into account both the number of unknown parameters and the complexity of the model space. Their consistency is established, in particular allowing the number of covariates to increase to infinity with the sample size. Their performance in various situations is evaluated by simulation studies. It is demonstrated that the extended Bayesian information criteria incur a small loss in the positive selection rate but tightly control the false discovery rate, a desirable property in many applications. The extended Bayesian information criteria are extremely useful for variable selection in problems with a moderate sample size but with a huge number of covariates, especially in genome-wide association studies, which are now an active area in genetics research.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\EGVHS2LF\\Chen and Chen - 2008 - Extended Bayesian information criteria for model s.pdf},
  journal = {Biometrika},
  language = {en},
  number = {3}
}

@article{chenTournament2009,
  title = {Tournament Screening Cum {{EBIC}} for Feature Selection with High-Dimensional Feature Spaces},
  author = {Chen, ZeHua and Chen, JiaHua},
  year = {2009},
  volume = {52},
  pages = {1327--1341},
  issn = {1006-9283, 1862-2763},
  doi = {10.1007/s11425-009-0089-4},
  abstract = {The feature selection characterized by relatively small sample size and extremely high dimensional feature space is common in many areas of contemporary statistics. The high dimensionality of the feature space causes serious difficulties: (i) the sample correlations between features become high even if the features are stochastically independent; (ii) the computation becomes intractable. These difficulties make conventional approaches either inapplicable or inefficient. The reduction of dimensionality of the feature space followed by low dimensional approaches appears the only feasible way to tackle the problem. Along this line, we develop in this article a tournament screening cum EBIC approach for feature selection with high dimensional feature space. The procedure of tournament screening mimics that of a tournament. It is shown theoretically that the tournament screening has the sure screening property, a necessary property which should be satisfied by any valid screening procedure. It is demonstrated by numerical studies that the tournament screening cum EBIC approach enjoys desirable properties such as having higher positive selection rate and lower false discovery rate than other approaches.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\I2S4KWWU\\Chen and Chen - 2009 - Tournament screening cum EBIC for feature selectio.pdf},
  journal = {Science in China Series A: Mathematics},
  language = {en},
  number = {6}
}

@article{chumbleyBayesian,
  title = {A {{Bayesian}} Credible Set for Ranking Parameters by Relative Magnitude},
  author = {Chumbley, Justin},
  pages = {29},
  abstract = {The relative magnitude or ranking of statistical parameters - say treatment effects or variance components - is often more interesting or trustworthy than their absolute magnitude, or than strawman tests of their equality. Yet despite some existing tools for model selection, there is currently nothing akin to a simple {$\beta\%$} confidence or credible interval for ranking parameters of interest. We therefore aim here to automatically identify the probable ranking of (an interesting subset of) components of a parameter vector or matrix: to find the most informative or finest assertion about this ranking at the desired {$\beta\%$} credibility. For example, we may learn from linear regression on a given dataset that ``w2 {$<$} w1, w3 {$<$} w4 holds with 95\% probability'', so our 4 coefficients of interest contain at least r = 3 distinct ranks. Or we may discover from the covariance matrix of a time-series that observation 1 has a U-shaped dependence with the subsequent 5 observations: ``{$\sigma$}13, {$\sigma$}14, {$\sigma$}15 {$<$} {$\sigma$}12, {$\sigma$}16 with 95\% probability''. To do this we construct a new Bayesian posterior credible set of full rankings C{$\beta$} using simple group-theoretic properties of the tesselated parameter space. The approach can be applied in both exact and approximate MCMC and variational - settings and offers interpretational advantages over typical analysis. By sidestepping the computation of marginal likelihood and Bayes factors our procedure requires neither informative priors nor informative hypotheses.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HGYX2XJ5\\Chumbley - A Bayesian credible set for ranking parameters by .pdf},
  language = {en}
}

@article{cohenpower1992,
  title = {A Power Primer},
  author = {Cohen, Jacob},
  year = {1992},
  volume = {112},
  pages = {155--159},
  issn = {0033-2909},
  doi = {http://dx.doi.org/10.1037/0033-2909.112.1.155},
  abstract = {One possible reason for the continued neglect of statistical power analysis in research in the behavioral sciences is the inaccessibility of or difficulty with the standard material. A convenient, although not comprehensive, presentation of required sample sizes is provided. Effect-size indexes and conventional values for these are given for operationally defined small, medium, and large effects. The sample sizes necessary for .80 power to detect effects at these levels are tabled for 8 standard statistical tests: (1) the difference between independent means, (2) the significance of a product\textendash{}moment correlation, (3) the difference between independent rs, (4) the sign test, (5) the difference between independent proportions, (6) chi-square tests for goodness of fit and contingency tables, (7) 1-way analysis of variance (ANOVA), and (8) the significance of a multiple or multiple partial correlation. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  copyright = {\textcopyright{} 1992, American Psychological Association},
  file = {C\:\\Users\\josue\\Zotero\\storage\\X7ZWP62H\\Cohen - 1992 - A power primer.pdf},
  journal = {Psychological Bulletin},
  keywords = {Effect Size (Statistical) (major),Statistical Analysis (major),Statistical Power (major)},
  language = {English},
  number = {1}
}

@article{contrerasStudy2019,
  title = {The {{Study}} of {{Psychopathology}} from the {{Network Analysis Perspective}}: {{A~Systematic Review}}},
  shorttitle = {The {{Study}} of {{Psychopathology}} from the {{Network Analysis Perspective}}},
  author = {Contreras, Alba and Nieto, Ines and Valiente, Carmen and Espinosa, Regina and Vazquez, Carmelo},
  year = {2019},
  volume = {88},
  pages = {71--83},
  issn = {1423-0348},
  doi = {10.1159/000497425},
  abstract = {BACKGROUND: Network analysis (NA) is an analytical tool that allows one to explore the map of connections and eventual dynamic influences among symptoms and other elements of mental disorders. In recent years, the use of NA in psychopathology has rapidly grown, which calls for a systematic and critical analysis of its clinical utility.
METHODS: Following PRISMA guidelines, a systematic review of published empirical studies applying NA in psychopathology, between 2010 and 2017, was conducted. We included the literature published in PubMed and PsycINFO using as keywords any combination of "network analysis" with the terms "anxiety," "affective disorders," "depression," "schizophrenia," "psychosis," "personality disorders," "substance abuse" and "psychopathology."
RESULTS: The review showed that NA has been applied in a plethora of mental disorders in adults (i.e., 13 studies on anxiety disorders; 19 on mood disorders; 7 on psychosis; 1 on substance abuse; 1 on borderline personality disorder; 18 on the association of symptoms between disorders), and 6 on childhood and adolescence.
CONCLUSIONS: A critical examination of the results of each study suggests that NA helps to identify, in an innovative way, important aspects of psychopathology like the centrality of the symptoms in a given disorder as well as the mutual dynamics among symptoms. Yet, despite these promising results, the clinical utility of NA is still uncertain as there are important limitations on the analytic procedures (e.g., reliability of indices), the type of data included (e.g., typically restricted to secondary analysis of already published data), and ultimately, the psychometric and clinical validity of the results.},
  journal = {Psychotherapy and Psychosomatics},
  keywords = {Data Interpretation; Statistical,Humans,Mental disorder,Mental Disorders,Network analysis,Network theory,Psychopathology,Symptom Assessment,Systematic review},
  language = {eng},
  number = {2},
  pmid = {30889609}
}

@article{costantiniState2015,
  title = {State of the {{aRt}} Personality Research: {{A}} Tutorial on Network Analysis of Personality Data in {{R}}},
  shorttitle = {State of the {{aRt}} Personality Research},
  author = {Costantini, Giulio and Epskamp, Sacha and Borsboom, Denny and Perugini, Marco and M{\~o}ttus, Ren{\'e} and Waldorp, Lourens J. and Cramer, Ang{\'e}lique O. J.},
  year = {2015},
  volume = {54},
  pages = {13--29},
  issn = {0092-6566},
  doi = {10.1016/j.jrp.2014.07.003},
  abstract = {Network analysis represents a novel theoretical approach to personality. Network approaches motivate alternative ways of analyzing data, and suggest new ways of modeling and simulating personality processes. In the present paper, we provide an overview of network analysis strategies as they apply to personality data. We discuss different ways to construct networks from typical personality data, show how to compute and interpret important measures of centrality and clustering, and illustrate how one can simulate on networks to mimic personality processes. All analyses are illustrated using a data set on the commonly used HEXACO questionnaire using elementary R-code that readers may easily adapt to apply to their own data.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\6T99L6XF\\Costantini et al. - 2015 - State of the aRt personality research A tutorial .pdf;C\:\\Users\\josue\\Zotero\\storage\\JLYHQK44\\S0092656614000701.html},
  journal = {Journal of Research in Personality},
  keywords = {Centrality,Clustering,HEXACO,Latent variables,Network analysis,Personality traits,Psychometrics},
  language = {en},
  series = {R {{Special Issue}}}
}

@article{cramerComorbidity2010,
  title = {Comorbidity: {{A}} Network Perspective},
  shorttitle = {Comorbidity},
  author = {Cramer, Ang{\'e}lique O. J. and Waldorp, Lourens J. and {van der Maas}, Han L. J. and Borsboom, Denny},
  year = {2010},
  volume = {33},
  pages = {137--150},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X09991567},
  abstract = {Abstract
            
              The pivotal problem of comorbidity research lies in the psychometric foundation it rests on, that is,
              latent variable theory
              , in which a mental disorder is viewed as a latent variable that
              causes
              a constellation of symptoms. From this perspective, comorbidity is a (bi)directional relationship between multiple latent variables. We argue that such a latent variable perspective encounters serious problems in the study of comorbidity, and offer a radically different conceptualization in terms of a
              network approach
              , where comorbidity is hypothesized to arise from direct relations between symptoms of multiple disorders. We propose a method to visualize comorbidity networks and, based on an empirical network for major depression and generalized anxiety, we argue that this approach generates realistic hypotheses about pathways to comorbidity, overlapping symptoms, and diagnostic boundaries, that are not naturally accommodated by latent variable models: Some pathways to comorbidity through the
              symptom space
              are more likely than others; those pathways generally have the same direction (i.e., from symptoms of one disorder to symptoms of the other); overlapping symptoms play an important role in comorbidity; and boundaries between diagnostic categories are necessarily fuzzy.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\BDFRZ5ES\\Cramer et al. - 2010 - Comorbidity A network perspective.pdf},
  journal = {Behavioral and Brain Sciences},
  language = {en},
  number = {2-3}
}

@article{cramerComplex2010,
  title = {Complex Realities Require Complex Theories: {{Refining}} and Extending the Network Approach to Mental Disorders},
  shorttitle = {Complex Realities Require Complex Theories},
  author = {Cramer, Ang{\'e}lique O. J. and Waldorp, Lourens J. and {van der Maas}, Han L. J. and Borsboom, Denny},
  year = {2010},
  volume = {33},
  pages = {178--193},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X10000920},
  abstract = {Abstract
            The majority of commentators agree on one thing: Our network approach might be the prime candidate for offering a new perspective on the origins of mental disorders. In our response, we elaborate on refinements (e.g., cognitive and genetic levels) and extensions (e.g., to Axis II disorders) of the network model, as well as discuss ways to test its validity.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\6ADYWTQ8\\Cramer et al. - 2010 - Complex realities require complex theories Refini.pdf},
  journal = {Behavioral and Brain Sciences},
  language = {en},
  number = {2-3}
}

@article{cramerDimensions2012,
  title = {Dimensions of {{Normal Personality}} as {{Networks}} in {{Search}} of {{Equilibrium}}: {{You Can}}'t {{Like Parties}} If {{You Don}}'t {{Like People}}},
  shorttitle = {Dimensions of {{Normal Personality}} as {{Networks}} in {{Search}} of {{Equilibrium}}},
  author = {Cramer, Ang{\'e}lique O. J. and van der Sluis, Sophie and Noordhof, Arjen and Wichers, Marieke and Geschwind, Nicole and Aggen, Steven H. and Kendler, Kenneth S. and Borsboom, Denny},
  year = {2012},
  volume = {26},
  pages = {414--431},
  issn = {1099-0984},
  doi = {10.1002/per.1866},
  abstract = {In one currently dominant view on personality, personality dimensions (e.g. extraversion) are causes of human behaviour, and personality inventory items (e.g. `I like to go to parties' and `I like people') are measurements of these dimensions. In this view, responses to extraversion items correlate because they measure the same latent dimension. In this paper, we challenge this way of thinking and offer an alternative perspective on personality as a system of connected affective, cognitive and behavioural components. We hypothesize that these components do not hang together because they measure the same underlying dimension; they do so because they depend on one another directly for causal, homeostatic or logical reasons (e.g. if one does not like people and it is harder to enjoy parties). From this `network perspective', personality dimensions emerge out of the connectivity structure that exists between the various components of personality. After outlining the network theory, we illustrate how it applies to personality research in four domains: (i) the overall organization of personality components; (ii) the distinction between state and trait; (iii) the genetic architecture of personality; and (iv) the relation between personality and psychopathology. Copyright \textcopyright{} 2012 John Wiley \& Sons, Ltd.},
  copyright = {Copyright \textcopyright{} 2012 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\Q8EEWWGX\\Cramer et al. - 2012 - Dimensions of Normal Personality as Networks in Se.pdf;C\:\\Users\\josue\\Zotero\\storage\\WYDXWZ9M\\per.html},
  journal = {European Journal of Personality},
  keywords = {latent variable models,networks,normal personality,personality traits},
  language = {en},
  note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/per.1866},
  number = {4}
}

@incollection{cramerProblems2015,
  title = {Problems {{Attract Problems}}: {{A Network Perspective}} on {{Mental Disorders}}},
  shorttitle = {Problems {{Attract Problems}}},
  booktitle = {Emerging {{Trends}} in the {{Social}} and {{Behavioral Sciences}}},
  author = {Cramer, Ang{\'e}Lique O. J. and Borsboom, Denny},
  year = {2015},
  pages = {1--15},
  publisher = {{American Cancer Society}},
  doi = {10.1002/9781118900772.etrds0264},
  abstract = {What is the nature of mental disorders such as major depression and panic disorder? Are mental disorders analogous to tumors, in that they exist as separate entities somewhere in people's minds? Do mental disorders cause symptoms such as insomnia and fatigue? Until very recently, it was exactly this sort of thinking that (implicitly) permeated many, if not all, research paradigms in clinical psychology and psychiatry. However, in recent years, a novel approach has been advocated (i.e., the network perspective), in which mental disorders are not conceived of as entities that have a separate existence from their respective symptoms. Instead, mental disorders are hypothesized to be networks of symptoms that directly influence one another. So, for example, from a network perspective, insomnia and fatigue are not caused by the same underlying disorder (i.e., major depression) but causally influence one another (i.e., insomnia \textrightarrow{} fatigue). A disorder, then, develops because of such direct relations between symptoms in which positive feedback mechanisms (i.e., vicious circles) are present: for example, insomnia \textrightarrow{} fatigue \textrightarrow{} feelings of guilt \textrightarrow{} insomnia. These feedback mechanisms may propel the aggravation of one's condition and make a person end up in, for example, a full-fledged depressive episode. In this contribution, we elaborate on network perspectives on the nature of mental disorders as well as their implications for our outlook on diagnosis and comorbidity.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HHG2KFPQ\\Cramer and Borsboom - 2015 - Problems Attract Problems A Network Perspective o.pdf;C\:\\Users\\josue\\Zotero\\storage\\F237V85D\\9781118900772.html},
  isbn = {978-1-118-90077-2},
  keywords = {comorbidity,diagnosis,dynamical systems theory,early warning signals,latent variable models,missing heritability,network models,ontological status of mental disorders},
  language = {en}
}

@article{dablanderNode2019,
  title = {Node Centrality Measures Are a Poor Substitute for Causal Inference},
  author = {Dablander, Fabian and Hinne, Max},
  year = {2019},
  volume = {9},
  pages = {1--13},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-43033-9},
  abstract = {Network models have become a valuable tool in making sense of a diverse range of social, biological, and information systems. These models marry graph and probability theory to visualize, understand, and interpret variables and their relations as nodes and edges in a graph. Many applications of network models rely on undirected graphs in which the absence of an edge between two nodes encodes conditional independence between the corresponding variables. To gauge the importance of nodes in such a network, various node centrality measures have become widely used, especially in psychology and neuroscience. It is intuitive to interpret nodes with high centrality measures as being important in a causal sense. Using the causal framework based on directed acyclic graphs (DAGs), we show that the relation between causal influence and node centrality measures is not straightforward. In particular, the correlation between causal influence and several node centrality measures is weak, except for eigenvector centrality. Our results provide a cautionary tale: if the underlying real-world system can be modeled as a DAG, but researchers interpret nodes with high centrality as causally important, then this may result in sub-optimal interventions.},
  copyright = {2019 The Author(s)},
  file = {C\:\\Users\\josue\\Zotero\\storage\\8URH9KU5\\Dablander and Hinne - 2019 - Node centrality measures are a poor substitute for.pdf;C\:\\Users\\josue\\Zotero\\storage\\HN74LWKF\\s41598-019-43033-9.html},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{dahlData2008,
  title = {Data Splitting as a Countermeasure against Hypothesis Fishing: With a Case Study of Predictors for Low Back Pain},
  shorttitle = {Data Splitting as a Countermeasure against Hypothesis Fishing},
  author = {Dahl, Fredrik A. and Grotle, Margreth and {\v S}altyt{\.e} Benth, J{\=u}rat{\.e} and Natvig, B{\aa}rd},
  year = {2008},
  volume = {23},
  pages = {237--242},
  issn = {0393-2990},
  doi = {10.1007/s10654-008-9230-x},
  abstract = {There is growing concern in the scientific community that many published scientific findings may represent spurious patterns that are not reproducible in independent data sets. A reason for this is that significance levels or confidence intervals are often applied to secondary variables or sub-samples within the trial, in addition to the primary hypotheses (multiple hypotheses). This problem is likely to be extensive for population-based surveys, in which epidemiological hypotheses are derived after seeing the data set (hypothesis fishing). We recommend a data-splitting procedure to counteract this methodological problem, in which one part of the data set is used for identifying hypotheses, and the other is used for hypothesis testing. The procedure is similar to two-stage analysis of microarray data. We illustrate the process using a real data set related to predictors of low back pain at 14-year follow-up in a population initially free of low back pain. ``Widespreadness'' of pain (pain reported in several other places than the low back) was a statistically significant predictor, while smoking was not, despite its strong association with low back pain in the first half of the data set. We argue that the application of data splitting, in which an independent party handles the data set, will achieve for epidemiological surveys what pre-registration has done for clinical studies.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\MGA8UBMX\\Dahl et al. - 2008 - Data splitting as a countermeasure against hypothe.pdf},
  journal = {European Journal of Epidemiology},
  number = {4},
  pmcid = {PMC2270357},
  pmid = {18288577}
}

@article{dalegeNetwork2019,
  title = {A {{Network Perspective}} on {{Attitude Strength}}: {{Testing}} the {{Connectivity Hypothesis}}},
  shorttitle = {A {{Network Perspective}} on {{Attitude Strength}}},
  author = {Dalege, Jonas and Borsboom, Denny and {van Harreveld}, Frenk and {van der Maas}, Han L. J.},
  year = {2019},
  volume = {10},
  pages = {746--756},
  issn = {1948-5506},
  doi = {10.1177/1948550618781062},
  abstract = {Attitude strength is a key characteristic of attitudes. Strong attitudes are durable and impactful, while weak attitudes are fluctuating and inconsequential. Recently, the causal attitude network (CAN) model was proposed as a comprehensive measurement model of attitudes, which conceptualizes attitudes as networks of causally connected evaluative reactions (i.e., beliefs, feelings, and behavior toward an attitude object). Here, we test the central postulate of the CAN model that highly connected attitude networks correspond to strong attitudes. We use data from the American National Election Studies 1980\textendash{}2012 on attitudes toward presidential candidates (N = 18,795). We first show that political interest predicts connectivity of attitude networks toward presidential candidates. Second, we show that connectivity is strongly related to two defining features of strong attitudes\textemdash{}stability of the attitude and the attitude's impact on behavior. We conclude that network theory provides a promising framework to advance the understanding of attitude strength.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RU26KX4U\\Dalege et al. - 2019 - A Network Perspective on Attitude Strength Testin.pdf},
  journal = {Social Psychological and Personality Science},
  keywords = {attitude strength,attitude–behavior consistency,causal attitude network model,network models},
  language = {en},
  number = {6}
}

@article{desernoMulticausal2017,
  title = {Multicausal Systems Ask for Multicausal Approaches: {{A}} Network Perspective on Subjective Well-Being in Individuals with Autism Spectrum Disorder},
  shorttitle = {Multicausal Systems Ask for Multicausal Approaches},
  author = {Deserno, Marie K and Borsboom, Denny and Begeer, Sander and Geurts, Hilde M},
  year = {2017},
  volume = {21},
  pages = {960--971},
  publisher = {{SAGE Publications Ltd}},
  issn = {1362-3613},
  doi = {10.1177/1362361316660309},
  abstract = {Given the heterogeneity of autism spectrum disorder, an important limitation of much autism spectrum disorder research is that outcome measures are statistically modeled as separate dependent variables. Often, their multivariate structure is either ignored or treated as a nuisance. This study aims to lift this limitation by applying network analysis to explicate the multivariate pattern of risk and success factors for subjective well-being in autism spectrum disorder. We estimated a network structure for 27 potential factors in 2341 individuals with autism spectrum disorder to assess the centrality of specific life domains and their importance for well-being. The data included both self- and proxy-reported information. We identified social satisfaction and societal contribution as the strongest direct paths to subjective well-being. The results suggest that an important contribution to well-being lies in resources that allow the individual to engage in social relations, which influence well-being directly. Factors most important in determining the network?s structure include self-reported IQ, living situation, level of daily activity, and happiness. Number of family members with autism spectrum disorder and openness about one?s diagnosis are least important of all factors for subjective well-being. These types of results can serve as a roadmap for interventions directed at improving the well-being of individuals with autism spectrum disorder.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\GIL4SPDI\\Deserno et al. - 2017 - Multicausal systems ask for multicausal approaches.pdf},
  journal = {Autism},
  number = {8}
}

@article{dienesBayesian2011,
  title = {Bayesian {{Versus Orthodox Statistics}}: {{Which Side Are You On}}?},
  shorttitle = {Bayesian {{Versus Orthodox Statistics}}},
  author = {Dienes, Zoltan},
  year = {2011},
  volume = {6},
  pages = {274--290},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691611406920},
  abstract = {Researchers are often confused about what can be inferred from significance tests. One problem occurs when people apply Bayesian intuitions to significance testing\textemdash{}two approaches that must be firmly separated. This article presents some common situations in which the approaches come to different conclusions; you can see where your intuitions initially lie. The situations include multiple testing, deciding when to stop running participants, and when a theory was thought of relative to finding out results. The interpretation of nonsignificant results has also been persistently problematic in a way that Bayesian inference can clarify. The Bayesian and orthodox approaches are placed in the context of different notions of rationality, and I accuse myself and others as having been irrational in the way we have been using statistics on a key notion of rationality. The reader is shown how to apply Bayesian inference in practice, using free online software, to allow more coherent inferences from data.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\DC72YW9F\\Dienes - 2011 - Bayesian Versus Orthodox Statistics Which Side Ar.pdf},
  journal = {Perspectives on Psychological Science},
  language = {en},
  number = {3}
}

@article{domingosfew2012,
  title = {A Few Useful Things to Know about Machine Learning},
  author = {Domingos, Pedro},
  year = {2012},
  volume = {55},
  pages = {78},
  issn = {00010782},
  doi = {10.1145/2347736.2347755},
  file = {C\:\\Users\\josue\\Zotero\\storage\\J9ALZBC7\\Domingos - 2012 - A few useful things to know about machine learning.pdf},
  journal = {Communications of the ACM},
  language = {en},
  number = {10}
}

@article{drtonModel2004,
  title = {Model Selection for {{Gaussian}} Concentration Graphs},
  author = {Drton, M. and Perlman, M. D.},
  year = {2004},
  volume = {91},
  pages = {591--602},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/91.3.591},
  file = {C\:\\Users\\josue\\Zotero\\storage\\3NR9U9ZK\\Drton and Perlman - 2004 - Model selection for Gaussian concentration graphs.pdf},
  journal = {Biometrika},
  language = {en},
  number = {3}
}

@article{drtonMultiple2007,
  title = {Multiple {{Testing}} and {{Error Control}} in {{Gaussian Graphical Model Selection}}},
  author = {Drton, Mathias and Perlman, Michael D.},
  year = {2007},
  volume = {22},
  pages = {430--449},
  issn = {0883-4237},
  doi = {10.1214/088342307000000113},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AN79BKSX\\Drton and Perlman - 2007 - Multiple Testing and Error Control in Gaussian Gra.pdf},
  journal = {Statistical Science},
  language = {en},
  number = {3}
}

@article{duchekUtility2009,
  title = {The {{Utility}} of {{Intraindividual Variability}} in {{Selective Attention Tasks}} as an {{Early Marker}} for {{Alzheimer}}'s {{Disease}}},
  author = {Duchek, Janet M. and Balota, David A. and Tse, Chi-Shing and Holtzman, David M. and Fagan, Anne M. and Goate, Alison M.},
  year = {2009},
  volume = {23},
  pages = {746--758},
  issn = {0894-4105},
  doi = {10.1037/a0016583},
  abstract = {This study explored differences in intraindividual variability in three attention tasks across a large sample of healthy older adults and individuals with very mild dementia of the Alzheimer's type (DAT). Three groups of participants (healthy young adults, healthy older adults, very mild DAT) were administered three computerized tasks of attentional selection and switching (Stroop, Simon, Task Switching). The results indicated that a measure of intraindividual variability, coefficient of variation (CoV; SD/Mean) increased across age and early-stage DAT. The CoV in Stroop discriminated the performance of {$\epsilon$}4 carriers from noncarriers in healthy older controls and the CoV in Task Switching was correlated with CSF biomarkers predictive of DAT.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\DMMFAE5F\\Duchek et al. - 2009 - The Utility of Intraindividual Variability in Sele.pdf},
  journal = {Neuropsychology},
  number = {6},
  pmcid = {PMC2779520},
  pmid = {19899833}
}

@article{dunsonBayesian2003,
  title = {Bayesian {{Inference}} on {{Order}}-{{Constrained Parameters}} in {{Generalized Linear Models}}},
  author = {Dunson, David B. and Neelon, Brian},
  year = {2003},
  volume = {59},
  pages = {286--295},
  issn = {1541-0420},
  doi = {10.1111/1541-0420.00035},
  abstract = {In biomedical studies, there is often interest in assessing the association between one or more ordered categorical predictors and an outcome variable, adjusting for covariates. For a k-level predictor, one typically uses either a k - 1 degree of freedom (df) test or a single df trend test, which requires scores for the different levels of the predictor. In the absence of knowledge of a parametric form for the response function, one can incorporate monotonicity constraints to improve the efficiency of tests of association. This article proposes a general Bayesian approach for inference on order-constrained parameters in generalized linear models. Instead of choosing a prior distribution with support on the constrained space, which can result in major computational difficulties, we propose to map draws from an unconstrained posterior density using an isotonic regression transformation. This approach allows flat regions over which increases in the level of a predictor have no effect. Bayes factors for assessing ordered trends can be computed based on the output from a Gibbs sampling algorithm. Results from a simulation study are presented and the approach is applied to data from a time-to-pregnancy study.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\SKD6BM6N\\Dunson and Neelon - 2003 - Bayesian Inference on Order-Constrained Parameters.pdf;C\:\\Users\\josue\\Zotero\\storage\\5XKSU7MY\\1541-0420.html},
  journal = {Biometrics},
  keywords = {Bayes factor,Categorical covariates,Constrained estimation,Gibbs sampling,Isotonic regression,Monotonicity,Simple ordering,Trend test},
  language = {en},
  number = {2}
}

@article{edwardsPresence2010,
  title = {The {{Presence}} of {{Something}} or the {{Absence}} of {{Nothing}}: {{Increasing Theoretical Precision}} in {{Management Research}}},
  shorttitle = {The {{Presence}} of {{Something}} or the {{Absence}} of {{Nothing}}},
  author = {Edwards, Jeffrey R. and Berry, James W.},
  year = {2010},
  volume = {13},
  pages = {668--689},
  issn = {1094-4281},
  doi = {10.1177/1094428110380467},
  abstract = {In management research, theory testing confronts a paradox described by Meehl in which designing studies with greater methodological rigor puts theories at less risk of falsification. This paradox exists because most management theories make predictions that are merely directional, such as stating that two variables will be positively or negatively related. As methodological rigor increases, the probability that an estimated effect will differ from zero likewise increases, and the likelihood of finding support for a directional prediction boils down to a coin toss. This paradox can be resolved by developing theories with greater precision, such that their propositions predict something more meaningful than deviations from zero. This article evaluates the precision of theories in management research, offers guidelines for making theories more precise, and discusses ways to overcome barriers to the pursuit of theoretical precision.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\3XJVUIDL\\Edwards and Berry - 2010 - The Presence of Something or the Absence of Nothin.pdf},
  journal = {Organizational Research Methods},
  language = {en},
  number = {4}
}

@article{emmert-streibConstrained2019,
  title = {Constrained {{Covariance Matrices With}} a {{Biologically Realistic Structure}}: {{Comparison}} of {{Methods}} for {{Generating High}}-{{Dimensional Gaussian Graphical Models}}},
  shorttitle = {Constrained {{Covariance Matrices With}} a {{Biologically Realistic Structure}}},
  author = {{Emmert-Streib}, Frank and Tripathi, Shailesh and Dehmer, Matthias},
  year = {2019},
  volume = {5},
  issn = {2297-4687},
  doi = {10.3389/fams.2019.00017},
  abstract = {High-dimensional data from molecular biology possess an intricate correlation structure that is imposed by the molecular interactions between genes and their products forming various different types of gene networks. This fact is particularly well known for gene expression data, because there is a sufficient number of large-scale data sets available that are amenable for a sensible statistical analysis confirming this assertion. The purpose of this paper is two fold. First, we investigate three methods for generating constrained covariance matrices with a biologically realistic structure. Such covariance matrices are playing a pivotal role in designing novel statistical methods for high-dimensional biological data, because they allow to define Gaussian graphical models (GGM) for the simulation of realistic data; including their correlation structure. We study local and global characteristics of these covariance matrices, and derived concentration/partial correlation matrices. Second, we connect these results, obtained from a probabilistic perspective, to statistical results of studies aiming to estimate gene regulatory networks from biological data. This connection allows to shed light on the well-known heterogeneity of statistical estimation methods for inferring gene regulatory networks and provides an explanation for the difficulties inferring molecular interactions between highly connected genes.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IQUYDX3K\\Emmert-Streib et al. - 2019 - Constrained Covariance Matrices With a Biologicall.pdf},
  journal = {Frontiers in Applied Mathematics and Statistics},
  keywords = {data science,Gaussian graphical models (GGMs),Gene Regulatory Networks,Genomics,machine learning,networks,statistics},
  language = {English}
}

@article{epskampEstimating2017,
  title = {Estimating Psychopathological Networks: {{Be}} Careful What You Wish For},
  shorttitle = {Estimating Psychopathological Networks},
  author = {Epskamp, Sacha and Kruis, Joost and Marsman, Maarten},
  editor = {Marinazzo, Daniele},
  year = {2017},
  volume = {12},
  pages = {e0179891},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0179891},
  file = {C\:\\Users\\josue\\Zotero\\storage\\DDAIKGFR\\Epskamp et al. - 2017 - Estimating psychopathological networks Be careful.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {6}
}

@article{epskampEstimating2018,
  title = {Estimating Psychological Networks and Their Accuracy: {{A}} Tutorial Paper},
  shorttitle = {Estimating Psychological Networks and Their Accuracy},
  author = {Epskamp, Sacha and Borsboom, Denny and Fried, Eiko I.},
  year = {2018},
  volume = {50},
  pages = {195--212},
  issn = {1554-3528},
  doi = {10.3758/s13428-017-0862-1},
  abstract = {The usage of psychological networks that conceptualize behavior as a complex interplay of psychological and other components has gained increasing popularity in various research fields. While prior publications have tackled the topics of estimating and interpreting such networks, little work has been conducted to check how accurate (i.e., prone to sampling variation) networks are estimated, and how stable (i.e., interpretation remains similar with less observations) inferences from the network structure (such as centrality indices) are. In this tutorial paper, we aim to introduce the reader to this field and tackle the problem of accuracy under sampling variation. We first introduce the current state-of-the-art of network estimation. Second, we provide a rationale why researchers should investigate the accuracy of psychological networks. Third, we describe how bootstrap routines can be used to (A) assess the accuracy of estimated network connections, (B) investigate the stability of centrality indices, and (C) test whether network connections and centrality estimates for different variables differ from each other. We introduce two novel statistical methods: for (B) the correlation stability coefficient, and for (C) the bootstrapped difference test for edge-weights and centrality indices. We conducted and present simulation studies to assess the performance of both methods. Finally, we developed the free R-package bootnet that allows for estimating psychological networks in a generalized framework in addition to the proposed bootstrap methods. We showcase bootnet in a tutorial, accompanied by R syntax, in which we analyze a dataset of 359 women with posttraumatic stress disorder available online.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\BA8ALQJ3\\Epskamp et al. - 2018 - Estimating psychological networks and their accura.pdf},
  journal = {Behavior Research Methods},
  language = {en},
  number = {1}
}

@article{epskampGaussian2018,
  title = {The {{Gaussian Graphical Model}} in {{Cross}}-{{Sectional}} and {{Time}}-{{Series Data}}},
  author = {Epskamp, Sacha and Waldorp, Lourens J. and M{\~o}ttus, Ren{\'e} and Borsboom, Denny},
  year = {2018},
  volume = {53},
  pages = {453--480},
  issn = {0027-3171, 1532-7906},
  doi = {10.1080/00273171.2018.1454823},
  file = {C\:\\Users\\josue\\Zotero\\storage\\JWCF2Z4R\\Epskamp et al. - 2018 - The Gaussian Graphical Model in Cross-Sectional an.pdf},
  journal = {Multivariate Behavioral Research},
  language = {en},
  number = {4}
}

@article{epskampGeneralized2017,
  title = {Generalized {{Network Psychometrics}}: {{Combining Network}} and {{Latent Variable Models}}},
  shorttitle = {Generalized {{Network Psychometrics}}},
  author = {Epskamp, Sacha and Rhemtulla, Mijke and Borsboom, Denny},
  year = {2017},
  volume = {82},
  pages = {904--927},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-017-9557-x},
  abstract = {We introduce the network model as a formal psychometric model, conceptualizing the covariance between psychometric indicators as resulting from pairwise interactions between observable variables in a network structure. This contrasts with standard psychometric models, in which the covariance between test items arises from the influence of one or more common latent variables. Here, we present two generalizations of the network model that encompass latent variable structures, establishing network modeling as parts of the more general framework of structural equation modeling (SEM). In the first generalization, we model the covariance structure of latent variables as a network. We term this framework latent network modeling (LNM) and show that, with LNM, a unique structure of conditional independence relationships between latent variables can be obtained in an explorative manner. In the second generalization, the residual variance\textendash{}covariance structure of indicators is modeled as a network. We term this generalization residual network modeling (RNM) and show that, within this framework, identifiable models can be obtained in which local independence is structurally violated. These generalizations allow for a general modeling framework that can be used to fit, and compare, SEM models, network models, and the RNM and LNM generalizations. This methodology has been implemented in the free-to-use software package lvnet, which contains confirmatory model testing as well as two exploratory search algorithms: stepwise search algorithms for low-dimensional datasets and penalized maximum likelihood estimation for larger datasets. We show in simulation studies that these search algorithms perform adequately in identifying the structure of the relevant residual or latent networks. We further demonstrate the utility of these generalizations in an empirical example on a personality inventory dataset.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\S2BRN524\\Epskamp et al. - 2017 - Generalized Network Psychometrics Combining Netwo.pdf},
  journal = {Psychometrika},
  language = {en},
  number = {4}
}

@article{epskampNetwork2018,
  title = {Network {{Psychometrics}}},
  author = {Epskamp, Sacha and Maris, Gunter K. J. and Waldorp, Lourens J. and Borsboom, Denny},
  year = {2018},
  abstract = {This chapter provides a general introduction of network modeling in psychometrics. The chapter starts with an introduction to the statistical model formulation of pairwise Markov random fields (PMRF), followed by an introduction of the PMRF suitable for binary data: the Ising model. The Ising model is a model used in ferromagnetism to explain phase transitions in a field of particles. Following the description of the Ising model in statistical physics, the chapter continues to show that the Ising model is closely related to models used in psychometrics. The Ising model can be shown to be equivalent to certain kinds of logistic regression models, loglinear models and multi-dimensional item response theory (MIRT) models. The equivalence between the Ising model and the MIRT model puts standard psychometrics in a new light and leads to a strikingly different interpretation of well-known latent variable models. The chapter gives an overview of methods that can be used to estimate the Ising model, and concludes with a discussion on the interpretation of latent variables given the equivalence between the Ising model and MIRT.},
  archivePrefix = {arXiv},
  eprint = {1609.02818},
  eprinttype = {arxiv},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ZQDWW6NQ\\Epskamp et al. - 2018 - Network Psychometrics.pdf},
  journal = {arXiv:1609.02818 [stat]},
  keywords = {Statistics - Methodology},
  language = {en},
  primaryClass = {stat}
}

@article{epskampPersonalized2018,
  title = {Personalized {{Network Modeling}} in {{Psychopathology}}: {{The Importance}} of {{Contemporaneous}} and {{Temporal Connections}}},
  shorttitle = {Personalized {{Network Modeling}} in {{Psychopathology}}},
  author = {Epskamp, Sacha and {van Borkulo}, Claudia D. and {van der Veen}, Date C. and Servaas, Michelle N. and Isvoranu, Adela-Maria and Riese, Harri{\"e}tte and Cramer, Ang{\'e}lique O. J.},
  year = {2018},
  volume = {6},
  pages = {416--427},
  issn = {2167-7026},
  doi = {10.1177/2167702617744325},
  abstract = {Recent literature has introduced (a) the network perspective to psychology and
(b) collection of time series data to capture symptom fluctuations and other
time varying factors in daily life. Combining these trends allows for the
estimation of intraindividual network structures. We argue that these networks
can be directly applied in clinical research and practice as hypothesis
generating structures. Two networks can be computed: a temporal
network, in which one investigates if symptoms (or other relevant
variables) predict one another over time, and a contemporaneous
network, in which one investigates if symptoms predict one another
in the same window of measurement. The contemporaneous network is a partial
correlation network, which is emerging in the analysis of cross-sectional data
but is not yet utilized in the analysis of time series data. We explain the
importance of partial correlation networks and exemplify the network structures
on time series data of a psychiatric patient.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\UIYEF4QF\\Epskamp et al. - 2018 - Personalized Network Modeling in Psychopathology .pdf},
  journal = {Clinical Psychological Science},
  number = {3},
  pmcid = {PMC5952299},
  pmid = {29805918}
}

@article{epskamptutorial2018,
  title = {A Tutorial on Regularized Partial Correlation Networks.},
  author = {Epskamp, Sacha and Fried, Eiko I.},
  year = {2018},
  volume = {23},
  pages = {617--634},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000167},
  abstract = {Recent years have seen an emergence of network modeling applied to moods, attitudes, and problems in the realm of psychology. In this framework, psychological variables are understood to directly affect each other rather than being caused by an unobserved latent entity. In this tutorial, we introduce the reader to estimating the most popular network model for psychological data: the partial correlation network. We describe how regularization techniques can be used to efficiently estimate a parsimonious and interpretable network structure in psychological data. We show how to perform these analyses in R and demonstrate the method in an empirical example on posttraumatic stress disorder data. In addition, we discuss the effect of the hyperparameter that needs to be manually set by the researcher, how to handle non-normal data, how to determine the required sample size for a network analysis, and provide a checklist with potential solutions for problems that can arise when estimating regularized partial correlation networks.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ZLYSDKSY\\Epskamp and Fried - 2018 - A tutorial on regularized partial correlation netw.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {4}
}

@article{ericksonStriatal2010,
  title = {Striatal {{Volume Predicts Level}} of {{Video Game Skill Acquisition}}},
  author = {Erickson, K. I. and Boot, W. R. and Basak, C. and Neider, M. B. and Prakash, R. S. and Voss, M. W. and Graybiel, A. M. and Simons, D. J. and Fabiani, M. and Gratton, G. and Kramer, A. F.},
  year = {2010},
  volume = {20},
  pages = {2522--2530},
  issn = {1047-3211, 1460-2199},
  doi = {10.1093/cercor/bhp293},
  abstract = {Video game skills transfer to other tasks, but individual differences in performance and in learning and transfer rates make it difficult to identify the source of transfer benefits. We asked whether variability in initial acquisition and of improvement in performance on a demanding video game, the Space Fortress game, could be predicted by variations in the pretraining volume of either of 2 key brain regions implicated in learning and memory: the striatum, implicated in procedural learning and cognitive flexibility, and the hippocampus, implicated in declarative memory. We found that hippocampal volumes did not predict learning improvement but that striatal volumes did. Moreover, for the striatum, the volumes of the dorsal striatum predicted improvement in performance but the volumes of the ventral striatum did not. Both ventral and dorsal striatal volumes predicted early acquisition rates. Furthermore, this early-stage correlation between striatal volumes and learning held regardless of the cognitive flexibility demands of the game versions, whereas the predictive power of the dorsal striatal volumes held selectively for performance improvements in a game version emphasizing cognitive flexibility. These findings suggest a neuroanatomical basis for the superiority of training strategies that promote cognitive flexibility and transfer to untrained tasks.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KLP2WZQG\\Erickson et al. - 2010 - Striatal Volume Predicts Level of Video Game Skill.pdf},
  journal = {Cerebral Cortex},
  language = {en},
  number = {11}
}

@article{etzBayesian2018,
  title = {Bayesian {{Inference}} and {{Testing Any Hypothesis You Can Specify}}},
  author = {Etz, Alexander and Haaf, Julia M and Rouder, Jeffrey N and Vandekerckhove, Joachim},
  year = {2018},
  volume = {1},
  pages = {281--295},
  doi = {10.1177/2515245918773087},
  abstract = {Hypothesis testing is a special form of model selection. Once a pair of competing models is fully defined, their definition immediately leads to a measure of how strongly each model supports the data. The ratio of their support is often called the likelihood ratio or the Bayes factor. Critical in the model-selection endeavor is the specification of the models. In the case of hypothesis testing, it is of the greatest importance that the researcher specify exactly what is meant by a ``null'' hypothesis as well as the alternative to which it is contrasted, and that these are suitable instantiations of theoretical positions. Here, we provide an overview of different instantiations of null and alternative hypotheses that can be useful in practice, but in all cases the inferential procedure is based on the same underlying method of likelihood comparison. An associated app can be found at https://osf.io/mvp53/. This article is the work of the authors and is reformatted from the original, which was published under a CC-By Attribution 4.0 International license and is available at https://psyarxiv.com/wmf3r/.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AW8R6X3U\\Etz et al. - Bayesian Inference and Testing Any Hypothesis You .pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  language = {en},
  number = {2}
}

@article{fanNetwork2009,
  title = {Network Exploration via the Adaptive {{LASSO}} and {{SCAD}} Penalties},
  author = {Fan, Jianqing and Feng, Yang and Wu, Yichao},
  year = {2009},
  volume = {3},
  pages = {521--541},
  issn = {1932-6157},
  doi = {10.1214/08-AOAS215},
  file = {C\:\\Users\\josue\\Zotero\\storage\\2YMEEXIZ\\Fan et al. - 2009 - Network exploration via the adaptive LASSO and SCA.pdf},
  journal = {The Annals of Applied Statistics},
  language = {en},
  number = {2}
}

@book{farawayData1995,
  title = {Data {{Splitting Strategies}} for {{Reducing}} the {{Effect}} of {{Model Selection}} on {{Inference}}},
  author = {Faraway, Julian J.},
  year = {1995},
  abstract = {Using the same data to both select and make inference from a model leads to overoptimistic  predictions. Data splitting has been posited as an attractive alternative  to complex methods of adjusting for the effect of model selection on inference. Data  splitting is widely recommended and used but little-studied. Different strategies are  considered and the "honesty" of the predictions is assessed. Two simple experiments  suggest that data splitting is not effective.  Keywords: Model uncertainty, cross-validation, model building, data mining, prediction, subset selection, Box-Cox model.  1 Introduction  When the same data are used to select both the model and estimate the parameters of that model, there is a danger that the predictions made by that model will be more optimistic than they should be. To expand on this, consider that in many cases a suitable model for the data is not completely known, and various data-analytic techniques will be used to try to find a satisfactory model. Ev...},
  file = {C\:\\Users\\josue\\Zotero\\storage\\PU7HL4MG\\Faraway - 1995 - Data Splitting Strategies for Reducing the Effect .pdf;C\:\\Users\\josue\\Zotero\\storage\\QHX3675B\\summary.html}
}

@article{fisherDistribution1924,
  title = {The {{Distribution}} of the {{Partial Correlation Coefficient}}.},
  shorttitle = {035},
  author = {Fisher, Ronald Aylmer},
  year = {1924},
  volume = {3},
  abstract = {Reproduced with permission of Metron},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ZI46TZ4P\\Fisher - 1924 - 035 The Distribution of the Partial Correlation C.pdf;C\:\\Users\\josue\\Zotero\\storage\\55E2VIHL\\15182.html},
  journal = {Metron},
  language = {en}
}

@article{foldnesHow2015,
  title = {How {{General}} Is the {{Vale}}\textendash{{Maurelli Simulation Approach}}?},
  author = {Foldnes, Nj{\aa}l and Gr{\o}nneberg, Steffen},
  year = {2015},
  volume = {80},
  pages = {1066--1083},
  issn = {1860-0980},
  doi = {10.1007/s11336-014-9414-0},
  abstract = {The Vale\textendash{}Maurelli (VM) approach to generating non-normal multivariate data involves the use of Fleishman polynomials applied to an underlying Gaussian random vector. This method has been extensively used in Monte Carlo studies during the last three decades to investigate the finite-sample performance of estimators under non-Gaussian conditions. The validity of conclusions drawn from these studies clearly depends on the range of distributions obtainable with the VM method. We deduce the distribution and the copula for a vector generated by a generalized VM transformation, and show that it is fundamentally linked to the underlying Gaussian distribution and copula. In the process we derive the distribution of the Fleishman polynomial in full generality. While data generated with the VM approach appears to be highly non-normal, its truly multivariate properties are close to the Gaussian case. A Monte Carlo study illustrates that generating data with a different copula than that implied by the VM approach severely weakens the performance of normal-theory based ML estimates.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\X6DQNIAI\\Foldnes and Grønneberg - 2015 - How General is the Vale–Maurelli Simulation Approa.pdf},
  journal = {Psychometrika},
  keywords = {copula,Monte Carlo,multivariate distributions,simulation,Vale–Maurelli},
  language = {en},
  number = {4}
}

@article{forbesEvidence2017,
  title = {Evidence That Psychopathology Symptom Networks Have Limited Replicability},
  author = {Forbes, Miriam K. and Wright, Aidan G. C. and Markon, Kristian E. and Krueger, Robert F.},
  year = {2017},
  volume = {126},
  pages = {969--988},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1846(Electronic),0021-843X(Print)},
  doi = {10.1037/abn0000276},
  abstract = {Network analysis is quickly gaining popularity in psychopathology research as a method that aims to reveal causal relationships among individual symptoms. To date, 4 main types of psychopathology networks have been proposed: (a) association networks, (b) regularized concentration networks, (c) relative importance networks, and (d) directed acyclic graphs. The authors examined the replicability of these analyses based on symptoms of major depression and generalized anxiety between and within 2 highly similar epidemiological samples (i.e., the National Comorbidity Survey\textemdash{}Replication [n = 9282] and the National Survey of Mental Health and Wellbeing [n = 8841]). Although association networks were stable, the 3 other types of network analysis (i.e., the conditional independence networks) had poor replicability between and within methods and samples. The detailed aspects of the models\textemdash{}such as the estimation of specific edges and the centrality of individual nodes\textemdash{}were particularly unstable. For example, 44\% of the symptoms were estimated as the ``most influential'' on at least 1 centrality index across the 6 conditional independence networks in the full samples, and only 13\textendash{}21\% of the edges were consistently estimated across these networks. One of the likely reasons for the instability of the networks is the predominance of measurement error in the assessment of individual symptoms. The authors discuss the implications of these findings for the growing field of psychopathology network research, and conclude that novel results originating from psychopathology networks should be held to higher standards of evidence before they are ready for dissemination or implementation in the field. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  file = {C\:\\Users\\josue\\Zotero\\storage\\JI5ZNF9X\\2017-49368-012.html},
  journal = {Journal of Abnormal Psychology},
  keywords = {Causality,Experimental Replication,Inference,Psychopathology,Symptoms},
  number = {7}
}

@article{forbesQuantifying2019,
  title = {Quantifying the {{Reliability}} and {{Replicability}} of {{Psychopathology Network Characteristics}}},
  author = {Forbes, Miriam K. and Wright, Aidan G. C. and Markon, Kristian E. and Krueger, Robert F.},
  year = {2019},
  volume = {0},
  pages = {1--19},
  issn = {0027-3171},
  doi = {10.1080/00273171.2019.1616526},
  abstract = {Pairwise Markov random field networks\textemdash{}including Gaussian graphical models (GGMs) and Ising models\textemdash{}have become the ``state-of-the-art'' method for psychopathology network analyses. Recent research has focused on the reliability and replicability of these networks. In the present study, we compared the existing suite of methods for maximizing and quantifying the stability and consistency of PMRF networks (i.e., lasso regularization, plus the bootnet and NetworkComparisonTest packages in R) with a set of metrics for directly comparing the detailed network characteristics interpreted in the literature (e.g., the presence, absence, sign, and strength of each individual edge). We compared GGMs of depression and anxiety symptoms in two waves of data from an observational study (n = 403) and reanalyzed four posttraumatic stress disorder GGMs from a recent study of network replicability. Taken on face value, the existing suite of methods indicated that overall the network edges were stable, interpretable, and consistent between networks, but the direct metrics of replication indicated that this was not the case (e.g., 39\textendash{}49\% of the edges in each network were unreplicated across the pairwise comparisons). We discuss reasons for these apparently contradictory results (e.g., relying on global summary statistics versus examining the detailed characteristics interpreted in the literature) and conclude that the limited reliability of the detailed characteristics of networks observed here is likely to be common in practice, but overlooked by current methods. Poor replicability underpins our concern surrounding the use of these methods, given that generalizable conclusions are fundamental to the utility of their results.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\S8BM5C4B\\Forbes et al. - 2019 - Quantifying the Reliability and Replicability of P.pdf;C\:\\Users\\josue\\Zotero\\storage\\ACMTN6B6\\00273171.2019.html},
  journal = {Multivariate Behavioral Research},
  keywords = {conditional independence,Network analysis,network theory of mental disorders,psychopathology networks,replicability crisis},
  number = {0}
}

@article{fortunatoCommunity2016,
  title = {Community Detection in Networks: {{A}} User Guide},
  shorttitle = {Community Detection in Networks},
  author = {Fortunato, Santo and Hric, Darko},
  year = {2016},
  volume = {659},
  pages = {1--44},
  issn = {0370-1573},
  doi = {10.1016/j.physrep.2016.09.002},
  abstract = {Community detection in networks is one of the most popular topics of modern network science. Communities, or clusters, are usually groups of vertices having higher probability of being connected to each other than to members of other groups, though other patterns are possible. Identifying communities is an ill-defined problem. There are no universal protocols on the fundamental ingredients, like the definition of community itself, nor on other crucial issues, like the validation of algorithms and the comparison of their performances. This has generated a number of confusions and misconceptions, which undermine the progress in the field. We offer a guided tour through the main aspects of the problem. We also point out strengths and weaknesses of popular methods, and give directions to their use.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\K7B6V2HM\\Fortunato and Hric - 2016 - Community detection in networks A user guide.pdf;C\:\\Users\\josue\\Zotero\\storage\\84Y2UWJN\\S0370157316302964.html},
  journal = {Physics Reports},
  keywords = {Clustering,Communities,Networks},
  language = {en},
  series = {Community Detection in Networks: {{A}} User Guide}
}

@incollection{foygelExtended2010,
  title = {Extended {{Bayesian Information Criteria}} for {{Gaussian Graphical Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 23},
  author = {Foygel, Rina and Drton, Mathias},
  editor = {Lafferty, J. D. and Williams, C. K. I. and {Shawe-Taylor}, J. and Zemel, R. S. and Culotta, A.},
  year = {2010},
  pages = {604--612},
  publisher = {{Curran Associates, Inc.}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\36MAVQ6S\\Foygel and Drton - 2010 - Extended Bayesian Information Criteria for Gaussia.pdf;C\:\\Users\\josue\\Zotero\\storage\\S5PRIKNQ\\4087-extended-bayesian-information-criteria-for-gaussian-graphical-models.html}
}

@article{frankFeature2008,
  title = {Feature Selection in Feature Network Models: {{Finding}} Predictive Subsets of Features with the {{Positive Lasso}}},
  shorttitle = {Feature Selection in Feature Network Models},
  author = {Frank, Laurence E. and Heiser, Willem J.},
  year = {2008},
  volume = {61},
  pages = {1--27},
  issn = {2044-8317},
  doi = {10.1348/000711006X119365},
  abstract = {A set of features is the basis for the network representation of proximity data achieved by feature network models (FNMs). Features are binary variables that characterize the objects in an experiment, with some measure of proximity as response variable. Sometimes features are provided by theory and play an important role in the construction of the experimental conditions. In some research settings, the features are not known a priori. This paper shows how to generate features in this situation and how to select an adequate subset of features that takes into account a good compromise between model fit and model complexity, using a new version of least angle regression that restricts coefficients to be non-negative, called the Positive Lasso. It will be shown that features can be generated efficiently with Gray codes that are naturally linked to the FNMs. The model selection strategy makes use of the fact that FNM can be considered as univariate multiple regression model. A simulation study shows that the proposed strategy leads to satisfactory results if the number of objects is less than or equal to 22. If the number of objects is larger than 22, the number of features selected by our method exceeds the true number of features in some conditions.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AT9WVC2W\\Frank and Heiser - 2008 - Feature selection in feature network models Findi.pdf;C\:\\Users\\josue\\Zotero\\storage\\RUVIGD8N\\000711006X119365.html},
  journal = {British Journal of Mathematical and Statistical Psychology},
  language = {en},
  number = {1}
}

@article{friedmanSparse2008,
  title = {Sparse Inverse Covariance Estimation with the Graphical Lasso},
  author = {Friedman, J. and Hastie, T. and Tibshirani, R.},
  year = {2008},
  volume = {9},
  pages = {432--441},
  issn = {1465-4644, 1468-4357},
  doi = {10.1093/biostatistics/kxm045},
  abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm\textemdash{}the graphical lasso\textemdash{}that is remarkably fast: It solves a 1000-node problem ({$\sim$}500 000 parameters) in at most a minute and is 30\textendash{}4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen and Bu\textasciidieresis{}hlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\LLAUNDBE\\Friedman et al. - 2008 - Sparse inverse covariance estimation with the grap.pdf},
  journal = {Biostatistics},
  language = {en},
  number = {3}
}

@article{friedmanUnity2017,
  title = {Unity and {{Diversity}} of {{Executive Functions}}: {{Individual Differences}} as a {{Window}} on {{Cognitive Structure}}},
  shorttitle = {Unity and {{Diversity}} of {{Executive Functions}}},
  author = {Friedman, Naomi P. and Miyake, Akira},
  year = {2017},
  volume = {86},
  pages = {186--204},
  issn = {0010-9452},
  doi = {10.1016/j.cortex.2016.04.023},
  abstract = {Executive functions (EFs) are high-level cognitive processes, often associated with the frontal lobes, that control lower level processes in the service of goal-directed behavior. They include abilities such as response inhibition, interference control, working memory updating, and set shifting. EFs show a general pattern of shared but distinct functions, a pattern described as ``unity and diversity.'' We review studies of EF unity and diversity at the behavioral and genetic levels, focusing on studies of normal individual differences and what they reveal about the functional organization of these cognitive abilities. In particular, we review evidence that across multiple ages and populations, commonly studied EFs (a) are robustly correlated but separable when measured with latent variables; (b) are not the same as general intelligence or g; (c) are highly heritable at the latent level and seemingly also highly polygenic; and (d) activate both common and specific neural areas and can be linked to individual differences in neural activation, volume, and connectivity. We highlight how considering individual differences at the behavioral and neural levels can add considerable insight to the investigation of the functional organization of the brain, and conclude with some key points about individual differences to consider when interpreting neuropsychological patterns of dissociation.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\8RPJ9XUA\\Friedman and Miyake - 2017 - Unity and Diversity of Executive Functions Indivi.pdf},
  journal = {Cortex},
  pmcid = {PMC5104682},
  pmid = {27251123}
}

@article{friedMental2017,
  title = {Mental Disorders as Networks of Problems: A Review of Recent Insights},
  shorttitle = {Mental Disorders as Networks of Problems},
  author = {Fried, Eiko I. and {van Borkulo}, Claudia D. and Cramer, Ang{\'e}lique O. J. and Boschloo, Lynn and Schoevers, Robert A. and Borsboom, Denny},
  year = {2017},
  volume = {52},
  pages = {1--10},
  issn = {0933-7954, 1433-9285},
  doi = {10.1007/s00127-016-1319-z},
  abstract = {Purpose The network perspective on psychopathology understands mental disorders as complex networks of interacting symptoms. Despite its recent debut, with conceptual foundations in 2008 and empirical foundations in 2010, the framework has received considerable attention and recognition in the last years.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AIZAS684\\Fried et al. - 2017 - Mental disorders as networks of problems a review.pdf},
  journal = {Social Psychiatry and Psychiatric Epidemiology},
  language = {en},
  number = {1}
}

@article{friedReplicability2018a,
  ids = {friedReplicability2018},
  title = {Replicability and {{Generalizability}} of {{Posttraumatic Stress Disorder}} ({{PTSD}}) {{Networks}}: {{A Cross}}-{{Cultural Multisite Study}} of {{PTSD Symptoms}} in {{Four Trauma Patient Samples}}},
  shorttitle = {Replicability and {{Generalizability}} of {{Posttraumatic Stress Disorder}} ({{PTSD}}) {{Networks}}},
  author = {Fried, Eiko I. and Eidhof, Marloes B. and Palic, Sabina and Costantini, Giulio and {Huisman-van Dijk}, Hilde M. and Bockting, Claudi L. H. and Engelhard, Iris and Armour, Cherie and Nielsen, Anni B. S. and Karstoft, Karen-Inge},
  year = {2018},
  volume = {6},
  pages = {335--351},
  publisher = {{SAGE Publications Inc}},
  issn = {2167-7026},
  doi = {10.1177/2167702617745092},
  abstract = {The growing literature conceptualizing mental disorders like posttraumatic stress disorder (PTSD) as networks of interacting symptoms faces three key challenges. Prior studies predominantly used (a) small samples with low power for precise estimation, (b) nonclinical samples, and (c) single samples. This renders network structures in clinical data, and the extent to which networks replicate across data sets, unknown. To overcome these limitations, the present cross-cultural multisite study estimated regularized partial correlation networks of 16 PTSD symptoms across four data sets of traumatized patients receiving treatment for PTSD (total N = 2,782). Despite differences in culture, trauma type, and severity of the samples, considerable similarities emerged, with moderate to high correlations between symptom profiles (0.43\textendash{}0.82), network structures (0.62\textendash{}0.74), and centrality estimates (0.63\textendash{}0.75). We discuss the importance of future replicability efforts to improve clinical psychological science and provide code, model output, and correlation matrices to make the results of this article fully reproducible.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\FEATZQZ5\\Fried et al. - 2018 - Replicability and Generalizability of Posttraumati.pdf;C\:\\Users\\josue\\Zotero\\storage\\JIKHHE53\\Fried et al. - 2018 - Replicability and Generalizability of Posttraumati.pdf},
  journal = {Clinical Psychological Science},
  keywords = {generalizability,network modeling,open materials,posttraumatic stress disorder,replicability},
  language = {en},
  number = {3},
  pmcid = {PMC5974702},
  pmid = {29881651}
}

@article{friedWhat2016,
  title = {What Are 'good' Depression Symptoms? {{Comparing}} the Centrality of {{DSM}} and Non-{{DSM}} Symptoms of Depression in a Network Analysis},
  shorttitle = {What Are 'good' Depression Symptoms?},
  author = {Fried, Eiko I. and Epskamp, Sacha and Nesse, Randolph M. and Tuerlinckx, Francis and Borsboom, Denny},
  year = {2016},
  volume = {189},
  pages = {314--320},
  issn = {1573-2517},
  doi = {10.1016/j.jad.2015.09.005},
  abstract = {BACKGROUND: The symptoms for Major Depression (MD) defined in the DSM-5 differ markedly from symptoms assessed in common rating scales, and the empirical question about core depression symptoms is unresolved. Here we conceptualize depression as a complex dynamic system of interacting symptoms to examine what symptoms are most central to driving depressive processes.
METHODS: We constructed a network of 28 depression symptoms assessed via the Inventory of Depressive Symptomatology (IDS-30) in 3,463 depressed outpatients from the Sequenced Treatment Alternatives to Relieve Depression (STAR*D) study. We estimated the centrality of all IDS-30 symptoms, and compared the centrality of DSM and non-DSM symptoms; centrality reflects the connectedness of each symptom with all other symptoms.
RESULTS: A network with 28 intertwined symptoms emerged, and symptoms differed substantially in their centrality values. Both DSM symptoms (e.g., sad mood) and non-DSM symptoms (e.g., anxiety) were among the most central symptoms, and DSM criteria were not more central than non-DSM symptoms.
LIMITATIONS: Many subjects enrolled in STAR*D reported comorbid medical and psychiatric conditions which may have affected symptom presentation.
CONCLUSION: The network perspective neither supports the standard psychometric notion that depression symptoms are equivalent indicators of MD, nor the common assumption that DSM symptoms of depression are of higher clinical relevance than non-DSM depression symptoms. The findings suggest the value of research focusing on especially central symptoms to increase the accuracy of predicting outcomes such as the course of illness, probability of relapse, and treatment response.},
  journal = {Journal of Affective Disorders},
  keywords = {Adult,Centrality,Comorbidity,Depression,Depression symptoms,Depressive Disorder; Major,Diagnostic and Statistical Manual of Mental Disorders,Female,Humans,Major depression,Male,Middle Aged,Network analysis,Psychometrics,Symptom Assessment},
  language = {eng},
  pmid = {26458184}
}

@article{fuentesIntraindividual2001,
  title = {Intraindividual {{Variability}} in {{Cognitive Performance}} in {{Persons With Chronic Fatigue Syndrome}}},
  author = {Fuentes, Karina and Hunter, Michael A. and Strauss, Esther and Hultsch, David F.},
  year = {2001},
  volume = {15},
  pages = {210--227},
  issn = {1385-4046, 1744-4144},
  doi = {10.1076/clin.15.2.210.1896},
  abstract = {Studies of cognitive performance among persons with chronic fatigue syndrome (CFS) have yielded inconsistent results. We sought to contribute to \textregistered{}ndings in this area by examining intraindividual variability as well as level of performance in cognitive functioning. A battery of cognitive measures was administered to 14 CFS patients and 16 healthy individuals on 10 weekly occasions. Analyses comparing the two groups in terms of level of performance de\textregistered{}ned by latency and accuracy scores revealed that the CFS patients were slower but not less accurate than healthy persons. The CFS group showed greater intraindividual variability (as measured by intraindividual standard deviations and coef\textregistered{}cients of variation) than the healthy group, although the results varied by task and time frame. Intraindividual variability was found to be stable across time and correlated across tasks at each testing occasion. Intraindividual variability also uniquely differentiated the groups. The present \textregistered{}ndings support the proposition that intraindividual variability is a meaningful indicator of cognitive functioning in CFS patients.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\TX6GW4IV\\Fuentes et al. - 2001 - Intraindividual Variability in Cognitive Performan.pdf},
  journal = {The Clinical Neuropsychologist},
  language = {en},
  number = {2}
}

@book{galeckiLinear2013,
  title = {Linear {{Mixed}}-{{Effects Models Using R}}},
  author = {Ga{\l}ecki, Andrzej and Burzykowski, Tomasz},
  year = {2013},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-3900-4},
  file = {C\:\\Users\\josue\\Zotero\\storage\\Q3S5VHPG\\Gałecki and Burzykowski - 2013 - Linear Mixed-Effects Models Using R.pdf},
  isbn = {978-1-4614-3899-1 978-1-4614-3900-4},
  series = {Springer {{Texts}} in {{Statistics}}}
}

@article{geiserDistinguishing2015,
  title = {Distinguishing {{State Variability From Trait Change}} in {{Longitudinal Data}}: {{The Role}} of {{Measurement}} ({{Non}}){{Invariance}} in {{Latent State}}-{{Trait Analyses}}},
  shorttitle = {Distinguishing {{State Variability From Trait Change}} in {{Longitudinal Data}}},
  author = {Geiser, Christian and Keller, Brian T. and Lockhart, Ginger and Eid, Michael and Cole, David A. and Koch, Tobias},
  year = {2015},
  volume = {47},
  pages = {172--203},
  issn = {1554-351X},
  doi = {10.3758/s13428-014-0457-z},
  abstract = {Researchers analyzing longitudinal data often want to find out whether the process they study is characterized by (1) short-term state variability, (2) long-term trait change, or (3) a combination of state variability and trait change. Classical latent state-trait (LST) models are designed to measure reversible state variability around a fixed set-point or trait, whereas latent growth curve (LGC) models focus on long-lasting and often irreversible trait changes. In the present paper, we contrast LST and LGC models from the perspective of measurement invariance (MI) testing. We show that establishing a pure state-variability process requires (a) the inclusion of a mean structure and (b) establishing strong factorial invariance in LST analyses. Analytical derivations and simulations demonstrate that LST models with non-invariant parameters can mask the fact that a trait-change or hybrid process has generated the data. Furthermore, the inappropriate application of LST models to trait change or hybrid data can lead to bias in the estimates of consistency and occasion-specificity, which are typically of key interest in LST analyses. Four tips for the proper application of LST models are provided.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ZSN93DDZ\\Geiser et al. - 2015 - Distinguishing State Variability From Trait Change.pdf},
  journal = {Behavior research methods},
  number = {1},
  pmcid = {PMC4170059},
  pmid = {24652650}
}

@article{gelfandBayesian1992,
  title = {Bayesian {{Analysis}} of {{Constrained Parameter}} and {{Truncated Data Problems Using Gibbs Sampling}}},
  author = {Gelfand, Alan E and Smith, Adrian F M and Lee, Tai-Ming},
  year = {1992},
  volume = {87},
  doi = {10.1080/01621459.1992.10475235},
  abstract = {Constrained parameter problems arise in a wide variety of applications, including bioassay, actuarial graduation, ordinal categorical
data, response surfaces, reliability development testing, and variance component models. Truncated data problems arise naturally
in survival and failure time studies, ordinal data models, and categorical data studies aimed at uncovering underlying continuous
distributions. In many applications both parameter constraints and data truncation are present. The statistical literature on such
problems is very extensive, reflecting both the problems' widespread occurrence in applications and the methodological challenges
that they pose. However, it is striking that so little of this applied and theoretical literature involves a parametric Bayesian perspective.
From a technical viewpoint, this perhaps is not difficult to understand. The fundamental tool for Bayesian calculations in typical
realistic models is(multidimensional) numerical integration, which often is problematic in unconstrained contexts and can be wellnigh impossible for the kinds of constrained problems we consider. In this article we show that Bayesiancalculations canbe implemented
routinely for constrained parameter and truncated data problems by means of the Gibbs sampler. Specific models discussed include
constrained multinorrnal parameters, constrained linear model parameters, ordered parameters in experimental family models, data
and order restricted parameters from exponential distributions, straight line regression with censoring and bivariate grouped data
models. Analysis of data sets illustrating the first two of these settings is provided.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KVCG4ISV\\Gelfand et al. - Bayesian Analysis of Constrained Parameter and Tru.pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {418}
}

@article{gelmanBayesian,
  title = {Bayesian {{Data Analysis Third}} Edition (with Errors Fixed as of 13 {{February}} 2020)},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  pages = {677},
  language = {en}
}

@article{gelmanBayesian2006,
  title = {Bayesian {{Measures}} of {{Explained Variance}} and {{Pooling}} in {{Multilevel}} ({{Hierarchical}}) {{Models}}},
  author = {Gelman, Andrew and Pardoe, Iain},
  year = {2006},
  volume = {48},
  pages = {241--251},
  issn = {0040-1706},
  doi = {10.1198/004017005000000517},
  abstract = {Explained variance (R2) is a familiar summary of the fit of a linear regression and has been generalized in various ways to multilevel (hierarchical) models. The multilevel models that we consider in this article are characterized by hierarchical data structures in which individuals are grouped into units (which themselves might be further grouped into larger units), and variables are measured on individuals and each grouping unit. The models are based on regression relationships at different levels, with the first level corresponding to the individual data and subsequent levels corresponding to between-group regressions of individual predictor effects on grouping unit variables. We present an approach to defining R2 at each level of the multilevel model, rather than attempting to create a single summary measure of fit. Our method is based on comparing variances in a single fitted model rather than with a null model. In simple regression, our measure generalizes the classical adjusted R2. We also discuss a related variance comparison to summarize the degree to which estimates at each level of the model are pooled together based on the level-specific regression relationship, rather than estimated separately. This pooling factor is related to the concept of shrinkage in simple hierarchical models. We illustrate the methods on a dataset of radon in houses within counties using a series of models ranging from a simple linear regression model to a multilevel varying-intercept, varying-slope model.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RVZ8VUWE\\Gelman and Pardoe - 2006 - Bayesian Measures of Explained Variance and Poolin.pdf;C\:\\Users\\josue\\Zotero\\storage\\8X4RYGFS\\004017005000000517.html},
  journal = {Technometrics},
  number = {2}
}

@book{gelmanBayesian2014,
  title = {Bayesian {{Data Analysis}}, {{Third Edition}}},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year = {2014},
  file = {C\:\\Users\\josue\\Zotero\\storage\\Z5HUGS8A\\BDA3.pdf},
  language = {en}
}

@book{gelmanData2006,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Hill, Jennifer},
  year = {2006},
  edition = {First},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4ADV6WUW\\Gelman and Hill - 2006 - Data Analysis Using Regression and MultilevelHier.pdf}
}

@article{gelmangarden,
  title = {The Garden of Forking Paths: {{Why}} Multiple Comparisons Can Be a Problem, Even When There Is No ``Fishing Expedition'' or ``p-Hacking'' and the Research Hypothesis Was Posited Ahead of Time},
  author = {Gelman, Andrew and Loken, Eric},
  pages = {17},
  abstract = {Researcher degrees of freedom can lead to a multiple comparisons problem, even in settings where researchers perform only a single analysis on their data. The problem is there can be a large number of potential comparisons when the details of data analysis are highly contingent on data, without the researcher having to perform any conscious procedure of fishing or examining multiple p-values. We discuss in the context of several examples of published papers where data-analysis decisions were theoretically-motivated based on previous literature, but where the details of data selection and analysis were not pre-specified and, as a result, were contingent on data.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\FV8Y49J6\\Gelman and Loken - The garden of forking paths Why multiple comparis.pdf},
  language = {en}
}

@article{gelmanWhy2012,
  title = {Why {{We}} ({{Usually}}) {{Don}}'t {{Have}} to {{Worry About Multiple Comparisons}}},
  author = {Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
  year = {2012},
  volume = {5},
  pages = {189--211},
  issn = {1934-5747, 1934-5739},
  doi = {10.1080/19345747.2011.618213},
  file = {C\:\\Users\\josue\\Zotero\\storage\\YE3ZA5UZ\\Gelman et al. - 2012 - Why We (Usually) Don't Have to Worry About Multipl.pdf},
  journal = {Journal of Research on Educational Effectiveness},
  language = {en},
  number = {2}
}

@article{gerstorfWithinperson2009,
  title = {Within-Person Variability in State Anxiety across Adulthood: {{Magnitude}} and Associations with between-Person Characteristics},
  shorttitle = {Within-Person Variability in State Anxiety across Adulthood},
  author = {Gerstorf, Denis and Siedlecki, Karen L. and {Tucker-Drob}, Elliot M. and Salthouse, Timothy A.},
  year = {2009},
  volume = {33},
  issn = {0165-0254},
  doi = {10.1177/0165025408098013},
  abstract = {Across domains of functioning, research has shown substantial within-person variability in a number of different types of variables from one measurement occasion to another. Using data obtained from a large sample (n = 784, 18\textendash{}97 years) at three separate occasions, we examined properties and correlates of short-term variability in a construct that by definition is prone to fluctuations, namely state anxiety. Our results revealed that participants exhibited sizeable across-occasion variation in state anxiety. The magnitude of variability was unrelated to age, but was associated with a number of individual difference characteristics such as self-reported health, aspects of personality, well-being, and cognition. However, after taking into account mean-level differences in state anxiety, evidence for unique associations of variability was minimal.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\P7S7CZ4T\\Gerstorf et al. - 2009 - Within-person variability in state anxiety across .pdf},
  journal = {International journal of behavioral development},
  number = {1},
  pmcid = {PMC3859617},
  pmid = {24347751}
}

@article{geukesTrait2017,
  title = {Trait Personality and State Variability: {{Predicting}} Individual Differences in within- and Cross-Context Fluctuations in Affect, Self-Evaluations, and Behavior in Everyday Life},
  shorttitle = {Trait Personality and State Variability},
  author = {Geukes, Katharina and Nestler, Steffen and Hutteman, Roos and K{\"u}fner, Albrecht C.P. and Back, Mitja D.},
  year = {2017},
  volume = {69},
  pages = {124--138},
  issn = {00926566},
  doi = {10.1016/j.jrp.2016.06.003},
  abstract = {Prior research on the effects of personality on the variability of states has either not assessed states in real-life contexts or not incorporated meaningful contextual information when analyzing state variability. Providing an integrated contextualized approach, we introduce the Within and Across Context (WAC) Variability framework that disentangles real-life within-person fluctuations occurring within and across real-life contexts. To illustrate the utility of this framework, we investigated effects of Big Five personality traits on the level and the within- and cross-context variability of experience-sampled states (affect, selfesteem, behavior) of psychology freshmen (N = 118). Results provide initial empirical support for the meaningful separation of within- and cross-context variability and their distinct relations to personality. {\'O} 2016 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RIWCLQ5S\\Geukes et al. - 2017 - Trait personality and state variability Predictin.pdf},
  journal = {Journal of Research in Personality},
  language = {en}
}

@article{gigerenzerSurrogate,
  title = {Surrogate {{Science}}},
  author = {Gigerenzer, Gerd and Marewski, Julian N},
  pages = {20},
  file = {C\:\\Users\\josue\\Zotero\\storage\\S2JRAA6G\\Gigerenzer and Marewski - Surrogate Science.pdf},
  language = {en}
}

@book{gillBayesian2015,
  title = {Bayesian {{Methods}}},
  author = {Gill, Jeff},
  year = {2015},
  file = {C\:\\Users\\josue\\Zotero\\storage\\YFGXDLHC\\Gill - Bayesian Methods.pdf},
  language = {en}
}

@article{goekoopNetwork2014,
  title = {A {{Network View}} on {{Psychiatric Disorders}}: {{Network Clusters}} of {{Symptoms}} as {{Elementary Syndromes}} of {{Psychopathology}}},
  shorttitle = {A {{Network View}} on {{Psychiatric Disorders}}},
  author = {Goekoop, Rutger and Goekoop, Jaap G.},
  editor = {Vanneste, Sven},
  year = {2014},
  volume = {9},
  pages = {e112734},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0112734},
  abstract = {Introduction: The vast number of psychopathological syndromes that can be observed in clinical practice can be described in terms of a limited number of elementary syndromes that are differentially expressed. Previous attempts to identify elementary syndromes have shown limitations that have slowed progress in the taxonomy of psychiatric disorders. Aim: To examine the ability of network community detection (NCD) to identify elementary syndromes of psychopathology and move beyond the limitations of current classification methods in psychiatry.
Methods: 192 patients with unselected mental disorders were tested on the Comprehensive Psychopathological Rating Scale (CPRS). Principal component analysis (PCA) was performed on the bootstrapped correlation matrix of symptom scores to extract the principal component structure (PCS). An undirected and weighted network graph was constructed from the same matrix. Network community structure (NCS) was optimized using a previously published technique.
Results: In the optimal network structure, network clusters showed a 89\% match with principal components of psychopathology. Some 6 network clusters were found, including "DEPRESSION", "MANIA", ``ANXIETY'', "PSYCHOSIS", "RETARDATION", and "BEHAVIORAL DISORGANIZATION". Network metrics were used to quantify the continuities between the elementary syndromes.
Conclusion: We present the first comprehensive network graph of psychopathology that is free from the biases of previous classifications: a `Psychopathology Web'. Clusters within this network represent elementary syndromes that are connected via a limited number of bridge symptoms. Many},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VPVESMIU\\Goekoop and Goekoop - 2014 - A Network View on Psychiatric Disorders Network C.pdf},
  journal = {PLoS ONE},
  language = {en},
  number = {11}
}

@article{golinoExploratory2017,
  title = {Exploratory Graph Analysis: {{A}} New Approach for Estimating the Number of Dimensions in Psychological Research},
  shorttitle = {Exploratory Graph Analysis},
  author = {Golino, Hudson F. and Epskamp, Sacha},
  year = {2017},
  volume = {12},
  pages = {e0174035},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0174035},
  abstract = {The estimation of the correct number of dimensions is a long-standing problem in psychometrics. Several methods have been proposed, such as parallel analysis (PA), Kaiser-Guttman's eigenvalue-greater-than-one rule, multiple average partial procedure (MAP), the maximum-likelihood approaches that use fit indexes as BIC and EBIC and the less used and studied approach called very simple structure (VSS). In the present paper a new approach to estimate the number of dimensions will be introduced and compared via simulation to the traditional techniques pointed above. The approach proposed in the current paper is called exploratory graph analysis (EGA), since it is based on the graphical lasso with the regularization parameter specified using EBIC. The number of dimensions is verified using the walktrap, a random walk algorithm used to identify communities in networks. In total, 32,000 data sets were simulated to fit known factor structures, with the data sets varying across different criteria: number of factors (2 and 4), number of items (5 and 10), sample size (100, 500, 1000 and 5000) and correlation between factors (orthogonal, .20, .50 and .70), resulting in 64 different conditions. For each condition, 500 data sets were simulated using lavaan. The result shows that the EGA performs comparable to parallel analysis, EBIC, eBIC and to Kaiser-Guttman rule in a number of situations, especially when the number of factors was two. However, EGA was the only technique able to correctly estimate the number of dimensions in the four-factor structure when the correlation between factors were .7, showing an accuracy of 100\% for a sample size of 5,000 observations. Finally, the EGA was used to estimate the number of factors in a real dataset, in order to compare its performance with the other six techniques tested in the simulation study.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\PBQCRIF7\\Golino and Epskamp - 2017 - Exploratory graph analysis A new approach for est.pdf;C\:\\Users\\josue\\Zotero\\storage\\3QRTN7JZ\\article.html},
  journal = {PLOS ONE},
  keywords = {Covariance,Eigenvalues,Factor analysis,Network analysis,Psychology,Psychometrics,Reasoning,Simulation and modeling},
  language = {en},
  number = {6}
}

@article{gomesWhy2015,
  title = {Why {{Are Children Different}} in {{Their Daily Sedentariness}}? {{An Approach Based}} on the {{Mixed}}-{{Effects Location Scale Model}}},
  shorttitle = {Why {{Are Children Different}} in {{Their Daily Sedentariness}}?},
  author = {Gomes, Thayse Natacha and Hedeker, Donald and dos Santos, Fernanda Karina and Pereira, Sara and Katzmarzyk, Peter T. and Maia, Jos{\'e} A. R.},
  year = {2015},
  volume = {10},
  pages = {e0132192},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0132192},
  abstract = {This study aimed to investigate the between- and within-individual variability in sedentary time over seven days, using a mixed-effects location scale model. The sample comprised 686 Portuguese children (381 girls) aged 9\textendash{}11 years, from 23 schools. Sedentary time was estimated by the Actigraph GT3X+ accelerometer, which was used 24 hours/day for 7 consecutive days; height, sitting height, and weight were measured, BMI was computed (WHO cut-points were used to classify subjects as normal weight or overweight/obese), and maturity offset was estimated. Information regarding the home environment was obtained by questionnaire. Results revealed that (i) children were more sedentary on Friday, but less so on Saturday and Sunday (compared to Monday), with significant variation between- and within-subjects (between-subject variance=0.800, within-subject variance=1.793, intra-subject correlation=0.308); (ii) there is a sex effect on sedentariness, with boys being less sedentary than girls (p{$<$}0.001), and the between-subject variance was 1.48 times larger for boys than girls; (iii) in terms of the within-subject variance, or erraticism, Tuesday, Wednesday and Friday have similar erraticism levels as Monday (Thursday has less, while Saturday and Sunday have more); in addition, girls (variance ratio=0.632, p{$<$}0.001), overweight/obese children (variance ratio=0.861, p=0.019), and those later mature (variance ratio=0.849, p=0.013) have less erraticism than their counterparts; (iv) the within-subject variance varied significantly across subjects (scale std dev=0.342{$\pm$}0.037, p{$<$}0.001); and (v) in the fixed part of the model, only biological maturation was positively related to sedentariness. This study demonstrated that there is significant between- and within-subject variability in sedentariness across a whole week. This implies that a focus on intra-individual variability, instead of only on mean values, would provide relevant information towards a more complete map of children's sedentary behaviour, which can be helpful when developing more efficient strategies to reduce sedentariness.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\CYB6A4MR\\Gomes et al. - 2015 - Why Are Children Different in Their Daily Sedentar.pdf;C\:\\Users\\josue\\Zotero\\storage\\4E88GKQ4\\article.html},
  journal = {PLOS ONE},
  keywords = {Accelerometers,Adolescents,Behavior,Childhood obesity,Children,Physical activity,Portuguese people,Schools},
  language = {en},
  number = {7}
}

@article{guApproximated2018,
  title = {Approximated Adjusted Fractional {{Bayes}} Factors: {{A}} General Method for Testing Informative Hypotheses},
  shorttitle = {Approximated Adjusted Fractional {{Bayes}} Factors},
  author = {Gu, Xin and Mulder, Joris and Hoijtink, Herbert},
  year = {2018},
  volume = {71},
  pages = {229--261},
  issn = {2044-8317},
  doi = {10.1111/bmsp.12110},
  abstract = {Informative hypotheses are increasingly being used in psychological sciences because they adequately capture researchers' theories and expectations. In the Bayesian framework, the evaluation of informative hypotheses often makes use of default Bayes factors such as the fractional Bayes factor. This paper approximates and adjusts the fractional Bayes factor such that it can be used to evaluate informative hypotheses in general statistical models. In the fractional Bayes factor a fraction parameter must be specified which controls the amount of information in the data used for specifying an implicit prior. The remaining fraction is used for testing the informative hypotheses. We discuss different choices of this parameter and present a scheme for setting it. Furthermore, a software package is described which computes the approximated adjusted fractional Bayes factor. Using this software package, psychological researchers can evaluate informative hypotheses by means of Bayes factors in an easy manner. Two empirical examples are used to illustrate the procedure.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\5MU7TQ8X\\Gu et al. - 2018 - Approximated adjusted fractional Bayes factors A .pdf;C\:\\Users\\josue\\Zotero\\storage\\PD5XCIZ6\\bmsp.html},
  journal = {British Journal of Mathematical and Statistical Psychology},
  keywords = {fractional Bayes factor,informative hypothesis,normal approximation,prior sensitivity},
  language = {en},
  number = {2}
}

@article{haafDeveloping2017,
  title = {Developing {{Constraint}} in {{Bayesian Mixed Models}}},
  author = {Haaf, Julia M and Rouder, Jeffrey N},
  year = {2017},
  volume = {22},
  pages = {779--798},
  doi = {10.1037/met0000156},
  abstract = {Model comparison in Bayesian mixed models is becoming popular in psychological science. Here we develop a set of nested models that account for order restrictions across individuals in psychological tasks. An order-restricted model addresses the question ``Does everybody,'' as in ``Does everybody show the usual Stroop effect,'' or ``Does everybody respond more quickly to intense noises than subtle ones?'' The crux of the modeling is the instantiation of 10s or 100s of order restrictions simultaneously, one for each participant. To our knowledge, the problem is intractable in frequentist contexts but relatively straightforward in Bayesian ones. We develop a Bayes factor model-comparison strategy using Zellner and Siow's default g-priors appropriate for assessing whether effects obey equality and order restrictions. We apply the methodology to seven data sets from Stroop, Simon, and Eriksen interference tasks. Not too surprisingly, we find that everybody Stroops\textemdash{}that is, for all people congruent colors are truly named more quickly than incongruent ones. But, perhaps surprisingly, we find these order constraints are violated for some people in the Simon task, that is, for these people spatially incongruent responses occur truly more quickly than congruent ones! Implications of the modeling and conjectures about the task-related differences are discussed.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ESKSDAXW\\Haaf and Rouder - Developing Constraint in Bayesian Mixed Models.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {4}
}

@article{hamraIntegrating2013,
  title = {Integrating {{Informative Priors}} from {{Experimental Research}} with {{Bayesian Methods}}},
  author = {Hamra, Ghassan and Richardson, David and MacLehose, Richard and Wing, Steve},
  year = {2013},
  volume = {24},
  pages = {90--95},
  issn = {1044-3983},
  doi = {10.1097/EDE.0b013e31827623ea},
  abstract = {Informative priors can be a useful tool for epidemiologists to handle problems of sparse data in regression modeling. It is sometimes the case that an investigator is studying a population exposed to two agents, X and Y, where Y is the agent of primary interest. Previous research may suggest that the exposures have different effects on the health outcome of interest, one being more harmful than the other. Such information may be derived from epidemiologic analyses; however, in the case where such evidence is unavailable, knowledge can be drawn from toxicologic studies or other experimental research. Unfortunately, using toxicologic findings to develop informative priors in epidemiologic analyses requires strong assumptions, with no established method for its utilization. We present a method to help bridge the gap between animal and cellular studies and epidemiologic research by specification of an order-constrained prior. We illustrate this approach using an example from radiation epidemiology.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\JPAKCJBW\\Hamra et al. - 2013 - Integrating Informative Priors from Experimental R.pdf},
  journal = {Epidemiology (Cambridge, Mass.)},
  number = {1},
  pmcid = {PMC3607314},
  pmid = {23222512}
}

@book{hardyRegression1993,
  title = {Regression with {{Dummy Variables}}},
  author = {Hardy, Melissa A.},
  year = {1993},
  publisher = {{SAGE}},
  abstract = {It is often necessary for social scientists to study differences in groups, such as gender or race differences in attitudes, buying behavior, or socioeconomic characteristics. When the researcher seeks to estimate group differences through the use of independent variables that are qualitative, dummy variables allow the researcher to represent information about group membership in quantitative terms without imposing unrealistic measurement assumptions on the categorical variables. Beginning with the simplest model, Hardy probes the use of dummy variable regression in increasingly complex specifications, exploring issues such as: interaction, heteroscedasticity, multiple comparisons and significance testing, the use of effects or contrast coding, testing for curvilinearity, and estimating a piecewise linear regression.},
  googlebooks = {EzLffJlYISEC},
  isbn = {978-0-8039-5128-0},
  keywords = {Social Science / Research},
  language = {en}
}

@techreport{haslbeckModeling2019,
  title = {Modeling {{Psychopathology}}: {{From Data Models}} to {{Formal Theories}}},
  shorttitle = {Modeling {{Psychopathology}}},
  author = {Haslbeck, Jonas M B and Ryan, Ois{\'i}n and Robinaugh, Donald and Waldorp, Lourens and Borsboom, Denny},
  year = {2019},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/jgm7f},
  abstract = {Over the past decade there has been a surge of empirical research investigating mental disorders as complex systems. In this paper, we investigate how to best make use of this growing body of empirical research and move the field toward its fundamental aims of explaining, predicting, and controlling psychopathology. We first review the contemporary philosophy of science literature on scientific theories and argue that fully achieving the aims of explanation, prediction, and control requires that we construct formal theories of mental disorders: theories expressed in the language of mathematics or a computational programming language. We then investigate three routes by which one can use empirical findings (i.e., data models) to construct formal theories: (a) using data models themselves as formal theories, (b) using data models to infer formal theories, and (c) comparing empirical data models to theory-implied data models in order to evaluate and refine an existing formal theory. We argue that the third approach is the most promising path forward and conclude by expanding on this approach, proposing a framework for theory construction that details how to best use empirical research to generate, develop, and test formal theories of mental disorders.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\LLFXLMJ3\\Haslbeck et al. - 2019 - Modeling Psychopathology From Data Models to Form.pdf},
  language = {en},
  type = {Preprint}
}

@book{hastieElements2017,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2017},
  file = {C\:\\Users\\josue\\Zotero\\storage\\N72JP764\\Tibshirani and Friedman - Valerie and Patrick Hastie.pdf},
  language = {en}
}

@book{hastieStatistical2015,
  title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
  author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
  year = {2015},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Hastie, T., Tibshirani, R., \& Wainwright, M. (2015). . .},
  file = {C\:\\Users\\josue\\Zotero\\storage\\227GBFAD\\Tibshirani and Wainwright - Valerie and Patrick Hastie.pdf},
  language = {en}
}

@article{hawkinsProblem2004,
  title = {The {{Problem}} of {{Overfitting}}},
  author = {Hawkins, Douglas M.},
  year = {2004},
  volume = {44},
  pages = {1--12},
  issn = {0095-2338},
  doi = {10.1021/ci0342472},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KWRNG3SX\\Hawkins - 2004 - The Problem of Overfitting.pdf},
  journal = {Journal of Chemical Information and Computer Sciences},
  language = {en},
  number = {1}
}

@article{heckcaveat2019,
  title = {A Caveat on the {{Savage}}\textendash{{Dickey}} Density Ratio: {{The}} Case of Computing {{Bayes}} Factors for Regression Parameters},
  shorttitle = {A Caveat on the {{Savage}}\textendash{{Dickey}} Density Ratio},
  author = {Heck, Daniel W.},
  year = {2019},
  volume = {72},
  pages = {316--333},
  issn = {2044-8317},
  doi = {10.1111/bmsp.12150},
  abstract = {The Savage\textendash{}Dickey density ratio is a simple method for computing the Bayes factor for an equality constraint on one or more parameters of a statistical model. In regression analysis, this includes the important scenario of testing whether one or more of the covariates have an effect on the dependent variable. However, the Savage\textendash{}Dickey ratio only provides the correct Bayes factor if the prior distribution of the nuisance parameters under the nested model is identical to the conditional prior under the full model given the equality constraint. This condition is violated for multiple regression models with a Jeffreys\textendash{}Zellner\textendash{}Siow prior, which is often used as a default prior in psychology. Besides linear regression models, the limitation of the Savage\textendash{}Dickey ratio is especially relevant when analytical solutions for the Bayes factor are not available. This is the case for generalized linear models, non-linear models, or cognitive process models with regression extensions. As a remedy, the correct Bayes factor can be computed using a generalized version of the Savage\textendash{}Dickey density ratio.},
  copyright = {\textcopyright{} 2018 The British Psychological Society},
  file = {C\:\\Users\\josue\\Zotero\\storage\\84U3JSZI\\Heck - 2019 - A caveat on the Savage–Dickey density ratio The c.pdf;C\:\\Users\\josue\\Zotero\\storage\\8YS6PBEG\\bmsp.html},
  journal = {British Journal of Mathematical and Statistical Psychology},
  keywords = {Bayesian model selection,general linear model,Hypothesis test,Jeffreys–Zellner–Siow prior,marginal likelihood,variable selection},
  language = {en},
  number = {2}
}

@article{heckMultinomial2019,
  title = {Multinomial {{Models}} with {{Linear Inequality Constraints}}: {{Overview}} and {{Improvements}} of {{Computational Methods}} for {{Bayesian Inference}}},
  shorttitle = {Multinomial {{Models}} with {{Linear Inequality Constraints}}},
  author = {Heck, Daniel W. and {Davis-Stober}, Clintin P.},
  year = {2019},
  volume = {91},
  pages = {70--87},
  issn = {00222496},
  doi = {10.1016/j.jmp.2019.03.004},
  abstract = {Many psychological theories can be operationalized as linear inequality constraints on the parameters of multinomial distributions (e.g., discrete choice analysis). These constraints can be described in two equivalent ways: Either as the solution set to a system of linear inequalities or as the convex hull of a set of extremal points (vertices). For both representations, we describe a general Gibbs sampler for drawing posterior samples in order to carry out Bayesian analyses. We also summarize alternative sampling methods for estimating Bayes factors for these model representations using the encompassing Bayes factor method. We introduce the R package multinomineq, which provides an easily-accessible interface to a computationally efficient implementation of these techniques.},
  archivePrefix = {arXiv},
  eprint = {1808.07140},
  eprinttype = {arxiv},
  file = {C\:\\Users\\josue\\Zotero\\storage\\7283WM5Y\\Heck and Davis-Stober - 2019 - Multinomial Models with Linear Inequality Constrai.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Statistics - Computation,Statistics - Methodology},
  language = {en}
}

@article{hedekerApplication2008,
  title = {An {{Application}} of a {{Mixed}}-{{Effects Location Scale Model}} for {{Analysis}} of {{Ecological Momentary Assessment}} ({{EMA}}) {{Data}}},
  author = {Hedeker, Donald and Mermelstein, Robin J. and Demirtas, Hakan},
  year = {2008},
  volume = {64},
  pages = {627--634},
  issn = {0006341X},
  doi = {10.1111/j.1541-0420.2007.00924.x},
  abstract = {For longitudinal data, mixed models include random subject effects to indicate how subjects influence their responses over repeated assessments. The error variance and the variance of the random effects are usually considered to be homogeneous. These variance terms characterize the within-subjects (i.e., error variance) and between-subjects (i.e., random-effects variance) variation in the data. In studies using ecological momentary assessment (EMA), up to 30 or 40 observations are often obtained for each subject, and interest frequently centers around changes in the variances, both within and between subjects. In this article, we focus on an adolescent smoking study using EMA where interest is on characterizing changes in mood variation. We describe how covariates can influence the mood variances, and also extend the standard mixed model by adding a subject-level random effect to the within-subject variance specification. This permits subjects to have influence on the mean, or location, and variability, or (square of the) scale, of their mood responses. Additionally, we allow the location and scale random effects to be correlated. These mixed-effects location scale models have useful applications in many research areas where interest centers on the joint modeling of the mean and variance structure.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\65Z93X2P\\Hedeker et al. - 2008 - An Application of a Mixed-Effects Location Scale M.pdf},
  journal = {Biometrics},
  language = {en},
  number = {2}
}

@article{hedekerMixedEffects,
  title = {Mixed-{{Effects Regression Models}} with {{Heterogeneous Variance}}: {{Analyzing Ecological Momentary Assessment}} ({{EMA}}) {{Data}} of {{Smoking}}},
  author = {Hedeker, Donald and Mermelstein, Robin J},
  pages = {23},
  file = {C\:\\Users\\josue\\Zotero\\storage\\LF6Z3C7F\\Hedeker and Mermelstein - Mixed-Eﬀects Regression Models with Heterogeneous .pdf},
  language = {en}
}

@article{hedekermixedeffects2016,
  title = {A Mixed-Effects Location-Scale Model for Ordinal Questionnaire Data},
  author = {Hedeker, Donald and Mermelstein, Robin J. and Demirtas, Hakan and Berbaum, Michael L.},
  year = {2016},
  volume = {16},
  pages = {117--131},
  issn = {1387-3741, 1572-9400},
  doi = {10.1007/s10742-016-0145-9},
  abstract = {In health studies, questionnaire items are often scored on an ordinal scale, for example on a Likert scale. For such questionnaires, item response theory (IRT) models provide a useful approach for obtaining summary scores for subjects (i.e., the model's random subject effect) and characteristics of the items (e.g., item difficulty and discrimination). In this article, we describe a model that allows the items to additionally exhibit different within-subject variance, and also includes a subject-level random effect to the within-subject variance specification. This permits subjects to be characterized in terms of their mean level, or location, and their variability, or scale, and the model allows item difficulty and discrimination in terms of both random subject effects (location and scale). We illustrate application of this location-scale mixed model using data from the Social Subscale of the Drinking Motives Questionnaire assessed in an adolescent study. We show that the proposed model fits the data significantly better than simpler IRT models, and is able to identify items and subjects that are not well-fit by the simpler models. The proposed model has useful applications in many areas where questionnaires are often rated on an ordinal scale, and there is interest in characterizing subjects in terms of both their mean and variability.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\8ZKFBX7T\\Hedeker et al. - 2016 - A mixed-effects location-scale model for ordinal q.pdf},
  journal = {Health Services and Outcomes Research Methodology},
  language = {en},
  number = {3}
}

@article{hedekerMIXREGLS2013,
  title = {{{MIXREGLS}}: {{A Program}} for {{Mixed}}-{{Effects Location Scale Analysis}}},
  shorttitle = {{{MIXREGLS}}},
  author = {Hedeker, Donald and Nordgren, Rachel},
  year = {2013},
  volume = {52},
  pages = {1--38},
  issn = {1548-7660},
  abstract = {MIXREGLS is a program which provides estimates for a mixed-effects location scale model assuming a (conditionally) normally-distributed dependent variable. This model can be used for analysis of data in which subjects may be measured at many observations and interest is in modeling the mean and variance structure. In terms of the variance structure, covariates can by specified to have effects on both the between-subject and within-subject variances. Another use is for clustered data in which subjects are nested within clusters (e.g., clinics, hospitals, schools, etc.) and interest is in modeling the between-cluster and within-cluster variances in terms of covariates. MIXREGLS was written in Fortran and uses maximum likelihood estimation, utilizing both the EM algorithm and a Newton-Raphson solution. Estimation of the random effects is accomplished using empirical Bayes methods. Examples illustrating stand-alone usage and features of MIXREGLS are provided, as well as use via the SAS and R software packages.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\F6BU8DLK\\Hedeker and Nordgren - 2013 - MIXREGLS A Program for Mixed-Effects Location Sca.pdf},
  journal = {Journal of statistical software},
  number = {12},
  pmcid = {PMC3676904},
  pmid = {23761062}
}

@article{hedekerModeling2012,
  title = {Modeling Between-Subject and within-Subject Variances in Ecological Momentary Assessment Data Using Mixed-Effects Location Scale Models},
  author = {Hedeker, Donald and Mermelstein, Robin J. and Demirtas, Hakan},
  year = {2012},
  volume = {31},
  pages = {3328--3336},
  issn = {02776715},
  doi = {10.1002/sim.5338},
  file = {C\:\\Users\\josue\\Zotero\\storage\\M54P64YU\\Hedeker et al. - 2012 - Modeling between-subject and within-subject varian.pdf},
  journal = {Statistics in Medicine},
  language = {en},
  number = {27}
}

@book{hefferonLinear,
  title = {Linear {{Algebra}}},
  author = {Hefferon, Jim},
  edition = {Third},
  file = {C\:\\Users\\josue\\Zotero\\storage\\BVUA9BI9\\linear_algebra_hefferon.pdf}
}

@book{hofffirst2009,
  title = {A First Course in {{Bayesian}} Statistical Methods},
  author = {Hoff, Peter D.},
  year = {2009},
  publisher = {{Springer}},
  address = {{London ; New York}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\S9VFNZRC\\Hoff - 2009 - A first course in Bayesian statistical methods.pdf},
  isbn = {978-0-387-92299-7 978-0-387-92407-6},
  keywords = {Bayes-Verfahren,Bayesian statistical decision theory,Methode van Bayes,Social sciences,Statistical methods,Statistique bayésienne},
  language = {en},
  lccn = {QA279.5 .H64 2009},
  note = {OCLC: ocn310401109},
  series = {Springer Texts in Statistics}
}

@article{hoffmanNoUTurn2011,
  title = {The {{No}}-{{U}}-{{Turn Sampler}}: {{Adaptively Setting Path Lengths}} in {{Hamiltonian Monte Carlo}}},
  shorttitle = {The {{No}}-{{U}}-{{Turn Sampler}}},
  author = {Hoffman, Matthew D. and Gelman, Andrew},
  year = {2011},
  abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size \{\textbackslash{}epsilon\} and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS perform at least as efficiently as and sometimes more efficiently than a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter \{\textbackslash{}epsilon\} on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all. NUTS is also suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" sampling algorithms.},
  archivePrefix = {arXiv},
  eprint = {1111.4246},
  eprinttype = {arxiv},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RM9IRL7J\\Hoffman and Gelman - 2011 - The No-U-Turn Sampler Adaptively Setting Path Len.pdf;C\:\\Users\\josue\\Zotero\\storage\\X59XW2FK\\1111.html},
  journal = {arXiv:1111.4246 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Computation},
  primaryClass = {cs, stat}
}

@article{hoffmanPersons2009,
  title = {Persons as {{Contexts}}: {{Evaluating Between}}-{{Person}} and {{Within}}-{{Person Effects}} in {{Longitudinal Analysis}}},
  shorttitle = {Persons as {{Contexts}}},
  author = {Hoffman, Lesa and Stawski, Robert S.},
  year = {2009},
  volume = {6},
  pages = {97--120},
  issn = {1542-7609, 1542-7617},
  doi = {10.1080/15427600902911189},
  file = {C\:\\Users\\josue\\Zotero\\storage\\7D6ENCGU\\Hoffman and Stawski - 2009 - Persons as Contexts Evaluating Between-Person and.pdf},
  journal = {Research in Human Development},
  language = {en},
  number = {2-3}
}

@book{hoijtinkBayesian2008,
  title = {Bayesian {{Evaluation}} of {{Informative Hypotheses}}},
  editor = {Hoijtink, Herbert},
  year = {2008},
  edition = {1. ed},
  publisher = {{Springer}},
  address = {{Berlin}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\WN3GAXGA\\Hoijtink - 2008 - Bayesian Evaluation of Informative Hypotheses.pdf},
  isbn = {978-0-387-09611-7},
  language = {en},
  note = {OCLC: 845382939},
  series = {Statistics for {{Social}} and {{Behavioral Sciences}}}
}

@article{hoijtinkConfirmatory2001,
  title = {Confirmatory {{Latent Class Analysis}}: {{Model Selection Using Bayes Factors}} and ({{Pseudo}}) {{Likelihood Ratio Statistics}}},
  shorttitle = {Confirmatory {{Latent Class Analysis}}},
  author = {Hoijtink, Herbert},
  year = {2001},
  volume = {36},
  pages = {563--588},
  issn = {0027-3171, 1532-7906},
  doi = {10.1207/S15327906MBR3604_04},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4S7HCHGQ\\Hoijtink - 2001 - Confirmatory Latent Class Analysis Model Selectio.pdf},
  journal = {Multivariate Behavioral Research},
  language = {en},
  number = {4}
}

@book{hoijtinkInformative2011,
  title = {Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists},
  shorttitle = {Informative Hypotheses},
  author = {Hoijtink, Herbert},
  year = {2011},
  publisher = {{CRC}},
  address = {{Boca Raton}},
  isbn = {978-1-4398-8051-7},
  keywords = {Hypothesis,MATHEMATICS / Probability \& Statistics / General,Psychology,Social sciences,Statistical methods},
  lccn = {BF39 .H625 2012},
  series = {Chapman \& {{Hall}}/{{CRC}} Statistics in the Social and Behavioral Sciences Series}
}

@article{hoijtinktutorial2019,
  title = {A Tutorial on Testing Hypotheses Using the {{Bayes}} Factor},
  author = {Hoijtink, Herbert and Mulder, Joris and {van Lissa}, Caspar and Gu, Xin},
  year = {2019},
  volume = {24},
  pages = {539--556},
  issn = {1082-989X},
  doi = {http://dx.doi.org/10.1037/met0000201},
  abstract = {Learning about hypothesis evaluation using the Bayes factor could enhance psychological research. In contrast to null-hypothesis significance testing it renders the evidence in favor of each of the hypotheses under consideration (it can be used to quantify support for the null-hypothesis) instead of a dichotomous reject/do-not-reject decision; it can straightforwardly be used for the evaluation of multiple hypotheses without having to bother about the proper manner to account for multiple testing; and it allows continuous reevaluation of hypotheses after additional data have been collected (Bayesian updating). This tutorial addresses researchers considering to evaluate their hypotheses by means of the Bayes factor. The focus is completely applied and each topic discussed is illustrated using Bayes factors for the evaluation of hypotheses in the context of an ANOVA model, obtained using the R package bain. Readers can execute all the analyses presented while reading this tutorial if they download bain and the R-codes used. It will be elaborated in a completely nontechnical manner: what the Bayes factor is, how it can be obtained, how Bayes factors should be interpreted, and what can be done with Bayes factors. After reading this tutorial and executing the associated code, researchers will be able to use their own data for the evaluation of hypotheses by means of the Bayes factor, not only in the context of ANOVA models, but also in the context of other statistical models. (PsycINFO Database Record (c) 2019 APA, all rights reserved) (Source: journal abstract)
Translational Abstract\textemdash{}Learning about hypothesis evaluation using the Bayes factor could enhance psychological research. The Bayes factor quantifies the support in the data for two competing hypotheses. These may be the traditional null and alternative hypotheses, but these may also be informative hypotheses like m1 \&gt; m2 \&gt; m3 and (m1 - m2) \&gt; (m2 - m3) where m1, m2, and m3 denote the means in three experimental groups. Bayesian hypotheses evaluation offers options such as quantifying evidence in favor of the null-hypothesis, simultaneous evaluation of multiple hypotheses, and Bayesian updating, that is, recomputation of the Bayes factor after additional data have been collected. In this tutorial it is elaborated how researchers can use the Bayes factor for the analysis of their own data. The focus is completely applied and each topic discussed is illustrated using Bayes factors for the evaluation of hypotheses in the context of an ANOVA model, obtained using the R package bain. Readers can execute all the analyses presented while reading this tutorial if they download bain and the R-codes used from the bain website. It will be elaborated in a completely nontechnical manner: what the Bayes factor is, how it can be obtained, how Bayes factors should be interpreted, and what can be done with Bayes factors. After reading this tutorial and executing the associated code, researchers will be able to use their own data for the evaluation of hypotheses by means of the Bayes factor, not only in the context of ANOVA models, but also in the context of other statistical models. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  copyright = {\textcopyright{} 2019, American Psychological Association},
  file = {C\:\\Users\\josue\\Zotero\\storage\\8FJX3CXD\\Hoijtink et al. - 2019 - A tutorial on testing hypotheses using the Bayes f.pdf},
  journal = {Psychological Methods},
  keywords = {bain,Bayes Factor,Bayesian error probabilities,Empirical Study,informative hypotheses,Mathematical Model,posterior probabilities},
  language = {English},
  number = {5}
}

@book{hojsgaardGraphical2012,
  title = {Graphical {{Models}} with {{R}}},
  author = {H{\o}jsgaard, S{\o}ren and Edwards, David and Lauritzen, Steffen},
  year = {2012},
  publisher = {{Springer Science \& Business Media}},
  abstract = {Graphical models in their modern form have been around since the late 1970s and appear today in many areas of the sciences. Along with the ongoing developments of graphical models, a number of different graphical modeling software programs have been written over the years. In recent years many of these software developments have taken place within the R community, either in the form of new packages or by providing an R interface to existing software. This book attempts to give the reader a gentle introduction to graphical modeling using R and the main features of some of these packages. In addition, the book provides examples of how more advanced aspects of graphical modeling can be represented and handled within R. Topics covered in the seven chapters include graphical models for contingency tables, Gaussian and mixed graphical models, Bayesian networks and modeling high dimensional data.},
  googlebooks = {em5QdpWmljAC},
  isbn = {978-1-4614-2298-3},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes},
  language = {en}
}

@article{hoorelbekeinterplay2016,
  title = {The Interplay between Cognitive Risk and Resilience Factors in Remitted Depression: {{A}} Network Analysis},
  shorttitle = {The Interplay between Cognitive Risk and Resilience Factors in Remitted Depression},
  author = {Hoorelbeke, Kristof and Marchetti, Igor and De Schryver, Maarten and Koster, Ernst H. W.},
  year = {2016},
  volume = {195},
  pages = {96--104},
  issn = {0165-0327},
  doi = {10.1016/j.jad.2016.02.001},
  abstract = {Background
Individuals in remission from depression are at increased risk for developing future depressive episodes. Several cognitive risk- and resilience factors have been suggested to account for this vulnerability. In the current study we explored how risk- and protective factors such as cognitive control, adaptive and maladaptive emotion regulation, residual symptomatology, and resilience relate to one another in a remitted depressed (RMD) sample.
Methods
We examined the relationships between these constructs in a cross-sectional dataset of 69 RMD patients using network analyses in order to obtain a comprehensive, data-driven view on the interplay between these constructs. We subsequently present an association network, a concentration network, and a relative importance network.
Results
In all three networks resilience formed the central hub, connecting perceived cognitive control (i.e., working memory complaints), emotion regulation, and residual symptomatology. The contribution of the behavioral measure for cognitive control in the network was negligible. Moreover, the directed relative importance network indicates bidirectional influences between these constructs, with all indicators of centrality suggesting a key role of resilience in remission from depression.
Limitations
The presented findings are cross-sectional and networks are limited to a fixed set of key constructs in the literature pertaining cognitive vulnerability for depression.
Conclusions
These findings indicate the importance of resilience to successfully cope with stressors following remission from depression. Further in-depth studies will be essential to identify the specific underlying resilience mechanisms that may be key to successful remission from depression.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KSA8W69E\\Hoorelbeke et al. - 2016 - The interplay between cognitive risk and resilienc.pdf;C\:\\Users\\josue\\Zotero\\storage\\BKSCGV56\\S0165032715313252.html},
  journal = {Journal of Affective Disorders},
  keywords = {Cognitive control,Depression,Network,Remission,Resilience,Vulnerability},
  language = {en}
}

@article{hornRefinement1966,
  title = {Refinement and Test of the Theory of Fluid and Crystallized General Intelligences},
  author = {Horn, John L. and Cattell, Raymond B.},
  year = {1966},
  volume = {57},
  pages = {253--270},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-2176(Electronic),0022-0663(Print)},
  doi = {10.1037/h0023816},
  abstract = {The 23 factors previously identified as representing primary mental abilities and 8 factors previously defined as general personality dimensions were factored, using a sample of 297 adults, to provide evidence for hypotheses stipulating that general visualization, fluency, and speediness functions, as well as fluid and crystallized intelligence functions, are involved in the performances commonly said to indicate intelligence. 9 principal axes factors were sufficient to account for the observed, generally positive, intercorrelations among the 31 primary factors. These were rotated blindly to oblique simple structure. The resulting structure was consistent with predictions based upon refinements of the general theory of fluid and crystallized intelligence. Positive manifold for the intercorrelations among the 2nd-order factors was interpreted as indicating a social fact of interdependence between intraperson and environmental influences determining behavioral attributes. (30 ref.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C\:\\Users\\josue\\Zotero\\storage\\EXI6LWDK\\1966-13188-001.html},
  journal = {Journal of Educational Psychology},
  keywords = {Cognitive Ability,Intelligence},
  number = {5}
}

@article{hunterPicking,
  title = {Picking {{Winners Using Integer Programming}}},
  author = {Hunter, David Scott and Vielma, Juan Pablo and Zaman, Tauhid},
  pages = {37},
  abstract = {We consider the problem of selecting a portfolio of entries of fixed cardinality for a winner take all contest such that the probability of at least one entry winning is maximized. This framework is very general and can be used to model a variety of problems, such as movie studios selecting movies to produce, drug companies choosing drugs to develop, or venture capital firms picking start-up companies in which to invest. We model this as a combinatorial optimization problem with a submodular objective function, which is the probability of winning. We then show that the objective function can be approximated using only pairwise marginal probabilities of the entries winning when there is a certain structure on their joint distribution. We consider a model where the entries are jointly Gaussian random variables and present a closed form approximation to the objective function. We then consider a model where the entries are given by sums of constrained resources and present a greedy integer programming formulation to construct the entries. Our formulation uses three principles to construct entries: maximize the expected score of an entry, lower bound its variance, and upper bound its correlation with previously constructed entries. To demonstrate the effectiveness of our greedy integer programming formulation, we apply it to daily fantasy sports contests that have top heavy payoff structures (i.e. most of the winnings go to the top ranked entries). We find that the entries produced by our approach perform well in practice and are even able to come in first place in contests with thousands of entries. Our approach can easily be extended to other problems with a winner take all type of payoff structure.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\N6DGAEL5\\Hunter et al. - Picking Winners Using Integer Programming.pdf},
  language = {en}
}

@article{ibrahimFixed2011,
  title = {Fixed and {{Random Effects Selection}} in {{Mixed Effects Models}}},
  author = {Ibrahim, Joseph G. and Zhu, Hongtu and Garcia, Ramon I. and Guo, Ruixin},
  year = {2011},
  volume = {67},
  pages = {495--503},
  issn = {1541-0420},
  doi = {10.1111/j.1541-0420.2010.01463.x},
  abstract = {We consider selecting both fixed and random effects in a general class of mixed effects models using maximum penalized likelihood (MPL) estimation along with the smoothly clipped absolute deviation (SCAD) and adaptive least absolute shrinkage and selection operator (ALASSO) penalty functions. The MPL estimates are shown to possess consistency and sparsity properties and asymptotic normality. A model selection criterion, called the ICQ statistic, is proposed for selecting the penalty parameters (Ibrahim, Zhu, and Tang, 2008, Journal of the American Statistical Association 103, 1648\textendash{}1658). The variable selection procedure based on ICQ is shown to consistently select important fixed and random effects. The methodology is very general and can be applied to numerous situations involving random effects, including generalized linear mixed models. Simulation studies and a real data set from a Yale infant growth study are used to illustrate the proposed methodology.},
  copyright = {\textcopyright{} 2010, The International Biometric Society},
  file = {C\:\\Users\\josue\\Zotero\\storage\\Z7PVP3JX\\Ibrahim et al. - 2011 - Fixed and Random Effects Selection in Mixed Effect.pdf;C\:\\Users\\josue\\Zotero\\storage\\BD8X7RWT\\j.1541-0420.2010.01463.html},
  journal = {Biometrics},
  keywords = {ALASSO,Cholesky decomposition,EM algorithm,ICQ criterion,Mixed effects selection,Penalized likelihood,SCAD},
  language = {en},
  number = {2}
}

@article{ioannidisWhy2005,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  year = {2005},
  volume = {2},
  issn = {1549-1277},
  doi = {10.1371/journal.pmed.0020124},
  abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research., Published research findings are sometimes refuted by subsequent evidence, says Ioannidis, with ensuing confusion and disappointment.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\PWMGCQ6M\\Ioannidis - 2005 - Why Most Published Research Findings Are False.pdf},
  journal = {PLoS Medicine},
  number = {8},
  pmcid = {PMC1182327},
  pmid = {16060722}
}

@article{isvoranuNetwork2017,
  title = {A {{Network Approach}} to {{Psychosis}}: {{Pathways Between Childhood Trauma}} and {{Psychotic Symptoms}}},
  shorttitle = {A {{Network Approach}} to {{Psychosis}}},
  author = {Isvoranu, Adela-Maria and {van Borkulo}, Claudia D. and Boyette, Lindy-Lou and Wigman, Johanna T. W. and Vinkers, Christiaan H. and Borsboom, Denny and {Group Investigators}},
  year = {2017},
  volume = {43},
  pages = {187--196},
  issn = {0586-7614, 1745-1701},
  doi = {10.1093/schbul/sbw055},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4AN9QAW8\\Isvoranu et al. - 2017 - A Network Approach to Psychosis Pathways Between .pdf},
  journal = {Schizophrenia Bulletin},
  language = {en},
  number = {1}
}

@article{jacobucciRegularized2016,
  title = {Regularized {{Structural Equation Modeling}}},
  author = {Jacobucci, Ross and Grimm, Kevin J. and McArdle, John J.},
  year = {2016},
  volume = {23},
  pages = {555--566},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2016.1154793},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HRFJWN2S\\Jacobucci et al. - 2016 - Regularized Structural Equation Modeling.pdf},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  language = {en},
  number = {4}
}

@book{jamesIntroduction2013,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2013},
  volume = {103},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-7138-7},
  file = {C\:\\Users\\josue\\Zotero\\storage\\X5WYBE28\\James et al. - 2013 - An Introduction to Statistical Learning.pdf},
  isbn = {978-1-4614-7137-0 978-1-4614-7138-7},
  language = {en},
  series = {Springer {{Texts}} in {{Statistics}}}
}

@book{jeffreysTheory1961,
  title = {Theory of {{Probability}}},
  author = {Jeffreys, Harold},
  year = {1961},
  edition = {Third Edition},
  publisher = {{Oxford University Press}},
  address = {{Oxford, New York}},
  abstract = {Jeffreys' Theory of Probability, first published in 1939, was the first attempt to develop a fundamental theory of scientific inference based on Bayesian statistics. His ideas were well ahead of their time and it is only in the past ten years that the subject of Bayes' factors has been significantly developed and extended. Recent work has made Bayesian statistics an essential subject for graduate students and researchers. This seminal book is their starting point.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\Y9QFCEPC\\theory-of-probability-9780198503682.html},
  isbn = {978-0-19-850368-2},
  series = {Oxford {{Classic Texts}} in the {{Physical Sciences}}}
}

@article{jerniganAdolescent2018,
  title = {The {{Adolescent Brain Cognitive Development Study}}},
  author = {Jernigan, T. L. and Brown, S. A. and Dowling, G. J.},
  year = {2018},
  volume = {28},
  pages = {154--156},
  issn = {1050-8392},
  doi = {10.1111/jora.12374},
  abstract = {Author(s): Jernigan, TL; Brown, SA; Dowling, GJ},
  file = {C\:\\Users\\josue\\Zotero\\storage\\D2C4SJ8M\\Jernigan et al. - 2018 - The Adolescent Brain Cognitive Development Study.pdf;C\:\\Users\\josue\\Zotero\\storage\\JT6JUQLR\\3jp835jz.html},
  journal = {JOURNAL OF RESEARCH ON ADOLESCENCE},
  language = {en},
  number = {1}
}

@article{jerniganIntroduction2018,
  title = {Introduction},
  author = {Jernigan, Terry L. and Brown, Sandra A.},
  year = {2018},
  volume = {32},
  pages = {1--3},
  issn = {18789293},
  doi = {10.1016/j.dcn.2018.02.002},
  abstract = {The Adolescent Brain Cognitive Development (ABCD) Study is a longitudinal, observational study of over 10,000 youth recruited at 21 sites throughout the United States. Comprehensive biennial assessments and more limited interim assessments measure health, mental health, neurocognition, family, cultural and environmental variables, substance use, genetic and other biomarkers, and structural and functional brain development. Within this Special Issue, readers will find much information about the rationale and objectives of the study, the broad ranging assessment protocols and new as well as traditional methodologies applied at baseline, the recruitment and retention strategies, and the anticipated final composition of the cohort. Information is also provided about how the study is coordinated and conducted, how decisions are made, how data quality is monitored, and how ethical standards are protected. In this introduction we will focus instead on the position of the ABCD Study in the changing landscape of biomedical research.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IFCJVFBC\\Jernigan and Brown - 2018 - Introduction.pdf},
  journal = {Developmental Cognitive Neuroscience},
  language = {en}
}

@article{jonesBridge2019,
  title = {Bridge {{Centrality}}: {{A Network Approach}} to {{Understanding Comorbidity}}},
  shorttitle = {Bridge {{Centrality}}},
  author = {Jones, Payton J. and Ma, Ruofan and McNally, Richard J.},
  year = {2019},
  volume = {0},
  pages = {1--15},
  issn = {0027-3171},
  doi = {10.1080/00273171.2019.1614898},
  abstract = {Recently, researchers in clinical psychology have endeavored to create network models of the relationships between symptoms, both within and across mental disorders. Symptoms that connect two mental disorders are called "bridge symptoms." Unfortunately, no formal quantitative methods for identifying these bridge symptoms exist. Accordingly, we developed four network statistics to identify bridge symptoms: bridge strength, bridge betweenness, bridge closeness, and bridge expected influence. These statistics are nonspecific to the type of network estimated, making them potentially useful in individual-level psychometric networks, group-level psychometric networks, and networks outside the field of psychopathology such as social networks. We first tested the fidelity of our statistics in predicting bridge nodes in a series of simulations. Averaged across all conditions, the statistics achieved a sensitivity of 92.7\% and a specificity of 84.9\%. By simulating datasets of varying sample sizes, we tested the robustness of our statistics, confirming their suitability for network psychometrics. Furthermore, we simulated the contagion of one mental disorder to another, showing that deactivating bridge nodes prevents the spread of comorbidity (i.e., one disorder activating another). Eliminating nodes based on bridge statistics was more effective than eliminating nodes high on traditional centrality statistics in preventing comorbidity. Finally, we applied our algorithms to 18 group-level empirical comorbidity networks from published studies and discussed the implications of this analysis.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\QU2IW789\\Jones et al. - 2019 - Bridge Centrality A Network Approach to Understan.pdf;C\:\\Users\\josue\\Zotero\\storage\\CGCHPGWY\\00273171.2019.html},
  journal = {Multivariate Behavioral Research},
  keywords = {bridge nodes,comorbidity,Graph theory,network analysis,node centrality linear models,psychopathology},
  number = {0}
}

@article{juddTreating2012,
  title = {Treating Stimuli as a Random Factor in Social Psychology: {{A}} New and Comprehensive Solution to a Pervasive but Largely Ignored Problem.},
  shorttitle = {Treating Stimuli as a Random Factor in Social Psychology},
  author = {Judd, Charles M. and Westfall, Jacob and Kenny, David A.},
  year = {2012},
  volume = {103},
  pages = {54--69},
  issn = {1939-1315, 0022-3514},
  doi = {10.1037/a0028347},
  abstract = {Throughout social and cognitive psychology, participants are routinely asked to respond in some way to experimental stimuli that are thought to represent categories of theoretical interest. For instance, in measures of implicit attitudes, participants are primed with pictures of specific African American and White stimulus persons sampled in some way from possible stimuli that might have been used. Yet seldom is the sampling of stimuli taken into account in the analysis of the resulting data, in spite of numerous warnings about the perils of ignoring stimulus variation (Clark, 1973; Kenny, 1985; Wells \& Windschitl, 1999). Part of this failure to attend to stimulus variation is due to the demands imposed by traditional analysis of variance procedures for the analysis of data when both participants and stimuli are treated as random factors. In this article, we present a comprehensive solution using mixed models for the analysis of data with crossed random factors (e.g., participants and stimuli). We show the substantial biases inherent in analyses that ignore one or the other of the random factors, and we illustrate the substantial advantages of the mixed models approach with both hypothetical and actual, well-known data sets in social psychology (Bem, 2011; Blair, Chapleau, \& Judd, 2005; Correll, Park, Judd, \& Wittenbrink, 2002).},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4X93TQ8P\\Judd et al. - 2012 - Treating stimuli as a random factor in social psyc.pdf},
  journal = {Journal of Personality and Social Psychology},
  language = {en},
  number = {1}
}

@article{kalischEstimating2007,
  title = {Estimating {{High}}-{{Dimensional Directed Acyclic Graphs}} with the {{PC}}-{{Algorithm}}},
  author = {Kalisch, Markus and B{\"u}hlmann, Peter},
  year = {2007},
  volume = {8},
  pages = {613--636},
  abstract = {We consider the PC-algorithm (Spirtes et al., 2000) for estimating the skeleton and equivalence class of a very high-dimensional directed acyclic graph (DAG) with corresponding Gaussian distribution. The PC-algorithm is computationally feasible and often very fast for sparse problems with many nodes (variables), and it has the attractive property to automatically achieve high computational efficiency as a function of sparseness of the true underlying DAG. We prove uniform consistency of the algorithm for very high-dimensional, sparse DAGs where the number of nodes is allowed to quickly grow with sample size n, as fast as O(na) for any 0 {$<$} a {$<$} {$\infty$}. The sparseness assumption is rather minimal requiring only that the neighborhoods in the DAG are of lower order than sample size n. We also demonstrate the PC-algorithm for simulated data.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\JJCAFN29\\Kalisch - Estimating High-Dimensional Directed Acyclic Graph.pdf},
  journal = {Journal of Machine Learning Research},
  language = {en}
}

@article{karrunity2018,
  title = {The Unity and Diversity of Executive Functions: {{A}} Systematic Review and Re-Analysis of Latent Variable Studies},
  shorttitle = {The Unity and Diversity of Executive Functions},
  author = {Karr, Justin E. and Areshenkoff, Corson N. and Rast, Philippe and Hofer, Scott M. and Iverson, Grant L. and {Garcia-Barrera}, Mauricio A.},
  year = {2018},
  volume = {144},
  pages = {1147--1185},
  issn = {1939-1455(Electronic),0033-2909(Print)},
  doi = {10.1037/bul0000160},
  abstract = {Confirmatory factor analysis (CFA) has been frequently applied to executive function measurement since first used to identify a three-factor model of inhibition, updating, and shifting; however, subsequent CFAs have supported inconsistent models across the life span, ranging from unidimensional to nested-factor models (i.e., bifactor without inhibition). This systematic review summarized CFAs on performance-based tests of executive functions and reanalyzed summary data to identify best-fitting models. Eligible CFAs involved 46 samples (N = 9,756). The most frequently accepted models varied by age (i.e., preschool = one/two-factor; school-age = three-factor; adolescent/adult = three/nested-factor; older adult = two/three-factor), and most often included updating/working memory, inhibition, and shifting factors. A bootstrap reanalysis simulated 5,000 samples from 21 correlation matrices (11 child/adolescent; 10 adult) from studies including the three most common factors, fitting seven competing models. Model results were summarized as the mean percent accepted (i.e., average rate at which models converged and met fit thresholds: CFI {$\geq$} .90/RMSEA {$\leq$} .08) and mean percent selected (i.e., average rate at which a model showed superior fit to other models: {$\Delta$}CFI {$\geq$} .005/.010/{$\Delta$}RMSEA {$\leq$} -.010/-.015). No model consistently converged and met fit criteria in all samples. Among adult samples, the nested-factor was accepted (41\textendash{}42\%) and selected (8\textendash{}30\%) most often. Among child/adolescent samples, the unidimensional model was accepted (32\textendash{}36\%) and selected (21\textendash{}53\%) most often, with some support for two-factor models without a differentiated shifting factor. Results show some evidence for greater unidimensionality of executive function among child/adolescent samples and both unity and diversity among adult samples. However, low rates of model acceptance/selection suggest possible bias toward the publication of well-fitting but potentially nonreplicable models with underpowered samples. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  file = {C\:\\Users\\josue\\Zotero\\storage\\BECUIWQH\\Karr et al. - 2018 - The unity and diversity of executive functions A .pdf;C\:\\Users\\josue\\Zotero\\storage\\VBRQ2QHC\\2018-37997-001.html},
  journal = {Psychological Bulletin},
  keywords = {Age Differences,Cognitive Processes,Confirmatory Factor Analysis,Diversity,Executive Function,Factor Analysis,Latent Variables,Short Term Memory,Statistical Variables},
  number = {11}
}

@article{kassBayes1995,
  title = {Bayes {{Factors}}},
  author = {Kass, Robert E. and Raftery, Adrian E.},
  year = {1995},
  volume = {90},
  pages = {773--795},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1995.10476572},
  file = {C\:\\Users\\josue\\Zotero\\storage\\WA5R23PT\\Kass and Raftery - 1995 - Bayes Factors.pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {430}
}

@article{katoBayesian2006,
  title = {A {{Bayesian}} Approach to Inequality Constrained Linear Mixed Models: Estimation and Model Selection},
  shorttitle = {A {{Bayesian}} Approach to Inequality Constrained Linear Mixed Models},
  author = {Kato, Bernet S and Hoijtink, Herbert},
  year = {2006},
  volume = {6},
  pages = {231--249},
  issn = {1471-082X, 1477-0342},
  doi = {10.1191/1471082X06st119oa},
  abstract = {Constrained parameter problems arise in a wide variety of applications. This article deals with estimation and model selection in linear mixed models with inequality constraints on the parameters. It is shown that different theories can be translated into statistical models by putting constraints on the model parameters yielding a set of competing models. A new approach based on the principle of encompassing priors is proposed and used to compute Bayes factors and subsequently posterior model probabilities. Model selection is based on posterior model probabilities. The approach is illustrated using a longitudinal data set.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IPSXTHA3\\Kato and Hoijtink - 2006 - A Bayesian approach to inequality constrained line.pdf},
  journal = {Statistical Modelling: An International Journal},
  language = {en},
  number = {3}
}

@article{kleinMany2018,
  title = {Many {{Labs}} 2: {{Investigating Variation}} in {{Replicability Across Samples}} and {{Settings}}},
  shorttitle = {Many {{Labs}} 2},
  author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Adams, Reginald B. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahn{\'i}k, {\v S}t{\v e}p{\'a}n and Batra, Rishtee and Berkics, Mih{\'a}ly and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and R{\'e}dei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Dalla Rosa, Anna and Davis, William E. and {de Bruijn}, Maaike and De Schutter, Leander and Devos, Thierry and {de Vries}, Marieke and Do{\u g}ulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-{\'A}ngel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and G{\'o}mez, {\'A}ngel and Gonz{\'a}lez, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and {Innes-Ker}, {\AA}se H. and {Jim{\'e}nez-Leal}, William and John, Melissa-Sue and {Joy-Gaba}, Jennifer A. and Kamilo{\u g}lu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Kne{\v z}evi{\'c}, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Dani{\"e}l and Lazarevi{\'c}, Ljiljana B. and Levitan, Carmel A. and Lewis, Neil A. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Me{\dj}edovi{\'c}, Janko and {Mena-Pacheco}, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, F{\'e}lix and Lee Nichols, Austin and Ocampo, Aaron and O'Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, G{\'a}bor and Osowiecka, Malgorzata and Packard, Grant and {P{\'e}rez-S{\'a}nchez}, Rolando and Petrovi{\'c}, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Sch{\"o}nbrodt, Felix D. and Sekerdej, Maciej B. and Sirlop{\'u}, David and Skorinko, Jeanine L. M. and Smith, Michael A. and {Smith-Castro}, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and {van Aert}, Robbie C. M. and {van Assen}, Marcel A. L. M. and {van der Hulst}, Marije and {van Lange}, Paul A. M. and {van 't Veer}, Anna Elisabeth and {V{\'a}squez- Echeverr{\'i}a}, Alejandro and Ann Vaughn, Leigh and V{\'a}zquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
  year = {2018},
  volume = {1},
  pages = {443--490},
  issn = {2515-2459},
  doi = {10.1177/2515245918810225},
  abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p {$<$} .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p {$<$} .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen's ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small ({$<$} 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VV5EFF69\\Klein et al. - 2018 - Many Labs 2 Investigating Variation in Replicabil.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  language = {en},
  number = {4}
}

@article{klugkistBayesian2005,
  title = {Bayesian Model Selection Using Encompassing Priors},
  author = {Klugkist, Irene and Kato, Bernet and Hoijtink, Herbert},
  year = {2005},
  volume = {59},
  pages = {57--69},
  issn = {1467-9574},
  doi = {10.1111/j.1467-9574.2005.00279.x},
  abstract = {This paper deals with Bayesian selection of models that can be specified using inequality constraints among the model parameters. The concept of encompassing priors is introduced, that is, a prior distribution for an unconstrained model from which the prior distributions of the constrained models can be derived. It is shown that the Bayes factor for the encompassing and a constrained model has a very nice interpretation: it is the ratio of the proportion of the prior and posterior distribution of the encompassing model in agreement with the constrained model. It is also shown that, for a specific class of models, selection based on encompassing priors will render a virtually objective selection procedure. The paper concludes with three illustrative examples: an analysis of variance with ordered means; a contingency table analysis with ordered odds-ratios; and a multilevel model with ordered slopes.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\5ZBQBHD8\\Klugkist et al. - 2005 - Bayesian model selection using encompassing priors.pdf;C\:\\Users\\josue\\Zotero\\storage\\S3N5D4H8\\j.1467-9574.2005.00279.html},
  journal = {Statistica Neerlandica},
  keywords = {Bayes factors,inequality constraints,objective Bayesian inference,posterior probability},
  language = {en},
  number = {1}
}

@incollection{klugkistEncompassing2008,
  title = {Encompassing {{Prior Based Model Selection}} for {{Inequality Constrained Analysis}} of {{Variance}}},
  booktitle = {Bayesian {{Evaluation}} of {{Informative Hypotheses}}},
  author = {Klugkist, Irene},
  editor = {Hoijtink, Herbert and Klugkist, Irene and Boelen, Paul A.},
  year = {2008},
  pages = {53--83},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-09612-4_4},
  abstract = {In Chapter 2, three psychological datasets with competing, informative hypotheses were introduced. For instance, with respect to the Dissociative Identity Disorder (DID) data of Huntjens, two competing theories about interidentity amnesia were presented [11]. Some believe that information provided to one identity cannot be retrieved by another identity of the DID-patient; that is, there is no transfer of information between identities.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\W7RLL4R2\\Klugkist - 2008 - Encompassing Prior Based Model Selection for Inequ.pdf},
  isbn = {978-0-387-09612-4},
  keywords = {Marginal Likelihood,Model Selection,Prior Density,Prior Distribution,Unconstrained Model},
  language = {en},
  series = {Statistics for {{Social}} and {{Behavioral Sciences}}}
}

@article{klugkistInequality2005,
  title = {Inequality {{Constrained Analysis}} of {{Variance}}: {{A Bayesian Approach}}.},
  shorttitle = {Inequality {{Constrained Analysis}} of {{Variance}}},
  author = {Klugkist, Irene and Laudy, Olav and Hoijtink, Herbert},
  year = {2005},
  volume = {10},
  pages = {477--493},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.10.4.477},
  abstract = {Researchers often have one or more theories or expectations with respect to the outcome of their empirical research. When researchers talk about the expected relations between variables if a certain theory is correct, their statements are often in terms of one or more parameters expected to be larger or smaller than one or more other parameters. Stated otherwise, their statements are often formulated using inequality constraints. In this article, a Bayesian approach to evaluate analysis of variance or analysis of covariance models with inequality constraints on the (adjusted) means is presented. This evaluation contains two issues: estimation of the parameters given the restrictions using the Gibbs sampler and model selection using Bayes factors in the case of competing theories. The article concludes with two illustrations: a one-way analysis of covariance and an analysis of a three-way table of ordered means.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RXBPPULB\\Klugkist et al. - 2005 - Inequality Constrained Analysis of Variance A Bay.pdf},
  journal = {Psychological Methods},
  keywords = {Read},
  language = {en},
  number = {4}
}

@article{kluytmansIllustrating2012,
  title = {Illustrating {{Bayesian Evaluation}} of {{Informative Hypotheses}} for {{Regression Models}}},
  author = {Kluytmans, Anouck and Van De Schoot, Rens and Hoijtink, Herbert},
  year = {2012},
  volume = {3},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2012.00002},
  abstract = {In the present paper we illustrate the Bayesian evaluation of informative hypotheses for regression models. This approach allows psychologists to more directly test their theories than they would using conventional statis- tical analyses. Throughout this paper, both real-world data and simulated datasets will be introduced and evaluated to investigate the pragmatical as well as the theoretical qualities of the approach. We will pave the way from forming informative hypotheses in the context of regression models to interpreting the Bayes factors that express the support for the hypotheses being evaluated. In doing so, the present approach goes beyond p-values and uninformative null hypothesis testing, moving on to informative testing and quantification of model support in a way that is accessible to everyday psychologists.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IGKPPX3T\\Kluytmans et al. - 2012 - Illustrating Bayesian Evaluation of Informative Hy.pdf},
  journal = {Frontiers in Psychology},
  keywords = {Bayes factor,effect size,inequality constrained hypotheses,informative hypotheses},
  language = {English}
}

@article{koulCrossValidation2018,
  title = {Cross-{{Validation Approaches}} for {{Replicability}} in {{Psychology}}},
  author = {Koul, Atesh and Becchio, Cristina and Cavallo, Andrea},
  year = {2018},
  volume = {9},
  pages = {1117},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.01117},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AI7I6CSW\\Koul et al. - 2018 - Cross-Validation Approaches for Replicability in P.pdf},
  journal = {Frontiers in Psychology}
}

@article{kramerRegularized2009,
  title = {Regularized Estimation of Large-Scale Gene Association Networks Using Graphical {{Gaussian}} Models},
  author = {Kr{\"a}mer, Nicole and Sch{\"a}fer, Juliane and Boulesteix, Anne-Laure},
  year = {2009},
  volume = {10},
  pages = {384},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-10-384},
  abstract = {Background: Graphical Gaussian models are popular tools for the estimation of (undirected) gene association networks from microarray data. A key issue when the number of variables greatly exceeds the number of samples is the estimation of the matrix of partial correlations. Since the (Moore-Penrose) inverse of the sample covariance matrix leads to poor estimates in this scenario, standard methods are inappropriate and adequate regularization techniques are needed. Popular approaches include biased estimates of the covariance matrix and highdimensional regression schemes, such as the Lasso and Partial Least Squares.
Results: In this article, we investigate a general framework for combining regularized regression methods with the estimation of Graphical Gaussian models. This framework includes various existing methods as well as two new approaches based on ridge regression and adaptive lasso, respectively. These methods are extensively compared both qualitatively and quantitatively within a simulation study and through an application to six diverse real data sets. In addition, all proposed algorithms are implemented in the R package "parcor", available from the R repository CRAN.
Conclusion: In our simulation studies, the investigated non-sparse regression methods, i.e. Ridge Regression and Partial Least Squares, exhibit rather conservative behavior when combined with (local) false discovery rate multiple testing in order to decide whether or not an edge is present in the network. For networks with higher densities, the difference in performance of the methods decreases. For sparse networks, we confirm the Lasso's well known tendency towards selecting too many edges, whereas the two-stage adaptive Lasso is an interesting alternative that provides sparser solutions. In our simulations, both sparse and non-sparse methods are able to reconstruct networks with cluster structures. On six real data sets, we also clearly distinguish the results obtained using the non-sparse methods and those obtained using the sparse methods where specification of the regularization parameter automatically means model selection. In five out of six data sets, Partial Least Squares selects very dense networks. Furthermore, for data that violate the assumption of uncorrelated observations (due to replications), the Lasso and the adaptive Lasso yield very complex structures, indicating that they might not be suited under these conditions. The shrinkage approach is more stable than the regression based approaches when using subsampling.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\9CMJ65PA\\Krämer et al. - 2009 - Regularized estimation of large-scale gene associa.pdf},
  journal = {BMC Bioinformatics},
  language = {en},
  number = {1}
}

@article{kroenkePHQ92001,
  title = {The {{PHQ}}-9},
  author = {Kroenke, Kurt and Spitzer, Robert L and Williams, Janet B W},
  year = {2001},
  volume = {16},
  pages = {606--613},
  issn = {0884-8734},
  doi = {10.1046/j.1525-1497.2001.016009606.x},
  abstract = {OBJECTIVE
While considerable attention has focused on improving the detection of depression, assessment of severity is also important in guiding treatment decisions. Therefore, we examined the validity of a brief, new measure of depression severity.

MEASUREMENTS
The Patient Health Questionnaire (PHQ) is a self-administered version of the PRIME-MD diagnostic instrument for common mental disorders. The PHQ-9 is the depression module, which scores each of the 9 DSM-IV criteria as ``0'' (not at all) to ``3'' (nearly every day). The PHQ-9 was completed by 6,000 patients in 8 primary care clinics and 7 obstetrics-gynecology clinics. Construct validity was assessed using the 20-item Short-Form General Health Survey, self-reported sick days and clinic visits, and symptom-related difficulty. Criterion validity was assessed against an independent structured mental health professional (MHP) interview in a sample of 580 patients.

RESULTS
As PHQ-9 depression severity increased, there was a substantial decrease in functional status on all 6 SF-20 subscales. Also, symptom-related difficulty, sick days, and health care utilization increased. Using the MHP reinterview as the criterion standard, a PHQ-9 score {$\geq$}10 had a sensitivity of 88\% and a specificity of 88\% for major depression. PHQ-9 scores of 5, 10, 15, and 20 represented mild, moderate, moderately severe, and severe depression, respectively. Results were similar in the primary care and obstetrics-gynecology samples.

CONCLUSION
In addition to making criteria-based diagnoses of depressive disorders, the PHQ-9 is also a reliable and valid measure of depression severity. These characteristics plus its brevity make the PHQ-9 a useful clinical and research tool.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\QI9C5DEP\\Kroenke et al. - 2001 - The PHQ-9.pdf},
  journal = {Journal of General Internal Medicine},
  number = {9},
  pmcid = {PMC1495268},
  pmid = {11556941}
}

@article{kruschkeBayesian2013,
  title = {Bayesian Estimation Supersedes the t Test.},
  author = {Kruschke, John K.},
  year = {2013},
  volume = {142},
  pages = {573--603},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/a0029146},
  abstract = {Bayesian estimation for 2 groups provides complete distributions of credible values for the effect size, group means and their difference, standard deviations and their difference, and the normality of the data. The method handles outliers. The decision rule can accept the null value (unlike traditional t tests) when certainty in the estimate is high (unlike Bayesian model comparison using Bayes factors). The method also yields precise estimates of statistical power for various research goals. The software and programs are free and run on Macintosh, Windows, and Linux platforms.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\27A7TFYS\\Kruschke - 2013 - Bayesian estimation supersedes the t test..pdf},
  journal = {Journal of Experimental Psychology: General},
  language = {en},
  number = {2}
}

@article{kruschkeBayesian2018,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  year = {2018},
  volume = {25},
  pages = {178--206},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\6LJMVB54\\Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf},
  journal = {Psychonomic Bulletin \& Review},
  keywords = {Bayes factor,Bayesian inference,Confidence interval,Credible interval,Effect size,Equivalence testing,Highest density interval,Meta-analysis,Null hypothesis significance testing,Power analysis,Randomized controlled trial,Region of practical equivalence},
  language = {en},
  number = {1}
}

@book{kruschkeDoing2015,
  title = {Doing {{Bayesian Data Analysis}}},
  author = {Kruschke, John K.},
  year = {2015},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-405888-0.09999-2},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KW2VQGGW\\Kruschke - 2015 - Doing Bayesian Data Analysis.pdf},
  isbn = {978-0-12-405888-0},
  language = {en}
}

@article{kuisminEstimation2017,
  title = {Estimation of Covariance and Precision Matrix, Network Structure, and a View toward Systems Biology},
  author = {Kuismin, Markku O. and Sillanp{\"a}{\"a}, Mikko J.},
  year = {2017},
  volume = {9},
  pages = {e1415},
  issn = {1939-0068},
  doi = {10.1002/wics.1415},
  abstract = {Covariance matrix and its inverse, known as the precision matrix, have many applications in multivariate analysis because their elements can exhibit the variance, correlation, covariance, and conditional independence between variables. The practice of estimating the precision matrix directly without involving any matrix inversion has obtained significant attention in the literature. We review the methods that have been implemented in R and their R packages, particularly when there are more variables than data samples and discuss ideas behind them. We describe how sparse precision matrix estimation methods can be used to infer network structure. Finally, we discuss methods that are suitable for gene coexpression network construction. WIREs Comput Stat 2017, 9:e1415. doi: 10.1002/wics.1415 This article is categorized under: Statistical Models {$>$} Linear Models Applications of Computational Statistics {$>$} Computational and Molecular Biology Statistical and Graphical Methods of Data Analysis {$>$} Multivariate Analysis},
  file = {C\:\\Users\\josue\\Zotero\\storage\\5RZIXZX7\\Kuismin and Sillanpää - 2017 - Estimation of covariance and precision matrix, net.pdf;C\:\\Users\\josue\\Zotero\\storage\\JTWML4CW\\wics.html},
  journal = {WIREs Computational Statistics},
  keywords = {covariance matrix,Gaussian graphical models,microarray data,network estimation,shrinkage estimation,Sparse precision matrix},
  language = {en},
  number = {6}
}

@article{kwanRegressionBased2014,
  title = {A {{Regression}}-{{Based Interpretation}} of the {{Inverse}} of the {{Sample Covariance Matrix}}},
  author = {Kwan, Clarence C. Y.},
  year = {2014},
  volume = {7},
  pages = {4613},
  abstract = {The usefulness of covariance and correlation matrices is well-known in various academic fields. Matrix inversion, if required in an analytical setting, tends to mask the intuition in interpreting the corresponding empirical or experimental results. Drawing on the finance literature in mean-variance portfolio analysis, this paper presents pedagogically a regression-based interpretation of the inverse of the sample covariance matrix. Microsoft ExcelTM plays an important pedagogic role in this paper. The availability of various Excel functions and computational tools for numerical illustrations provides flexibility for instructors in the delivery of the corresponding analytical materials.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\CMJRU7P3\\Kwan - 2014 - A Regression-Based Interpretation of the Inverse o.pdf;C\:\\Users\\josue\\Zotero\\storage\\Q3WH3ADA\\4613-a-regression-based-interpretation-of-the-inverse-of-the-sample-covariance-matrix.html},
  journal = {Spreadsheets in Education},
  language = {en},
  number = {1}
}

@techreport{lakenspractical2019,
  title = {The Practical Alternative to the P-Value Is the Correctly Used p-Value},
  author = {Lakens, Daniel},
  year = {2019},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/shm8v},
  abstract = {Due to the strong overreliance on p-values in the scientific literature some researchers have argued that p-values should be abandoned or banned, and that we need to move beyond p-values and embrace practical alternatives. When proposing alternatives to p-values statisticians often commit the `Statistician's Fallacy', where they declare which statistic researchers really `want to know'. Instead of telling researchers what they want to know, statisticians should teach researchers which questions they can ask. In some situations, the answer to the question they are most interested in will be the p-value. There is clear room for improvement in how we teach p-values. If anyone really believes p-values are an important cause of problems in science, preventing the misinterpretation of p-values by developing better evidence-based education and user-centered statistical software should be a top priority. At least for some research questions we might not need alternatives to p-values, but can improve our inferences more by using alternatives to null-hypothesis tests. As long as null-hypothesis tests have been criticized, researchers have suggested to include minimal-effects tests and equivalence tests in our statistical toolbox, and these tests have the potential to greatly improve the questions researchers ask.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\X8Y2FI86\\Lakens - 2019 - The practical alternative to the p-value is the co.pdf},
  language = {en},
  type = {Preprint}
}

@article{langloisInfant1995,
  title = {Infant {{Attractiveness Predicts Maternal Behaviors}} and {{Attitudes}}},
  author = {Langlois, Judith H and Ritter, Jean M and Casey, Rita J and Sawin, Douglas B},
  year = {1995},
  volume = {31},
  pages = {9},
  file = {C\:\\Users\\josue\\Zotero\\storage\\969TM32M\\Langlois et al. - Infant Attractiveness Predicts Maternal Behaviors .pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {3}
}

@book{lauritzenGraphical1996,
  title = {Graphical {{Models}}},
  author = {Lauritzen, Steffen L.},
  year = {1996},
  publisher = {{Clarendon Press}},
  abstract = {The idea of modelling systems using graph theory has its origin in several scientific areas: in statistical physics (the study of large particle systems), in genetics (studying inheritable properties of natural species), and in interactions in contingency tables. The use of graphical models in statistics has increased considerably over recent years and the theory has been greatly developed and extended. This book provides the first comprehensive and authoritative account of the theory of graphical models and is written by a leading expert in the field. It contains the fundamental graph theory required and a thorough study of Markov properties associated with various type of graphs. The statistical theory of log-linear and graphical models for contingency tables, covariance selection models, and graphical models with mixed discrete-continous variables in developed detail. Special topics, such as the application of graphical models to probabilistic expert systems, are described briefly, and appendices give details of the multivarate normal distribution and of the theory of regular exponential families. The author has recently been awarded the RSS Guy Medal in Silver 1996 for his innovative contributions to statistical theory and practice, and especially for his work on graphical models.},
  googlebooks = {mGQWkx4guhAC},
  isbn = {978-0-19-159122-8},
  keywords = {Computers / Intelligence (AI) \& Semantics,Mathematics / Applied,Mathematics / Graphic Methods,Mathematics / Probability \& Statistics / General},
  language = {en}
}

@article{lazicImproving2013,
  title = {Improving Basic and Translational Science by Accounting for Litter-to-Litter Variation in Animal Models},
  author = {Lazic, Stanley E. and Essioux, Laurent},
  year = {2013},
  volume = {14},
  pages = {37},
  issn = {1471-2202},
  doi = {10.1186/1471-2202-14-37},
  abstract = {Animals from the same litter are often more alike compared with animals from different litters. This litter-to-litter variation, or ``litter effects'', can influence the results in addition to the experimental factors of interest. Furthermore, sometimes an experimental treatment can only be applied to whole litters rather than to individual offspring. An example is the valproic acid (VPA) model of autism, where VPA is administered to pregnant females thereby inducing the disease phenotype in the offspring. With this type of experiment the sample size is the number of litters and not the total number of offspring. If such experiments are not appropriately designed and analysed, the results can be severely biased as well as extremely underpowered.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\XQVXX5KD\\Lazic and Essioux - 2013 - Improving basic and translational science by accou.pdf;C\:\\Users\\josue\\Zotero\\storage\\VVZ9D7XZ\\1471-2202-14-37.html},
  journal = {BMC Neuroscience},
  number = {1}
}

@article{lecunDeep2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  volume = {521},
  pages = {436--444},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature14539},
  file = {C\:\\Users\\josue\\Zotero\\storage\\M59P7K24\\LeCun et al. - 2015 - Deep learning.pdf},
  journal = {Nature},
  language = {en},
  number = {7553}
}

@article{ledoitwellconditioned2004,
  title = {A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices},
  author = {Ledoit, Olivier and Wolf, Michael},
  year = {2004},
  volume = {88},
  pages = {365--411},
  issn = {0047259X},
  doi = {10.1016/S0047-259X(03)00096-4},
  abstract = {Many applied problems require a covariance matrix estimator that is not only invertible, but also well-conditioned (that is, inverting it does not amplify estimation error). For largedimensional covariance matrices, the usual estimator\textemdash{}the sample covariance matrix\textemdash{}is typically not well-conditioned and may not even be invertible. This paper introduces an estimator that is both well-conditioned and more accurate than the sample covariance matrix asymptotically. This estimator is distribution-free and has a simple explicit formula that is easy to compute and interpret. It is the asymptotically optimal convex linear combination of the sample covariance matrix with the identity matrix. Optimality is meant with respect to a quadratic loss function, asymptotically as the number of observations and the number of variables go to infinity together. Extensive Monte Carlo confirm that the asymptotic results tend to hold well in finite sample.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\WBSB2B4R\\Ledoit and Wolf - 2004 - A well-conditioned estimator for large-dimensional.pdf},
  journal = {Journal of Multivariate Analysis},
  language = {en},
  number = {2}
}

@book{leeBayesian2013,
  title = {Bayesian {{Cognitive Modeling}}: {{A Practical Course}}},
  shorttitle = {Bayesian {{Cognitive Modeling}}},
  author = {Lee, Michael D. and Wagenmakers, Eric-Jan},
  year = {2013},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9781139087759},
  isbn = {978-1-139-08775-9}
}

@article{leebMODEL2005,
  title = {{{MODEL SELECTION AND INFERENCE}}: {{FACTS AND FICTION}}},
  shorttitle = {{{MODEL SELECTION AND INFERENCE}}},
  author = {Leeb, Hannes and P{\"o}tscher, Benedikt M.},
  year = {2005},
  volume = {21},
  issn = {0266-4666, 1469-4360},
  doi = {10.1017/S0266466605050036},
  file = {C\:\\Users\\josue\\Zotero\\storage\\GE8FH88E\\Leeb and Pötscher - 2005 - MODEL SELECTION AND INFERENCE FACTS AND FICTION.pdf},
  journal = {Econometric Theory},
  language = {en},
  number = {01}
}

@book{leleBayesian2010,
  title = {Bayesian {{Analysis}} for {{Population Ecology}}},
  author = {Lele, S and Richtsmeier, J and Babu, G and Feigelson, E and King, Ruth and Morgan, Byron J T and Gimenez, Olivier and Brooks, Stephen P and Lawson, Andrew B and Patterson, S and Jones, B and Crowley, J and Green, S and Benedetti, J and Hayes, R J and Moulton, L H and Greenacre, M and Fairclough, D L and Pronzato, L and Wynn, H and Zhigljavsky, A and Skrondal, A and {Rabe-Hesketh}, S and Basford, K and Tukey, J and Waterman, M},
  year = {2010},
  file = {C\:\\Users\\josue\\Zotero\\storage\\NRSLN7L8\\Lele et al. - 2010 - Bayesian Analysis for Population Ecology.pdf},
  language = {en}
}

@article{leverModel2016,
  title = {Model Selection and Overfitting},
  author = {Lever, Jake and Krzywinski, Martin and Altman, Naomi},
  year = {2016},
  volume = {13},
  pages = {703--704},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.3968},
  file = {C\:\\Users\\josue\\Zotero\\storage\\DVXG9GG9\\Lever et al. - 2016 - Model selection and overfitting.pdf},
  journal = {Nature Methods},
  language = {en},
  number = {9}
}

@article{liebermanDisgust2012,
  title = {Disgust {{Sensitivity}}, {{Obesity Stigma}}, and {{Gender}}: {{Contamination Psychology Predicts Weight Bias}} for {{Women}}, {{Not Men}}},
  shorttitle = {Disgust {{Sensitivity}}, {{Obesity Stigma}}, and {{Gender}}},
  author = {Lieberman, Debra L. and Tybur, Josh M. and Latner, Janet D.},
  year = {2012},
  volume = {20},
  pages = {1803--1814},
  issn = {1930-739X},
  doi = {10.1038/oby.2011.247},
  abstract = {Recent research has established a link between disgust sensitivity and stigmatizing reactions to various groups, including obese individuals. However, previous research has overlooked disgust's multiple evolved functions. Here, we investigated whether the link between disgust sensitivity and obesity stigma is specific to pathogen disgust, or whether sexual disgust and moral disgust\textemdash{}two separate functional domains\textemdash{}also relate to negative attitudes toward obese individuals. Additionally, we investigated whether sex differences exist in the manner disgust sensitivity predicts obesity stigma, whether the sexes differ across the subtypes of obesity bias independent of disgust sensitivity, and last, the association between participants' BMI and different subtypes of obesity stigma. In study 1 (N = 92), we established that obesity elicits pathogen, sexual, and moral disgust. In study 2, we investigated the relationship between these types of disgust sensitivity and obesity stigma. Participants (N = 387) reported their level of disgust toward various pathogen, sexual, and moral acts and their attitudes toward obese individuals. For women, but not men, increased pathogen disgust sensitivity predicted more negative attitudes toward obese individuals. Men reported more negative general attitudes toward obese individuals whereas women reported greater fear of becoming obese. The sexes also differed in how their own BMI related to the subtypes of obesity stigma. These findings indicate that pathogen disgust sensitivity plays a role in obesity stigma, specifically for women. Defining the scope of disgust's activation in response to obesity and its relationship with other variables can help identify possible mechanisms for understanding and ultimately alleviating prejudice and discrimination.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\XIR47KWE\\Lieberman et al. - 2012 - Disgust Sensitivity, Obesity Stigma, and Gender C.pdf;C\:\\Users\\josue\\Zotero\\storage\\FQA63CEE\\oby.2011.html},
  journal = {Obesity},
  language = {en},
  number = {9}
}

@article{liptonTroubling2018,
  title = {Troubling {{Trends}} in {{Machine Learning Scholarship}}},
  author = {Lipton, Zachary C. and Steinhardt, Jacob},
  year = {2018},
  abstract = {Collectively, machine learning (ML) researchers are engaged in the creation and dissemination of knowledge about data-driven algorithms. In a given paper, researchers might aspire to any subset of the following goals, among others: to theoretically characterize what is learnable, to obtain understanding through empirically rigorous experiments, or to build a working system that has high predictive accuracy. While determining which knowledge warrants inquiry may be subjective, once the topic is fixed, papers are most valuable to the community when they act in service of the reader, creating foundational knowledge and communicating as clearly as possible. Recent progress in machine learning comes despite frequent departures from these ideals. In this paper, we focus on the following four patterns that appear to us to be trending in ML scholarship: (i) failure to distinguish between explanation and speculation; (ii) failure to identify the sources of empirical gains, e.g., emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning; (iii) mathiness: the use of mathematics that obfuscates or impresses rather than clarifies, e.g., by confusing technical and non-technical concepts; and (iv) misuse of language, e.g., by choosing terms of art with colloquial connotations or by overloading established technical terms. While the causes behind these patterns are uncertain, possibilities include the rapid expansion of the community, the consequent thinness of the reviewer pool, and the often-misaligned incentives between scholarship and short-term measures of success (e.g., bibliometrics, attention, and entrepreneurial opportunity). While each pattern offers a corresponding remedy (don't do it), we also discuss some speculative suggestions for how the community might combat these trends.},
  archivePrefix = {arXiv},
  eprint = {1807.03341},
  eprinttype = {arxiv},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IQQNWPYW\\Lipton and Steinhardt - 2018 - Troubling Trends in Machine Learning Scholarship.pdf;C\:\\Users\\josue\\Zotero\\storage\\54YDIANL\\1807.html},
  journal = {arXiv:1807.03341 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{liuBayes2008,
  title = {Bayes Factors: {{Prior}} Sensitivity and Model Generalizability},
  shorttitle = {Bayes Factors},
  author = {Liu, Charles C. and Aitkin, Murray},
  year = {2008},
  volume = {52},
  pages = {362--375},
  issn = {00222496},
  doi = {10.1016/j.jmp.2008.03.002},
  abstract = {Model selection is a central issue in mathematical psychology. One useful criterion for model selection is generalizability; that is, the chosen model should yield the best predictions for future data. Some researchers in psychology have proposed that the Bayes factor can be used for assessing model generalizability. An alternative method, known as the generalization criterion, has also been proposed for the same purpose. We argue that these two methods address different levels of model generalizability (local and global), and will often produce divergent conclusions. We illustrate this divergence by applying the Bayes factor and the generalization criterion to a comparison of retention functions. The application of alternative model selection criteria will also be demonstrated within the framework of model generalizability.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\E6T93PJA\\Liu and Aitkin - 2008 - Bayes factors Prior sensitivity and model general.pdf},
  journal = {Journal of Mathematical Psychology},
  language = {en},
  number = {6}
}

@article{liuSelecting2012,
  title = {Selecting a Linear Mixed Model for Longitudinal Data: {{Repeated}} Measures Analysis of Variance, Covariance Pattern Model, and Growth Curve Approaches.},
  shorttitle = {Selecting a Linear Mixed Model for Longitudinal Data},
  author = {Liu, Siwei and Rovine, Michael J. and Molenaar, Peter C. M.},
  year = {2012},
  volume = {17},
  pages = {15--30},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0026971},
  abstract = {With increasing popularity, growth curve modeling is more and more often considered as the 1st choice for analyzing longitudinal data. Although the growth curve approach is often a good choice, other modeling strategies may more directly answer questions of interest. It is common to see researchers fit growth curve models without considering alterative modeling strategies. In this article we compare 3 approaches for analyzing longitudinal data: repeated measures analysis of variance, covariance pattern models, and growth curve models. As all are members of the general linear mixed model family, they represent somewhat different assumptions about the way individuals change. These assumptions result in different patterns of covariation among the residuals around the fixed effects. In this article, we first indicate the kinds of data that are appropriately modeled by each and use real data examples to demonstrate possible problems associated with the blanket selection of the growth curve model. We then present a simulation that indicates the utility of Akaike information criterion and Bayesian information criterion in the selection of a proper residual covariance structure. The results cast doubt on the popular practice of automatically using growth curve modeling for longitudinal data without comparing the fit of different models. Finally, we provide some practical advice for assessing mean changes in the presence of correlated data.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\BKJKGG3N\\Liu et al. - 2012 - Selecting a linear mixed model for longitudinal da.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {1}
}

@book{lynchIntroduction2007,
  title = {Introduction to Applied {{Bayesian}} Statistics and Estimation for Social Scientists},
  author = {Lynch, Scott M.},
  year = {2007},
  publisher = {{Springer}},
  address = {{New York}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\79ZNZDZ9\\Lynch - 2007 - Introduction to applied Bayesian statistics and es.pdf},
  isbn = {978-0-387-71264-2},
  keywords = {Bayesian statistical decision theory,Social sciences,Statistical methods},
  language = {en},
  lccn = {HA29 .L973 2007},
  series = {Statistics for Social and Behavioral Sciences}
}

@book{madsenpsychology2019,
  title = {The Psychology of Micro-Targeted Election Campaigns},
  author = {Madsen, Jens Koed},
  year = {2019},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VLDPMQY7\\Madsen - 2019 - The psychology of micro-targeted election campaign.pdf},
  isbn = {978-3-030-22144-7},
  language = {en},
  note = {OCLC: 1120068024}
}

@article{mageziLinear2015,
  title = {Linear Mixed-Effects Models for within-Participant Psychology Experiments: An Introductory Tutorial and Free, Graphical User Interface ({{LMMgui}})},
  shorttitle = {Linear Mixed-Effects Models for within-Participant Psychology Experiments},
  author = {Magezi, David A.},
  year = {2015},
  volume = {6},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2015.00002},
  abstract = {Linear mixed-effects models (LMMs) are increasingly being used for data analysis in cognitive neuroscience and experimental psychology, where within-participant designs are common. The current article provides an introductory review of the use of LMMs for within-participant data analysis and describes a free, simple, graphical user interface (LMMgui). LMMgui uses the package lme4 (Bates et al. 2014) in the statistical environment R (R Core Team).},
  file = {C\:\\Users\\josue\\Zotero\\storage\\BWQ2KR2C\\Magezi - 2015 - Linear mixed-effects models for within-participant.pdf},
  journal = {Frontiers in Psychology},
  keywords = {graphical user interface,linear mixed-effects models,r,repeated measurements,within-participant design},
  language = {English}
}

@article{makridakisStatistical2018,
  title = {Statistical and {{Machine Learning}} Forecasting Methods: {{Concerns}} and Ways Forward},
  shorttitle = {Statistical and {{Machine Learning}} Forecasting Methods},
  author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
  year = {2018},
  volume = {13},
  pages = {e0194889},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0194889},
  abstract = {Machine Learning (ML) methods have been proposed in the academic literature as alternatives to statistical ones for time series forecasting. Yet, scant evidence is available about their relative performance in terms of accuracy and computational requirements. The purpose of this paper is to evaluate such performance across multiple forecasting horizons using a large subset of 1045 monthly time series used in the M3 Competition. After comparing the post-sample accuracy of popular ML methods with that of eight traditional statistical ones, we found that the former are dominated across both accuracy measures used and for all forecasting horizons examined. Moreover, we observed that their computational requirements are considerably greater than those of statistical methods. The paper discusses the results, explains why the accuracy of ML models is below that of statistical ones and proposes some possible ways forward. The empirical results found in our research stress the need for objective and unbiased ways to test the performance of forecasting methods that can be achieved through sizable and open competitions allowing meaningful comparisons and definite conclusions.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\L7IQNX28\\Makridakis et al. - 2018 - Statistical and Machine Learning forecasting metho.pdf;C\:\\Users\\josue\\Zotero\\storage\\DWLQV328\\article.html},
  journal = {PLOS ONE},
  keywords = {Algorithms,Computing methods,Forecasting,Neural networks,Optimization,Preprocessing,Statistical methods,Support vector machines},
  language = {en},
  number = {3}
}

@book{marinBayesian2014,
  title = {Bayesian Essentials with {{R}}},
  author = {Marin, Jean-Michel and Robert, Christian P.},
  year = {2014},
  edition = {Second edition},
  publisher = {{Springer}},
  address = {{New York}},
  abstract = {This Bayesian modeling book provides a self-contained entry to computational Bayesian statistics. Focusing on the most standard statistical models and backed up by real datasets and an all-inclusive R (CRAN) package called bayess, the book provides an operational methodology for conducting Bayesian inference, rather than focusing on its theoretical and philosophical justifications. Readers are empowered to participate in the real-life data analysis situations depicted here from the beginning. The stakes are high and the reader determines the outcome. Special attention is paid to the derivation of prior distributions in each case and specific reference solutions are given for each of the models. Similarly, computational details are worked out to lead the reader towards an effective programming of the methods given in the book. In particular, all R codes are discussed with enough detail to make them readily understandable and expandable},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4IEXLCYJ\\Marin and Robert - 2014 - Bayesian essentials with R.pdf},
  isbn = {978-1-4614-8686-2},
  keywords = {Bayesian statistical decision theory,R (Computer program language)},
  language = {en},
  lccn = {QA279.5 .M358 2014},
  note = {OCLC: ocn859186504},
  series = {Springer {{Texts}} in {{Statistics}}}
}

@article{marsmanBayesian2017,
  title = {Bayesian Benefits with {{JASP}}},
  author = {Marsman, Maarten and Wagenmakers, Eric-Jan},
  year = {2017},
  volume = {14},
  pages = {545--555},
  issn = {1740-5629},
  doi = {10.1080/17405629.2016.1259614},
  abstract = {We illustrate the Bayesian approach to data analysis using the newly developed statistical software program JASP. With JASP, researchers are able to take advantage of the benefits that the Bayesian framework has to offer in terms of parameter estimation and hypothesis testing. The Bayesian advantages are discussed using real data on the relation between Quality of Life and Executive Functioning in children with Autism Spectrum Disorder.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VWVZEHY3\\Marsman and Wagenmakers - 2017 - Bayesian benefits with JASP.pdf;C\:\\Users\\josue\\Zotero\\storage\\BZDR6CHR\\17405629.2016.html},
  journal = {European Journal of Developmental Psychology},
  keywords = {Bayes factor,Correlation test,credible interval,JASP},
  number = {5}
}

@article{mayoNovel1991,
  title = {Novel {{Evidence}} and {{Severe Tests}}},
  author = {Mayo, Deborah G.},
  year = {1991},
  volume = {58},
  pages = {523--552},
  publisher = {{[The University of Chicago Press, Philosophy of Science Association]}},
  issn = {0031-8248},
  abstract = {While many philosophers of science have accorded special evidential significance to tests whose results are "novel facts", there continues to be disagreement over both the definition of novelty and why it should matter. The view of novelty favored by Giere, Lakatos, Worrall and many others is that of use-novelty: An accordance between evidence e and hypothesis h provides a genuine test of h only if e is not used in h's construction. I argue that what lies behind the intuition that novelty matters is the deeper intuition that severe tests matter. I set out a criterion of severity akin to the notion of a test's power in Neyman-Pearson statistics. I argue that tests which are use-novel may fail to be severe, and tests that are severe may fail to be use-novel. I discuss the 1919 eclipse data as a severe test of Einstein's law of gravity.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\F9AQTRWS\\Mayo - 1991 - Novel Evidence and Severe Tests.pdf},
  journal = {Philosophy of Science},
  number = {4}
}

@incollection{mccullochGeneralized2014,
  title = {Generalized {{Linear Mixed Models}}},
  booktitle = {Wiley {{StatsRef}}: {{Statistics Reference Online}}},
  author = {Mcculloch, Charles E. and Neuhaus, John M.},
  year = {2014},
  publisher = {{American Cancer Society}},
  doi = {10.1002/9781118445112.stat07540},
  abstract = {Generalized linear mixed models (GLMMs) are a class of models that incorporates random effects into the linear predictor of a generalized linear model (GLM). This allows the modeling of correlated data within the context of GLMs and greatly extends their breadth of applicability. They thus include both linear mixed models (LMMs) and GLMs as special cases.},
  copyright = {Copyright \textcopyright{} 2013 John Wiley \& Sons, Ltd. All rights reserved.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\R5GGPSHR\\Mcculloch and Neuhaus - 2014 - Generalized Linear Mixed Models.pdf;C\:\\Users\\josue\\Zotero\\storage\\S82MFB55\\9781118445112.html},
  isbn = {978-1-118-44511-2},
  language = {en}
}

@book{mcelreathStatistical2018,
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{Stan}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2018},
  edition = {First},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/9781315372495},
  file = {C\:\\Users\\josue\\Zotero\\storage\\45LJAW9J\\McElreath - 2018 - Statistical Rethinking A Bayesian Course with Exa.pdf},
  isbn = {978-1-315-37249-5},
  language = {en}
}

@article{mcnallyCan2016,
  title = {Can Network Analysis Transform Psychopathology?},
  author = {McNally, Richard J.},
  year = {2016},
  volume = {86},
  pages = {95--104},
  issn = {00057967},
  doi = {10.1016/j.brat.2016.06.006},
  file = {C\:\\Users\\josue\\Zotero\\storage\\9SRHTUPZ\\McNally - 2016 - Can network analysis transform psychopathology.pdf},
  journal = {Behaviour Research and Therapy},
  language = {en}
}

@article{mcnallyComorbid2017,
  title = {Co-Morbid Obsessive\textendash{}Compulsive Disorder and Depression: A {{Bayesian}} Network Approach},
  shorttitle = {Co-Morbid Obsessive\textendash{}Compulsive Disorder and Depression},
  author = {McNally, R. J. and Mair, P. and Mugno, B. L. and Riemann, B. C.},
  year = {2017},
  volume = {47},
  pages = {1204--1214},
  issn = {0033-2917, 1469-8978},
  doi = {10.1017/S0033291716003287},
  abstract = {Background. Obsessive\textendash{}compulsive disorder (OCD) is often co-morbid with depression. Using the methods of network analysis, we computed two networks that disclose the potentially causal relationships among symptoms of these two disorders in 408 adult patients with primary OCD and co-morbid depression symptoms.
Method. We examined the relationship between the symptoms constituting these syndromes by computing a (regularized) partial correlation network via the graphical LASSO procedure, and a directed acyclic graph (DAG) via a Bayesian hill-climbing algorithm.
Results. The results suggest that the degree of interference and distress associated with obsessions, and the degree of interference associated with compulsions, are the chief drivers of co-morbidity. Moreover, activation of the depression cluster appears to occur solely through distress associated with obsessions activating sadness \textendash{} a key symptom that `bridges' the two syndromic clusters in the DAG.
Conclusions. Bayesian analysis can expand the repertoire of network analytic approaches to psychopathology. We discuss clinical implications and limitations of our findings.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IHUEAVQ2\\McNally et al. - 2017 - Co-morbid obsessive–compulsive disorder and depres.pdf},
  journal = {Psychological Medicine},
  language = {en},
  number = {7}
}

@article{mcnallyMental2015,
  title = {Mental {{Disorders}} as {{Causal Systems}}: {{A Network Approach}} to {{Posttraumatic Stress Disorder}}},
  shorttitle = {Mental {{Disorders}} as {{Causal Systems}}},
  author = {McNally, Richard J. and Robinaugh, Donald J. and Wu, Gwyneth W. Y. and Wang, Li and Deserno, Marie K. and Borsboom, Denny},
  year = {2015},
  volume = {3},
  pages = {836--849},
  publisher = {{SAGE Publications Inc}},
  issn = {2167-7026},
  doi = {10.1177/2167702614553230},
  abstract = {Debates about posttraumatic stress disorder (PTSD) often turn on whether it is a timeless, cross-culturally valid natural phenomenon or a socially constructed idiom of distress. Most clinicians seem to favor the first view, differing only in whether they conceptualize PTSD as a discrete category or the upper end of a dimension of stress responsiveness. Yet both categorical and dimensional construals presuppose that PTSD symptoms are fallible indicators reflective of an underlying, latent variable. This presupposition has governed psychopathology research for decades, but it rests on problematic psychometric premises. In this article, we review an alternative, network perspective for conceptualizing mental disorders as causal systems of interacting symptoms, and we illustrate this perspective via analyses of PTSD symptoms reported by survivors of the Wenchuan earthquake in China. Finally, we foreshadow emerging computational methods that may disclose the causal structure of mental disorders.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\QKIDTMF5\\McNally et al. - 2015 - Mental Disorders as Causal Systems A Network Appr.pdf},
  journal = {Clinical Psychological Science},
  number = {6}
}

@article{mcneishThanks2018,
  title = {Thanks Coefficient Alpha, We'll Take It from Here.},
  author = {McNeish, Daniel},
  year = {2018},
  volume = {23},
  pages = {412--433},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000144},
  abstract = {Empirical studies in psychology commonly report Cronbach's alpha as a measure of internal consistency reliability despite the fact that many methodological studies have shown that Cronbach's alpha is riddled with problems stemming from unrealistic assumptions. In many circumstances, violating these assumptions yields estimates of reliability that are too small, making measures look less reliable than they actually are. Although methodological critiques of Cronbach's alpha are being cited with increasing frequency in empirical studies, in this tutorial we discuss how the trend is not necessarily improving methodology used in the literature. That is, many studies continue to use Cronbach's alpha without regard for its assumptions or merely cite methodological articles advising against its use to rationalize unfavorable Cronbach's alpha estimates. This tutorial first provides evidence that recommendations against Cronbach's alpha have not appreciably changed how empirical studies report reliability. Then, we summarize the drawbacks of Cronbach's alpha conceptually without relying on mathematical or simulation-based arguments so that these arguments are accessible to a broad audience. We continue by discussing several alternative measures that make less rigid assumptions which provide justifiably higher estimates of reliability compared to Cronbach's alpha. We conclude with empirical examples to illustrate advantages of alternative measures of reliability including omega total, Revelle's omega total, the greatest lower bound, and Coefficient H. A detailed software appendix is also provided to help researchers implement alternative methods.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\92NQVW3K\\McNeish - 2018 - Thanks coefficient alpha, we’ll take it from here..pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {3}
}

@article{mcneishUsing2015,
  title = {Using {{Lasso}} for {{Predictor Selection}} and to {{Assuage Overfitting}}: {{A Method Long Overlooked}} in {{Behavioral Sciences}}},
  shorttitle = {Using {{Lasso}} for {{Predictor Selection}} and to {{Assuage Overfitting}}},
  author = {McNeish, Daniel M.},
  year = {2015},
  volume = {50},
  pages = {471--484},
  issn = {0027-3171, 1532-7906},
  doi = {10.1080/00273171.2015.1036965},
  file = {C\:\\Users\\josue\\Zotero\\storage\\JKAMJJFP\\McNeish - 2015 - Using Lasso for Predictor Selection and to Assuage.pdf},
  journal = {Multivariate Behavioral Research},
  language = {en},
  number = {5}
}

@article{meehlTheoryTesting1967a,
  title = {Theory-{{Testing}} in {{Psychology}} and {{Physics}}: {{A Methodological Paradox}}},
  shorttitle = {Theory-{{Testing}} in {{Psychology}} and {{Physics}}},
  author = {Meehl, Paul E.},
  year = {1967},
  volume = {34},
  pages = {103--115},
  publisher = {{[The University of Chicago Press, Philosophy of Science Association]}},
  issn = {0031-8248},
  abstract = {Because physical theories typically predict numerical values, an improvement in experimental precision reduces the tolerance range and hence increases corroborability. In most psychological research, improved power of a statistical design leads to a prior probability approaching 1/2 of finding a significant difference in the theoretically predicted direction. Hence the corroboration yielded by "success" is very weak, and becomes weaker with increased precision. "Statistical significance" plays a logical role in psychology precisely the reverse of its role in physics. This problem is worsened by certain unhealthy tendencies prevalent among psychologists, such as a premium placed on experimental "cuteness" and a free reliance upon ad hoc explanations to avoid refutation.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\PEZSCVHF\\Meehl - 1967 - Theory-Testing in Psychology and Physics A Method.pdf},
  journal = {Philosophy of Science},
  number = {2}
}

@article{meinshausenHighdimensional2006,
  title = {High-Dimensional Graphs and Variable Selection with the {{Lasso}}},
  author = {Meinshausen, Nicolai and B{\"u}hlmann, Peter},
  year = {2006},
  volume = {34},
  pages = {1436--1462},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/009053606000000281},
  abstract = {The pattern of zero entries in the inverse covariance matrix of a multivariate normal distribution corresponds to conditional independence restrictions between variables. Covariance selection aims at estimating those structural zeros from data. We show that neighborhood selection with the Lasso is a computationally attractive alternative to standard covariance selection for sparse high-dimensional graphs. Neighborhood selection estimates the conditional independence restrictions separately for each node in the graph and is hence equivalent to variable selection for Gaussian linear models. We show that the proposed neighborhood selection scheme is consistent for sparse high-dimensional graphs. Consistency hinges on the choice of the penalty parameter. The oracle value for optimal prediction does not lead to a consistent neighborhood estimate. Controlling instead the probability of falsely joining some distinct connectivity components of the graph, consistent estimation for sparse graphs is achieved (with exponential rates), even when the number of variables grows as the number of observations raised to an arbitrary power.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\N3RQ7JXC\\Meinshausen and Bühlmann - 2006 - High-dimensional graphs and variable selection wit.pdf;C\:\\Users\\josue\\Zotero\\storage\\SMZNKDFE\\1152540754.html},
  journal = {The Annals of Statistics},
  keywords = {covariance selection,Gaussian graphical models,Linear regression,penalized regression},
  language = {en},
  mrnumber = {MR2278363},
  number = {3},
  zmnumber = {1113.62082}
}

@book{mincerEconomic1969,
  title = {Economic Forecasts and Expectations: Analyses of Forecasting Behavior and Performance},
  shorttitle = {Economic Forecasts and Expectations},
  editor = {Mincer, Jacob},
  year = {1969},
  publisher = {{National Bureau of Economic Research [u.a.]}},
  address = {{New York}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\9YG3NKUS\\c1214.pdf},
  isbn = {978-0-87014-202-4},
  language = {en},
  note = {OCLC: 70334},
  number = {19},
  series = {Studies in Business Cycles}
}

@article{minzenbergMetaanalysis2009,
  title = {Meta-Analysis of 41 {{Functional Neuroimaging Studies}} of {{Executive Function}} in {{Schizophrenia}}},
  author = {Minzenberg, Michael J. and Laird, Angela R. and Thelen, Sarah and Carter, Cameron S. and Glahn, David C.},
  year = {2009},
  volume = {66},
  pages = {811},
  issn = {0003-990X},
  doi = {10.1001/archgenpsychiatry.2009.91},
  file = {C\:\\Users\\josue\\Zotero\\storage\\CYY3UMAY\\Minzenberg et al. - 2009 - Meta-analysis of 41 Functional Neuroimaging Studie.pdf},
  journal = {Archives of General Psychiatry},
  language = {en},
  number = {8}
}

@article{mitchellpowerful2016,
  title = {Towards Powerful Experimental and Statistical Approaches to Study Intraindividual Variability in Labile Traits},
  author = {Mitchell, David J. and Fanson, Benjamin G. and Beckmann, Christa and Biro, Peter A.},
  year = {2016},
  volume = {3},
  pages = {160352},
  issn = {2054-5703, 2054-5703},
  doi = {10.1098/rsos.160352},
  file = {C\:\\Users\\josue\\Zotero\\storage\\68TBGJ82\\Mitchell et al. - 2016 - Towards powerful experimental and statistical appr.pdf},
  journal = {Royal Society Open Science},
  language = {en},
  number = {10}
}

@article{mohammedBayesian2019,
  title = {Bayesian Variable Selection Using Spike-and-Slab Priors with Application to High Dimensional Electroencephalography Data by Local Modelling},
  author = {Mohammed, Shariq and Dey, Dipak K. and Zhang, Yuping},
  year = {2019},
  volume = {68},
  pages = {1305--1326},
  issn = {1467-9876},
  doi = {10.1111/rssc.12369},
  abstract = {Because of the immense technological advances, very often we encounter data in high dimensions. Any set of measurements taken at multiple time points for multiple subjects leads to data of more than two dimensions (a matrix of covariates for each subject). We present a Bayesian variable-selection method to identify the active regions in the brain as a response to a certain stimulus. We build binary classification models of subject level responses by using binary regression with Gaussian models on the latent variables. We also study the scaled normal priors on the latent variables, as they cover a large family of distributions. We use continuous spike-and-slab priors to incorporate variable selection within the modelling. Because of the computational complexity, we build many local (at different time points) models and make predictions by utilizing the temporal structure between the local models. We perform two-stage variable selection for each of these local models. We demonstrate the effectiveness of such modelling through the results of a simulation study. We then present the performance of these models on multisubject neuroimaging (electroencephalography) data to study the effects on the functional states of the frontal cortex and parietal lobe for chronic exposure of alcohol.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\T3BF8WF2\\Mohammed et al. - 2019 - Bayesian variable selection using spike-and-slab p.pdf;C\:\\Users\\josue\\Zotero\\storage\\2RB4LEIG\\rssc.html},
  journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  keywords = {Local Bayesian modelling,Multisubject neuroimaging,Parallel computing,Scale mixture of normal links,Spatial clustering},
  language = {en},
  number = {5}
}

@misc{moreyorder,
  title = {Order Constraints | {{Richard D}}. {{Morey}}},
  author = {Morey, Richard},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HTUKNRX8\\order-constraints.html},
  language = {en-US}
}

@article{moreyphilosophy2016,
  title = {The Philosophy of {{Bayes}} Factors and the Quantification of Statistical Evidence},
  author = {Morey, Richard D. and Romeijn, Jan-Willem and Rouder, Jeffrey N.},
  year = {2016},
  volume = {72},
  pages = {6--18},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2015.11.001},
  abstract = {A core aspect of science is using data to assess the degree to which data provide evidence for competing claims, hypotheses, or theories. Evidence is by definition something that should change the credibility of a claim in a reasonable person's mind. However, common statistics, such as significance testing and confidence intervals have no interface with concepts of belief, and thus it is unclear how they relate to statistical evidence. We explore the concept of statistical evidence, and how it can be quantified using the Bayes factor. We also discuss the philosophical issues inherent in the use of the Bayes factor.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\64ICL8MG\\Morey et al. - 2016 - The philosophy of Bayes factors and the quantifica.pdf;C\:\\Users\\josue\\Zotero\\storage\\FTX9MFPY\\S0022249615000723.html},
  journal = {Journal of Mathematical Psychology},
  keywords = {Bayes factor,Hypothesis testing},
  series = {Bayes {{Factors}} for {{Testing Hypotheses}} in {{Psychological Research}}: {{Practical Relevance}} and {{New Developments}}}
}

@article{moreySimple2014,
  title = {Simple Relation between {{Bayesian}} Order-Restricted and Point-Null Hypothesis Tests},
  author = {Morey, Richard D. and Wagenmakers, Eric-Jan},
  year = {2014},
  volume = {92},
  pages = {121--124},
  issn = {01677152},
  doi = {10.1016/j.spl.2014.05.010},
  abstract = {One of the main challenges facing potential users of Bayes factors as an inferential technique is the difficulty of computing them. We highlight a useful relationship that allows certain order-restricted and sign-restricted Bayes factors, such as one-sided Bayes factor tests, to be computed with ease.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\23ZNKKNK\\Morey and Wagenmakers - 2014 - Simple relation between Bayesian order-restricted .pdf},
  journal = {Statistics \& Probability Letters},
  language = {en}
}

@article{mulderBayes2014,
  title = {Bayes Factors for Testing Inequality Constrained Hypotheses: {{Issues}} with Prior Specification},
  shorttitle = {Bayes Factors for Testing Inequality Constrained Hypotheses},
  author = {Mulder, Joris},
  year = {2014},
  volume = {67},
  pages = {153--171},
  issn = {2044-8317},
  doi = {10.1111/bmsp.12013},
  abstract = {Several issues are discussed when testing inequality constrained hypotheses using a Bayesian approach. First, the complexity (or size) of the inequality constrained parameter spaces can be ignored. This is the case when using the posterior probability that the inequality constraints of a hypothesis hold, Bayes factors based on non-informative improper priors, and partial Bayes factors based on posterior priors. Second, the Bayes factor may not be invariant for linear one-to-one transformations of the data. This can be observed when using balanced priors which are centred on the boundary of the constrained parameter space with a diagonal covariance structure. Third, the information paradox can be observed. When testing inequality constrained hypotheses, the information paradox occurs when the Bayes factor of an inequality constrained hypothesis against its complement converges to a constant as the evidence for the first hypothesis accumulates while keeping the sample size fixed. This paradox occurs when using Zellner's g prior as a result of too much prior shrinkage. Therefore, two new methods are proposed that avoid these issues. First, partial Bayes factors are proposed based on transformed minimal training samples. These training samples result in posterior priors that are centred on the boundary of the constrained parameter space with the same covariance structure as in the sample. Second, a g prior approach is proposed by letting g go to infinity. This is possible because the Jeffreys\textendash{}Lindley paradox is not an issue when testing inequality constrained hypotheses. A simulation study indicated that the Bayes factor based on this g prior approach converges fastest to the true inequality constrained hypothesis.},
  copyright = {\textcopyright{} 2013 The British Psychological Society},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ZJDNFQ3J\\Mulder - 2014 - Bayes factors for testing inequality constrained h.pdf;C\:\\Users\\josue\\Zotero\\storage\\VVI4VDDM\\bmsp.html},
  journal = {British Journal of Mathematical and Statistical Psychology},
  language = {en},
  number = {1}
}

@article{mulderBayes2016,
  title = {Bayes Factors for Testing Order-Constrained Hypotheses on Correlations},
  author = {Mulder, Joris},
  year = {2016},
  volume = {72},
  pages = {104--115},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2014.09.004},
  abstract = {Correlation coefficients play a key role in the social and behavioral sciences for quantifying the degree of linear association between variables. A Bayes factor is proposed that allows researchers to test hypotheses with order constraints on correlation coefficients in a direct manner. This Bayes factor balances between fit and complexity of order-constrained hypotheses in a natural way. A diffuse prior on the correlation matrix is used that minimizes prior shrinkage and results in most evidence for an order-constrained hypothesis that is supported by the data. An efficient method is proposed for the computation of the Bayes factor. A key aspect in the computation is a Fisher Z transformation on the posterior distribution of the correlations such that an approximately normal distribution is obtained. The methodology is implemented in a freely downloadable software program called ``BOCOR''. The methods are applied to a multitrait\textendash{}multimethod analysis, a repeated measures study, and a study on directed moderator effects.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\EK8AI8BM\\Mulder - 2016 - Bayes factors for testing order-constrained hypoth.pdf;C\:\\Users\\josue\\Zotero\\storage\\96XGWAAG\\S0022249614000601.html},
  journal = {Journal of Mathematical Psychology},
  keywords = {Bayes factor,Bivariate correlations,MCMC computation,Order constraints},
  series = {Bayes {{Factors}} for {{Testing Hypotheses}} in {{Psychological Research}}: {{Practical Relevance}} and {{New Developments}}}
}

@article{mulderBayes2018,
  title = {Bayes Factor Testing of Equality and Order Constraints on Measures of Association in Social Research},
  author = {Mulder, Joris and Gelissen, John P. T. M.},
  year = {2018},
  abstract = {Measures of association play a central role in the social sciences to quantify the strength of a linear relationship between the variables of interest. In many applications researchers can translate scientific expectations to hypotheses with equality and/or order constraints on these measures of association. In this paper a Bayes factor test is proposed for testing multiple hypotheses with constraints on the measures of association between ordinal and/or continuous variables, possibly after correcting for certain covariates. This test can be used to obtain a direct answer to the research question how much evidence there is in the data for a social science theory relative to competing theories. The accompanying software package `BCT' allows users to apply the methodology in an easy manner. An empirical application from leisure studies about the associations between life, leisure and relationship satisfaction and an application about the differences about egalitarian justice beliefs across countries are used to illustrate the methodology.},
  archivePrefix = {arXiv},
  eprint = {1807.05819},
  eprinttype = {arxiv},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ETRS39M7\\Mulder and Gelissen - 2018 - Bayes factor testing of equality and order constra.pdf;C\:\\Users\\josue\\Zotero\\storage\\4FFN8S3I\\1807.html},
  journal = {arXiv:1807.05819 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{mulderBayes2019,
  title = {Bayes Factor Testing of Multiple Intraclass Correlations},
  author = {Mulder, Joris and Fox, J.-P.},
  year = {2019},
  volume = {14},
  pages = {521--552},
  issn = {1936-0975},
  doi = {10.1214/18-BA1115},
  file = {C\:\\Users\\josue\\Zotero\\storage\\NPADBLKM\\Mulder and Fox - 2019 - Bayes factor testing of multiple intraclass correl.pdf;C\:\\Users\\josue\\Zotero\\storage\\CTEJT44N\\bayes-factor-testing-of-multiple-intraclass-correlations.html},
  journal = {Bayesian Analysis},
  language = {English},
  number = {2}
}

@article{mulderBayesian2009,
  title = {Bayesian Model Selection of Informative Hypotheses for Repeated Measurements},
  author = {Mulder, Joris and Klugkist, Irene and {van de Schoot}, Rens and Meeus, Wim H.J. and Selfhout, Maarten and Hoijtink, Herbert},
  year = {2009},
  volume = {53},
  pages = {530--546},
  issn = {00222496},
  doi = {10.1016/j.jmp.2009.09.003},
  abstract = {When analyzing repeated measurements data, researchers often have expectations about the relations between the measurement means. The expectations can often be formalized using equality and inequality constraints between (i) the measurement means over time, (ii) the measurement means between groups, (iii) the means adjusted for time-invariant covariates, and (iv) the means adjusted for time-varying covariates. The result is a set of informative hypotheses. In this paper, the Bayes factor is used to determine which hypothesis receives most support from the data. A pivotal element in the Bayesian framework is the specification of the prior. To avoid subjective prior specification, training data in combination with restrictions on the measurement means are used to obtain so-called constrained posterior priors. A simulation study and an empirical example from developmental psychology show that this prior results in Bayes factors with desirable properties.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\K3VSNUTQ\\Mulder et al. - 2009 - Bayesian model selection of informative hypotheses.pdf},
  journal = {Journal of Mathematical Psychology},
  language = {en},
  number = {6}
}

@article{mulderBayesian2013,
  title = {Bayesian Tests on Components of the Compound Symmetry Covariance Matrix},
  author = {Mulder, Joris and Fox, J.-P.},
  year = {2013},
  volume = {23},
  pages = {109--122},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-011-9295-3},
  abstract = {Complex dependency structures are often conditionally modeled, where random effects parameters are used to specify the natural heterogeneity in the population. When interest is focused on the dependency structure, inferences can be made from a complex covariance matrix using a marginal modeling approach. In this marginal modeling framework, testing covariance parameters is not a boundary problem. Bayesian tests on covariance parameter(s) of the compound symmetry structure are proposed assuming multivariate normally distributed observations. Innovative proper prior distributions are introduced for the covariance components such that the positive definiteness of the (compound symmetry) covariance matrix is ensured. Furthermore, it is shown that the proposed priors on the covariance parameters lead to a balanced Bayes factor, in case of testing an inequality constrained hypothesis. As an illustration, the proposed Bayes factor is used for testing (non-)invariant intra-class correlations across different group types (public and Catholic schools), using the 1982 High School and Beyond survey data.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\DE9GUFAZ\\Mulder and Fox - 2013 - Bayesian tests on components of the compound symme.pdf},
  journal = {Statistics and Computing},
  language = {en},
  number = {1}
}

@article{mulderBIC2019,
  title = {{{BIC Extensions}} for {{Order}}-Constrained {{Model Selection}}},
  author = {Mulder, J. and Raftery, A. E.},
  year = {2019},
  pages = {0049124119882459},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124119882459},
  abstract = {The Schwarz or Bayesian information criterion (BIC) is one of the most widely used tools for model comparison in social science research. The BIC, however, is not suitable for evaluating models with order constraints on the parameters of interest. This article explores two extensions of the BIC for evaluating order-constrained models, one where a truncated unit information prior is used under the order-constrained model and the other where a truncated local unit information prior is used. The first prior is centered on the maximum likelihood estimate, and the latter prior is centered on a null value. Several analyses show that the order-constrained BIC based on the local unit information prior works better as an Occam's razor for evaluating order-constrained models and results in lower error probabilities. The methodology based on the local unit information prior is implemented in the R package ``BICpack'' which allows researchers to easily apply the method for order-constrained model selection. The usefulness of the methodology is illustrated using data from the European Values Study.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\I76UDZPV\\Mulder and Raftery - 2019 - BIC Extensions for Order-constrained Model Selecti.pdf},
  journal = {Sociological Methods \& Research},
  language = {en}
}

@article{mulderBIEMS2012,
  title = {{{BIEMS}}: {{A Fortran}} 90 {{Program}} for {{Calculating Bayes Factors}} for {{Inequality}} and {{Equality Constrained Models}}},
  shorttitle = {{{BIEMS}}},
  author = {Mulder, Joris and Hoijtink, Herbert and de Leeuw, Christiaan},
  year = {2012},
  volume = {46},
  pages = {1--39},
  issn = {1548-7660},
  doi = {10.18637/jss.v046.i02},
  copyright = {Copyright (c) 2010 Joris Mulder, Herbert Hoijtink, Christiaan de Leeuw},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4UGYRR48\\Mulder et al. - 2012 - BIEMS A Fortran 90 Program for Calculating Bayes .pdf;C\:\\Users\\josue\\Zotero\\storage\\GC96DUVT\\v046i02.html},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{mulderEquality2010,
  title = {Equality and Inequality Constrained Multivariate Linear Models: {{Objective}} Model Selection Using Constrained Posterior Priors},
  shorttitle = {Equality and Inequality Constrained Multivariate Linear Models},
  author = {Mulder, Joris and Hoijtink, Herbert and Klugkist, Irene},
  year = {2010},
  volume = {140},
  pages = {887--906},
  issn = {03783758},
  doi = {10.1016/j.jspi.2009.09.022},
  journal = {Journal of Statistical Planning and Inference},
  language = {en},
  number = {4}
}

@article{mulderMixtures2020,
  title = {Mixtures of Peaked Power {{Batschelet}} Distributions for Circular Data with Application to Saccade Directions},
  author = {Mulder, Kees and Klugkist, Irene and {van Renswoude}, Daan and Visser, Ingmar},
  year = {2020},
  volume = {95},
  pages = {102309},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2019.102309},
  abstract = {Circular data are encountered throughout a variety of scientific disciplines, such as in eye movement research as the direction of saccades. Motivated by such applications, mixtures of peaked circular distributions are developed. The peaked distributions are a novel family of Batschelet-type distributions, where the shape of the distribution is warped by means of a transformation function. Because the Inverse Batschelet distribution features an implicit inverse that is not computationally feasible for large or complex data, an alternative called the Power Batschelet distribution is introduced. This distribution is easy to compute and mimics the behavior of the Inverse Batschelet distribution. Inference is performed in both the frequentist framework, through Expectation\textendash{}Maximization (EM) and the bootstrap, and the Bayesian framework, through MCMC. All parameters can be fixed, which may be done by assumption to reduce the number of parameters. Model comparison can be performed through information criteria or through bridge sampling in the Bayesian framework, which allows performing a wealth of hypothesis tests through the Bayes factor. An R package, flexcircmix, is available to perform these analyses.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\A6XIYDBC\\Mulder et al. - 2020 - Mixtures of peaked power Batschelet distributions .pdf;C\:\\Users\\josue\\Zotero\\storage\\XSLV8KDD\\S0022249619301671.html},
  journal = {Journal of Mathematical Psychology},
  keywords = {Circular statistics,Metropolis–Hastings,Peaked distributions},
  language = {en}
}

@article{mulderPrior2014,
  title = {Prior Adjusted Default {{Bayes}} Factors for Testing (in)Equality Constrained Hypotheses},
  author = {Mulder, Joris},
  year = {2014},
  volume = {71},
  pages = {448--463},
  issn = {01679473},
  doi = {10.1016/j.csda.2013.07.017},
  file = {C\:\\Users\\josue\\Zotero\\storage\\779FBUGW\\Mulder - 2014 - Prior adjusted default Bayes factors for testing (.pdf},
  journal = {Computational Statistics \& Data Analysis},
  language = {en}
}

@article{mulderSimple2019,
  title = {Simple {{Bayesian}} Testing of Scientific Expectations in Linear Regression Models},
  author = {Mulder, Joris and {Olsson-Collentine}, A.},
  year = {2019},
  volume = {51},
  pages = {1117--1130},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-01196-9},
  abstract = {Scientific theories can often be formulated using equality and order constraints on the relative effects in a linear regression model. For example, it may be expected that the effect of the first predictor is larger than the effect of the second predictor, and the second predictor is expected to be larger than the third predictor. The goal is then to test such expectations against competing scientific expectations or theories. In this paper, a simple default Bayes factor test is proposed for testing multiple hypotheses with equality and order constraints on the effects of interest. The proposed testing criterion can be computed without requiring external prior information about the expected effects before observing the data. The method is implemented in R-package called `lmhyp' which is freely downloadable and ready to use. The usability of the method and software is illustrated using empirical applications from the social and behavioral sciences.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VEWWP5KI\\Mulder and Olsson-Collentine - 2019 - Simple Bayesian testing of scientific expectations.pdf},
  journal = {Behavior Research Methods},
  keywords = {Bayes factors,Bayesian hypothesis testing,Equality and order constraints,Regression modeling},
  language = {en},
  number = {3}
}

@article{nesselroadeIntraindividual2001,
  title = {Intraindividual Variability in Development within and between Individuals},
  author = {Nesselroade, John R.},
  year = {2001},
  volume = {6},
  pages = {187--193},
  issn = {1016-9040},
  doi = {http://dx.doi.org/10.1027//1016-9040.6.3.187},
  abstract = {A focus on the study of development and other kinds of changes in the whole individual has been one of the hallmarks of research by D. Magnusson and his colleagues. A number of different approaches emphasize this individual focus in their respective ways. This presentation focuses on intraindividual variability stemming from Cattell's P-technique factor analytic proposals (R. B. Cattell, 1947, 1963), making several refinements to make it more tractable from a research design standpoint and more appropriate from a statistical analysis perspective. The associated methods make it possible to study intraindividual variability both within and between individuals. An empirical example is used to illustrate the procedure. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  copyright = {\textcopyright{} 2001, Hogrefe \& Huber Publishers},
  file = {C\:\\Users\\josue\\Zotero\\storage\\A9HGRWSQ\\Nesselroade - 2001 - Intraindividual variability in development within .pdf},
  journal = {European Psychologist},
  keywords = {Cattell's P-technique,D. Magnusson,development,factor analysis,Human,intraindividual variability},
  language = {English},
  number = {3}
}

@article{neuhausWithinCluster1998,
  title = {Between- and {{Within}}-{{Cluster Covariate Effects}} in the {{Analysis}} of {{Clustered Data}}},
  author = {Neuhaus, J. M. and Kalbfleisch, J. D.},
  year = {1998},
  volume = {54},
  pages = {638--645},
  issn = {0006-341X},
  doi = {10.2307/3109770},
  abstract = {Standard methods for the regression analysis of clustered data postulate models relating covariates to the response without regard to between- and within-cluster covariate effects. Implicit in these analyses is the assumption that these effects are identical. Example data show that this is frequently not the case and that analyses that ignore differential between- and within-cluster covariate effects can be misleading. Consideration of between- and within-cluster effects also helps to explain observed and theoretical differences between mixture model analyses and those based on conditional likelihood methods. In particular, we show that conditional likelihood methods estimate purely within-cluster covariate effects, whereas mixture model approaches estimate a weighted average of between- and within-cluster covariate effects.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\UCV3JRYS\\Neuhaus and Kalbfleisch - 1998 - Between- and Within-Cluster Covariate Effects in t.pdf},
  journal = {Biometrics},
  number = {2}
}

@article{opsahlNode2010,
  title = {Node Centrality in Weighted Networks: {{Generalizing}} Degree and Shortest Paths},
  shorttitle = {Node Centrality in Weighted Networks},
  author = {Opsahl, Tore and Agneessens, Filip and Skvoretz, John},
  year = {2010},
  volume = {32},
  pages = {245--251},
  issn = {03788733},
  doi = {10.1016/j.socnet.2010.03.006},
  abstract = {Ties often have a strength naturally associated with them that differentiate them from each other. Tie strength has been operationalized as weights. A few network measures have been proposed for weighted networks, including three common measures of node centrality: degree, closeness, and betweenness. However, these generalizations have solely focused on tie weights, and not on the number of ties, which was the central component of the original measures. This paper proposes generalizations that combine both these aspects. We illustrate the benefits of this approach by applying one of them to Freeman's EIES dataset.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\5C4NBYE9\\Opsahl et al. - 2010 - Node centrality in weighted networks Generalizing.pdf},
  journal = {Social Networks},
  language = {en},
  number = {3}
}

@book{pangSpike2009,
  title = {Spike and {{Slab Prior Distributions}} for {{Simultaneous Bayesian Hypothesis Testing}}, {{Model Selection}}, and {{Prediction}}, of {{Nonlinear Outcomes}}},
  author = {Pang, Xun and Gill, Jeff},
  year = {2009},
  abstract = {A small body of literature has used the spike and slab prior specification for model selection with strictly linear outcomes. In this setup a two-component mixture dis-tribution is stipulated for coefficients of interest with one part centered at zero with very high precision (the spike) and the other as a distribution diffusely centered at the research hypothesis (the slab). With the selective shrinkage, this setup incorporates the zero coefficient contingency directly into the modeling process to produce pos-terior probabilities for hypothesized outcomes. We extend the model to qualitative responses by designing a hierarchy of forms over both the parameter and model spaces to achieve variable selection, model averaging, and individual coefficient hypothesis testing. To overcome the technical challenges in estimating the marginal posterior distributions possibly with a dramatic ratio of density heights of the spike to the slab, we develop a hybrid Gibbs sampling algorithm using an adaptive rejection ap-proach for various discrete outcome models, including dichotomous, polychotomous, and count responses. The performance of the models and methods are assessed with both Monte Carlo experiments and empirical applications in political science.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KMXX8EUW\\Pang and Gill - Spike and Slab Prior Distributions for Simultaneou.pdf;C\:\\Users\\josue\\Zotero\\storage\\ZEUUUGXL\\summary.html}
}

@book{pearlCausality2009,
  title = {Causality},
  author = {Pearl, Judea},
  year = {2009},
  publisher = {{Cambridge University Press}},
  abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 5,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\GCG3KC3H\\Pearl - 2009 - Causality.pdf},
  googlebooks = {f4nuexsNVZIC},
  isbn = {978-0-521-89560-6},
  keywords = {Computers / Intelligence (AI) \& Semantics,Mathematics / History \& Philosophy,Philosophy / Movements / Analytic,Science / Philosophy \& Social Aspects,Social Science / Research},
  language = {en}
}

@article{peterbuhlmannHighDimensional2014,
  title = {High-{{Dimensional Statistics}} with a {{View Toward Applications}} in {{Biology}}},
  author = {{Peter B{\"u}hlmann} and Kalisch, Markus and Meier, Lukas},
  year = {2014},
  volume = {1},
  pages = {255--278},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-022513-115545},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ZKRJ3KTK\\Bühlmann et al. - 2014 - High-Dimensional Statistics with a View Toward App.pdf},
  journal = {Annual Review of Statistics and Its Application},
  language = {en},
  number = {1}
}

@article{plattStrong,
  title = {Strong {{Inference}}},
  author = {Platt, John},
  volume = {146},
  pages = {8},
  file = {C\:\\Users\\josue\\Zotero\\storage\\CZCTL5LD\\Strong Inference.pdf},
  language = {en}
}

@article{plummerJAGS2003,
  title = {{{JAGS}}: {{A}} Program for Analysis of {{Bayesian}} Graphical Models Using {{Gibbs}} Sampling},
  author = {Plummer, Martyn},
  year = {2003},
  pages = {8},
  abstract = {JAGS is a program for Bayesian Graphical modelling which aims for compatibility with Classic BUGS. The program could eventually be developed as an R package. This article explains the motivations for this program, briefly describes the architecture and then discusses some ideas for a vectorized form of the BUGS language.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\PBKHVTYF\\Plummer - 2003 - JAGS A program for analysis of Bayesian graphical.pdf},
  journal = {Working Papers},
  language = {en}
}

@book{popperConjectures2014,
  title = {Conjectures and Refutations: {{The}} Growth of Scientific Knowledge},
  author = {Popper, Karl},
  year = {2014},
  publisher = {{routledge}}
}

@misc{Prior,
  title = {Prior Adjusted Default {{Bayes}} Factors for Testing (in)Equality Constrained Hypotheses | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.csda.2013.07.017},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VX6PL4IG\\S0167947313002624.html},
  language = {en}
}

@article{raghubarWorking2010,
  title = {Working Memory and Mathematics: {{A}} Review of Developmental, Individual Difference, and Cognitive Approaches},
  shorttitle = {Working Memory and Mathematics},
  author = {Raghubar, Kimberly P. and Barnes, Marcia A. and Hecht, Steven A.},
  year = {2010},
  volume = {20},
  pages = {110--122},
  issn = {1041-6080},
  doi = {10.1016/j.lindif.2009.10.005},
  abstract = {Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HI5T6EH3\\Raghubar et al. - 2010 - Working memory and mathematics A review of develo.pdf;C\:\\Users\\josue\\Zotero\\storage\\QD3UGX9D\\S1041608009000788.html},
  journal = {Learning and Individual Differences},
  keywords = {Development,Dual task studies,Individual differences,Mathematical processing,Working memory},
  language = {en},
  number = {2},
  series = {Perspectives on {{Math Difficulty}} and {{Disability}} in {{Children}}}
}

@article{rastMixedEffects2018,
  title = {A {{Mixed}}-{{Effects Location Scale Model}} for {{Dyadic Interactions}}},
  author = {Rast, Philippe and Ferrer, Emilio},
  year = {2018},
  volume = {53},
  pages = {756--775},
  issn = {0027-3171, 1532-7906},
  doi = {10.1080/00273171.2018.1477577},
  abstract = {We present a mixed-effects location scale model (MELSM) for examining the daily dynamics of affect in dyads. The MELSM includes person and time-varying variables to predict the location, or individual means, and the scale, or within-person variances. It also incorporates a submodel to account for between-person variances. The dyadic specification can accommodate individual and partner effects in both the location and the scale components, and allows random effects for all location and scale parameters. All covariances among the random effects, within and across the location and the scale are also estimated. These covariances offer new insights into the interplay of individual mean structures, intra-individual variability, and the influence of partner effects on such factors. To illustrate the model, we use data from 274 couples who provided daily ratings on their positive and negative emotions toward their relationship \textendash{} up to 90 consecutive days. The model is fit using Hamiltonian Monte Carlo methods, and includes subsets of predictors in order to demonstrate the flexibility of this approach. We conclude with a discussion on the usefulness and the limitations of the MELSM for dyadic research.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\36GHJ9KV\\Rast and Ferrer - 2018 - A Mixed-Effects Location Scale Model for Dyadic In.pdf},
  journal = {Multivariate Behavioral Research},
  language = {en},
  number = {5}
}

@article{rastModeling2012,
  title = {Modeling {{Individual Differences}} in {{Within}}-{{Person Variation}} of {{Negative}} and {{Positive Affect}} in a {{Mixed Effects Location Scale Model Using BUGS}}/{{JAGS}}},
  author = {Rast, Philippe and Hofer, Scott M. and Sparks, Catharine},
  year = {2012},
  volume = {47},
  pages = {177--200},
  issn = {0027-3171, 1532-7906},
  doi = {10.1080/00273171.2012.658328},
  file = {C\:\\Users\\josue\\Zotero\\storage\\3TXDD5YG\\Rast et al. - 2012 - Modeling Individual Differences in Within-Person V.pdf},
  journal = {Multivariate Behavioral Research},
  language = {en},
  number = {2}
}

@book{rcoreteamLanguage2019,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  year = {2019},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}}
}

@article{rhemtullaNetwork2016,
  title = {Network Analysis of Substance Abuse and Dependence Symptoms},
  author = {Rhemtulla, Mijke and Fried, Eiko I. and Aggen, Steven H. and Tuerlinckx, Francis and Kendler, Kenneth S. and Borsboom, Denny},
  year = {2016},
  volume = {161},
  pages = {230--237},
  issn = {03768716},
  doi = {10.1016/j.drugalcdep.2016.02.005},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AG9V3EQV\\Rhemtulla et al. - 2016 - Network analysis of substance abuse and dependence.pdf},
  journal = {Drug and Alcohol Dependence},
  language = {en}
}

@article{rindskopfParameterizing1983,
  title = {Parameterizing Inequality Constraints on Unique Variances in Linear Structural Models},
  author = {Rindskopf, David},
  year = {1983},
  volume = {48},
  pages = {73--83},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02314677},
  file = {C\:\\Users\\josue\\Zotero\\storage\\B7G8SP3Y\\Rindskopf - 1983 - Parameterizing inequality constraints on unique va.pdf},
  journal = {Psychometrika},
  language = {en},
  number = {1}
}

@article{robertMaximum1996,
  title = {Maximum {{Likelihood Estimation}} under {{Order Restrictions}} by the {{Prior Feedback Method}}},
  author = {Robert, Christian P. and Gene Hwang, J. T.},
  year = {1996},
  volume = {91},
  pages = {167--172},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1996.10476673},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VIA95TXG\\Robert and Gene Hwang - 1996 - Maximum Likelihood Estimation under Order Restrict.pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {433}
}

@book{robertMonte2010,
  title = {Monte {{Carlo}} Statistical Methods},
  author = {Robert, Christian P. and Casella, George},
  year = {2010},
  edition = {2. ed., softcover reprint of the hardcover 2. ed. 2004},
  publisher = {{Springer}},
  address = {{New York, NY}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\N4A8W4W9\\Robert and Casella - 2010 - Monte Carlo statistical methods.pdf},
  isbn = {978-1-4419-1939-7 978-1-4757-4145-2},
  language = {en},
  note = {OCLC: 837651914},
  series = {Springer Texts in Statistics}
}

@article{robinaughIdentifying2016,
  title = {Identifying {{Highly Influential Nodes}} in the {{Complicated Grief Network}}},
  author = {Robinaugh, Donald J. and Millner, Alexander J. and McNally, Richard J.},
  year = {2016},
  volume = {125},
  pages = {747--757},
  issn = {0021-843X},
  doi = {10.1037/abn0000181},
  abstract = {The network approach to psychopathology conceptualizes mental disorders as networks of mutually reinforcing nodes (i.e., symptoms). Researchers adopting this approach have suggested that network topology can be used to identify influential nodes, with nodes central to the network having the greatest influence on the development and maintenance of the disorder. However, because commonly used centrality indices do not distinguish between positive and negative edges, they may not adequately assess the nature and strength of a node's influence within the network. To address this limitation, we developed two indices of a node's expected influence (EI) that account for the presence of negative edges. To evaluate centrality and EI indices, we simulated single-node interventions on randomly generated networks. In networks with exclusively positive edges, centrality and EI were both strongly associated with observed node influence. In networks with negative edges, EI was more strongly associated with observed influence than was centrality. We then used data from a longitudinal study of bereavement to examine the association between (a) a node's centrality and EI in the complicated grief (CG) network and (b) the strength of association between change in that node and change in the remainder of the CG network from 6 to 18-months post-loss. Centrality and EI were both correlated with the strength of the association between node change and network change. These findings suggest high-EI nodes, such as emotional pain and feeling of emptiness, may be especially important to the etiology and treatment of CG., Complicated grief can be conceptualized as a network of mutually reinforcing symptoms. Centrality and expected influence indices aim to use the structure of the complicated grief network to identify symptoms that should be especially important to its development and persistence. We found that change in symptoms with high expected influence was more strongly tied to change in the severity of complicated grief than was change in symptoms with low expected influence, suggesting that this index is able to identify symptoms that may play an important role in the etiology and treatment of complicated grief.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\Q98GBAB6\\Robinaugh et al. - 2016 - Identifying Highly Influential Nodes in the Compli.pdf},
  journal = {Journal of abnormal psychology},
  number = {6},
  pmcid = {PMC5060093},
  pmid = {27505622}
}

@article{robinaughnetwork2020,
  title = {The Network Approach to Psychopathology: A Review of the Literature 2008\textendash{}2018 and an Agenda for Future Research},
  shorttitle = {The Network Approach to Psychopathology},
  author = {Robinaugh, Donald J. and Hoekstra, Ria H. A. and Toner, Emma R. and Borsboom, Denny},
  year = {2020},
  volume = {50},
  pages = {353--366},
  issn = {0033-2917, 1469-8978},
  doi = {10.1017/S0033291719003404},
  abstract = {Abstract
            The network approach to psychopathology posits that mental disorders can be conceptualized and studied as causal systems of mutually reinforcing symptoms. This approach, first posited in 2008, has grown substantially over the past decade and is now a full-fledged area of psychiatric research. In this article, we provide an overview and critical analysis of 363 articles produced in the first decade of this research program, with a focus on key theoretical, methodological, and empirical contributions. In addition, we turn our attention to the next decade of the network approach and propose critical avenues for future research in each of these domains. We argue that this program of research will be best served by working toward two overarching aims: (a) the identification of robust empirical phenomena and (b) the development of formal theories that can explain those phenomena. We recommend specific steps forward within this broad framework and argue that these steps are necessary if the network approach is to develop into a progressive program of research capable of producing a cumulative body of knowledge about how specific mental disorders operate as causal systems.},
  journal = {Psychological Medicine},
  language = {en},
  number = {3}
}

@article{rodgersDegrees2019,
  title = {Degrees of {{Freedom}} at the {{Start}} of the {{Second}} 100 {{Years}}: {{A Pedagogical Treatise}}},
  shorttitle = {Degrees of {{Freedom}} at the {{Start}} of the {{Second}} 100 {{Years}}},
  author = {Rodgers, Joseph Lee},
  year = {2019},
  volume = {2},
  pages = {396--405},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245919882050},
  abstract = {Degrees of freedom is a critical core concept within the field of statistics. Virtually every introductory statistics class treats the topic, though textbooks and the statistical literature show mostly superficial treatment, weak pedagogy, and substantial confusion. Fisher first defined degrees of freedom in 1915, and Walker provided technical treatment of the concept in 1940. In this article, the history of degrees of freedom is reviewed, and the pedagogical challenges are discussed. The core of the article is a simple reconceptualization of the degrees-of-freedom concept that is easier to teach and to learn than the traditional treatment. This reconceptualization defines a statistical bank, into which are deposited data points. These data points are used to estimate statistical models; some data are used up in estimating a model, and some data remain in the bank. The several types of degrees of freedom define an accounting process that simply counts the flow of data from the statistical bank into the model. The overall reconceptualization is based on basic economic principles, including treating data as statistical capital and data exchangeability (fungibility). The goal is to stimulate discussion of degrees of freedom that will improve its use and understanding in pedagogical and applied settings.},
  journal = {Advances in Methods and Practices in Psychological Science},
  language = {en},
  number = {4}
}

@article{rouderBayesian2018,
  title = {Bayesian Inference for Psychology, Part {{IV}}: Parameter Estimation and {{Bayes}} Factors},
  shorttitle = {Bayesian Inference for Psychology, Part {{IV}}},
  author = {Rouder, Jeffrey N. and Haaf, Julia M. and Vandekerckhove, Joachim},
  year = {2018},
  volume = {25},
  pages = {102--113},
  issn = {1531-5320},
  doi = {10.3758/s13423-017-1420-7},
  abstract = {In the psychological literature, there are two seemingly different approaches to inference: that from estimation of posterior intervals and that from Bayes factors. We provide an overview of each method and show that a salient difference is the choice of models. The two approaches as commonly practiced can be unified with a certain model specification, now popular in the statistics literature, called spike-and-slab priors. A spike-and-slab prior is a mixture of a null model, the spike, with an effect model, the slab. The estimate of the effect size here is a function of the Bayes factor, showing that estimation and model comparison can be unified. The salient difference is that common Bayes factor approaches provide for privileged consideration of theoretically useful parameter values, such as the value corresponding to the null hypothesis, while estimation approaches do not. Both approaches, either privileging the null or not, are useful depending on the goals of the analyst.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\R63WVS5R\\Rouder et al. - 2018 - Bayesian inference for psychology, part IV parame.pdf},
  journal = {Psychonomic Bulletin \& Review},
  keywords = {Bayesian inference and parameter estimation,Bayesian statistics,Model selection},
  language = {en},
  number = {1}
}

@article{rouderoverall2019,
  title = {Beyond Overall Effects: {{A Bayesian}} Approach to Finding Constraints in Meta-Analysis.},
  shorttitle = {Beyond Overall Effects},
  author = {Rouder, Jeffrey N. and Haaf, Julia M. and {Davis-Stober}, Clintin P. and Hilgard, Joseph},
  year = {2019},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000216},
  abstract = {Most meta-analyses focus on the behavior of meta-analytic means. In many cases, however, this mean is difficult to defend as a construct because the underlying distribution of studies reflects many factors including how we as researchers choose to design studies. We present an alternative goal for meta-analysis. The analyst may ask about relations that are stable across all the studies. In a typical meta-analysis, there is a hypothesized direction (e.g., that violent video games increase, rather than decrease, aggressive behavior). We ask whether all studies in a meta-analysis have true effects in the hypothesized direction. If so, this is an example of a stable relation across all the studies. We propose four models: (i) all studies are truly null; (ii) all studies share a single true nonzero effect; (iii) studies differ, but all true effects are in the same direction; and (iv) some study effects are truly positive while others are truly negative. We develop Bayes factor model comparison for these models and apply them to four extant meta-analyses to show their usefulness.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\WGNVJB3M\\Rouder et al. - 2019 - Beyond overall effects A Bayesian approach to fin.pdf},
  journal = {Psychological Methods},
  language = {en}
}

@article{rouderSignal2007,
  title = {Signal {{Detection Models}} with {{Random Participant}} and {{Item Effects}}},
  author = {Rouder, Jeffrey N. and Lu, Jun and Sun, Dongchu and Speckman, Paul and Morey, Richard and {Naveh-Benjamin}, Moshe},
  year = {2007},
  volume = {72},
  pages = {621},
  issn = {1860-0980},
  doi = {10.1007/s11336-005-1350-6},
  abstract = {The theory of signal detection is convenient for measuring mnemonic ability in recognition memory paradigms. In these paradigms, randomly selected participants are asked to study randomly selected items. In practice, researchers aggregate data across items or participants or both. The signal detection model is nonlinear; consequently, analysis with aggregated data is not consistent. In fact, mnemonic ability is underestimated, even in the large-sample limit. We present two hierarchical Bayesian models that simultaneously account for participant and item variability. We show how these models provide for accurate estimation of participants' mnemonic ability as well as the memorability of items. The model is benchmarked with a simulation study and applied to a novel data set.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HLT7PRMC\\Rouder et al. - 2007 - Signal Detection Models with Random Participant an.pdf},
  journal = {Psychometrika},
  keywords = {Bayesian models,hierarchical models,MCMC methods,recognition memory,theory of signal detection},
  language = {en},
  number = {4}
}

@article{rouderThere2016,
  title = {Is {{There}} a {{Free Lunch}} in {{Inference}}?},
  author = {Rouder, Jeffrey N. and Morey, Richard D. and Verhagen, Josine and Province, Jordan M. and Wagenmakers, Eric-Jan},
  year = {2016},
  volume = {8},
  pages = {520--547},
  issn = {1756-8765},
  doi = {10.1111/tops.12214},
  abstract = {The field of psychology, including cognitive science, is vexed by a crisis of confidence. Although the causes and solutions are varied, we focus here on a common logical problem in inference. The default mode of inference is significance testing, which has a free lunch property where researchers need not make detailed assumptions about the alternative to test the null hypothesis. We present the argument that there is no free lunch; that is, valid testing requires that researchers test the null against a well-specified alternative. We show how this requirement follows from the basic tenets of conventional and Bayesian probability. Moreover, we show in both the conventional and Bayesian framework that not specifying the alternative may lead to rejections of the null hypothesis with scant evidence. We review both frequentist and Bayesian approaches to specifying alternatives, and we show how such specifications improve inference. The field of cognitive science will benefit because consideration of reasonable alternatives will undoubtedly sharpen the intellectual underpinnings of research.},
  copyright = {Copyright \textcopyright{} 2016 Cognitive Science Society, Inc.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\XGRN7PKB\\Rouder et al. - 2016 - Is There a Free Lunch in Inference.pdf;C\:\\Users\\josue\\Zotero\\storage\\784HHX8S\\tops.html},
  journal = {Topics in Cognitive Science},
  keywords = {Inference,Philosophy of science,Replication crisis,Statistics},
  language = {en},
  number = {3}
}

@article{rubinValues2017,
  title = {Do p {{Values Lose Their Meaning}} in {{Exploratory Analyses}}? {{It Depends How You Define}} the {{Familywise Error Rate}}:},
  shorttitle = {Do p {{Values Lose Their Meaning}} in {{Exploratory Analyses}}?},
  author = {Rubin, Mark},
  year = {2017},
  publisher = {{SAGE PublicationsSage CA: Los Angeles, CA}},
  doi = {10.1037/gpr0000123},
  abstract = {Several researchers have recently argued that p values lose their meaning in exploratory analyses due to an unknown inflation of the alpha level (e.g., Nosek \& ...},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HBM62K5J\\Rubin - 2017 - Do p Values Lose Their Meaning in Exploratory Anal.pdf;C\:\\Users\\josue\\Zotero\\storage\\YVDPSVKD\\gpr0000123.html},
  journal = {Review of General Psychology},
  language = {en}
}

@article{rubio-aparicioTesting2019,
  title = {Testing {{Categorical Moderators}} in {{Mixed}}-{{Effects Meta}}-Analysis in the {{Presence}} of {{Heteroscedasticity}}},
  author = {{Rubio-Aparicio}, Mar{\'i}a and {L{\'o}pez-L{\'o}pez}, Jos{\'e} Antonio and Viechtbauer, Wolfgang and {Mar{\'i}n-Mart{\'i}nez}, Fulgencio and Botella, Juan and {S{\'a}nchez-Meca}, Julio},
  year = {2019},
  pages = {1--23},
  issn = {0022-0973, 1940-0683},
  doi = {10.1080/00220973.2018.1561404},
  abstract = {Mixed-effects models can be used to examine the association between a categorical moderator and the magnitude of the effect size. Two approaches are available to estimate the residual between-studies variance, s2res\textemdash{}namely, separate estimation within each category of the moderator versus pooled estimation across all categories. We examine, by means of a Monte Carlo simulation study, both approaches for s2res estimation in combination with two methods, the Wald-type v2 and F tests, to test the statistical significance of the moderator. Results suggest that the F test using a pooled estimate of s2res across categories is the best option in most conditions, although the F test using separate estimates of s2res is preferable if the residual heterogeneity variances are heteroscedastic.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ST6TA5GW\\Rubio-Aparicio et al. - 2019 - Testing Categorical Moderators in Mixed-Effects Me.pdf},
  journal = {The Journal of Experimental Education},
  language = {en}
}

@article{ruedaDevelopment2004,
  title = {Development of the Time Course for Processing Conflict: An Event-Related Potentials Study with 4 Year Olds and Adults},
  shorttitle = {Development of the Time Course for Processing Conflict},
  author = {Rueda, M. Rosario and Posner, Michael I. and Rothbart, Mary K. and {Davis-Stober}, Clintin P.},
  year = {2004},
  volume = {5},
  pages = {39},
  issn = {1471-2202},
  doi = {10.1186/1471-2202-5-39},
  abstract = {Tasks involving conflict are widely used to study executive attention. In the flanker task, a target stimulus is surrounded by distracting information that can be congruent or incongruent with the correct response. Developmental differences in the time course of brain activations involved in conflict processing were examined for 22 four year old children and 18 adults. Subjects performed a child-friendly flanker task while their brain activity was registered using a high-density electroencephalography system.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\QW3P66R3\\Rueda et al. - 2004 - Development of the time course for processing conf.pdf;C\:\\Users\\josue\\Zotero\\storage\\ILFDCB3X\\1471-2202-5-39.html},
  journal = {BMC Neuroscience},
  number = {1}
}

@techreport{ryanChallenge2019,
  title = {The {{Challenge}} of {{Generating Causal Hypotheses Using Network Models}}},
  author = {Ryan, Ois{\'i}n and Bringmann, Laura Francina and Schuurman, No{\'e}mi Katalin},
  year = {2019},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/ryg69},
  abstract = {The network approach to psychopathology is a theoretical framework in which mental disorders are viewed as arising from direct causal interactions between symptoms. To investigate such networks, researchers typically estimate undirected network models from empirical data, called Pairwise Markov Random Fields (PMRFs), or for normally distributed variables, Gaussian Graphical Models (GGMs). In this paper, we critically evaluate the use of PMRF-based methods to generate causal hypotheses about an underlying directed causal structure. We argue that hypothesis generation is critically dependent on the specification of a target causal structure: This is generally absent from applications of PMRFs, researchers instead taking a causally-agnostic approach. We show that the agnostic approach is fundamentally problematic, since the heuristics typically used for hypothesis generation do not hold for all types of causal structure. The specification of a target structure, however, allows a principled approach to hypothesis generation and yields novel insights.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\MB3W5TL3\\Ryan et al. - 2019 - The Challenge of Generating Causal Hypotheses Usin.pdf},
  language = {en},
  type = {Preprint}
}

@article{salaFar2019,
  title = {Near and {{Far Transfer}} in {{Cognitive Training}}: {{A Second}}-{{Order Meta}}-{{Analysis}}},
  shorttitle = {Near and {{Far Transfer}} in {{Cognitive Training}}},
  author = {Sala, Giovanni and Aksayli, N. Deniz and Tatlidil, K. Semir and Tatsumi, Tomoko and Gondo, Yasuyuki and Gobet, Fernand},
  year = {2019},
  volume = {5},
  pages = {18},
  issn = {2474-7394},
  doi = {10.1525/collabra.203},
  file = {C\:\\Users\\josue\\Zotero\\storage\\7M5SEBX7\\Sala et al. - 2019 - Near and Far Transfer in Cognitive Training A Sec.pdf},
  journal = {Collabra: Psychology},
  number = {1}
}

@inbook{salkindOverfitting2010,
  title = {Overfitting},
  booktitle = {Encyclopedia of {{Research Design}}},
  year = {2010},
  publisher = {{SAGE Publications, Inc.}},
  address = {{2455 Teller Road,~Thousand Oaks~California~91320~United States}},
  doi = {10.4135/9781412961288.n297},
  collaborator = {Salkind, Neil},
  isbn = {978-1-4129-6127-1 978-1-4129-6128-8}
}

@article{schadprincipled2019,
  title = {Toward a Principled {{Bayesian}} Workflow in Cognitive Science},
  author = {Schad, Daniel J. and Betancourt, Michael and Vasishth, Shravan},
  year = {2019},
  abstract = {Experiments in research on memory, language, and in other areas of cognitive science are increasingly being analyzed using Bayesian methods. This has been facilitated by the development of probabilistic programming languages such as Stan, and easily accessible front-end packages such as brms. However, the utility of Bayesian methods ultimately depends on the relevance of the Bayesian model, in particular whether or not it accurately captures the structure of the data and the data analyst's domain expertise. Even with powerful software, the analyst is responsible for verifying the utility of their model. To accomplish this, we introduce a principled Bayesian workflow (Betancourt, 2018) to cognitive science. Using a concrete working example, we describe basic questions one should ask about the model: prior predictive checks, computational faithfulness, model sensitivity, and posterior predictive checks. The running example for demonstrating the workflow is data on reading times with a linguistic manipulation of object versus subject relative sentences. This principled Bayesian workflow also demonstrates how to use domain knowledge to inform prior distributions. It provides guidelines and checks for valid data analysis, avoiding overfitting complex models to noise, and capturing relevant data structure in a probabilistic model. Given the increasing use of Bayesian methods, we aim to discuss how these methods can be properly employed to obtain robust answers to scientific questions. All data and code accompanying this paper are available from https://osf.io/b2vx9/.},
  archivePrefix = {arXiv},
  eprint = {1904.12765},
  eprinttype = {arxiv},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4CT9N7JY\\Schad et al. - 2019 - Toward a principled Bayesian workflow in cognitive.pdf;C\:\\Users\\josue\\Zotero\\storage\\BP6GV7TS\\1904.html},
  journal = {arXiv:1904.12765 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{schmittmannDeconstructing2013,
  title = {Deconstructing the Construct: {{A}} Network Perspective on Psychological Phenomena},
  shorttitle = {Deconstructing the Construct},
  author = {Schmittmann, Verena D. and Cramer, Ang{\'e}lique O.J. and Waldorp, Lourens J. and Epskamp, Sacha and Kievit, Rogier A. and Borsboom, Denny},
  year = {2013},
  volume = {31},
  pages = {43--53},
  issn = {0732118X},
  doi = {10.1016/j.newideapsych.2011.02.007},
  journal = {New Ideas in Psychology},
  language = {en},
  number = {1}
}

@article{schnuerchControlling2019,
  title = {Controlling Decision Errors with Minimal Costs: {{The}} Sequential Probability Ratio t Test.},
  shorttitle = {Controlling Decision Errors with Minimal Costs},
  author = {Schnuerch, Martin and Erdfelder, Edgar},
  year = {2019},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000234},
  abstract = {For several years, the public debate in psychological science has been dominated by what is referred to as the reproducibility crisis. This crisis has, inter alia, drawn attention to the need for proper control of statistical decision errors in testing psychological hypotheses. However, conventional methods of error probability control often require fairly large samples. Sequential statistical tests provide an attractive alternative: They can be applied repeatedly during the sampling process and terminate whenever there is sufficient evidence in the data for one of the hypotheses of interest. Thus, sequential tests may substantially reduce the required sample size without compromising predefined error probabilities. Herein, we discuss the most efficient sequential design, the sequential probability ratio test (SPRT), and show how it is easily implemented for a 2-sample t test using standard statistical software. We demonstrate, by means of simulations, that the SPRT not only reliably controls error probabilities but also typically requires substantially smaller samples than standard t tests and other common sequential designs. Moreover, we investigate the robustness of the SPRT against violations of its assumptions. Finally, we illustrate the sequential t test by applying it to an empirical example and provide recommendations on how psychologists can employ it in their own research to benefit from its desirable properties.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\3G7N8H6X\\Schnuerch and Erdfelder - 2019 - Controlling decision errors with minimal costs Th.pdf},
  journal = {Psychological Methods},
  language = {en}
}

@article{schootBayesian2013,
  title = {Bayesian Evaluation of Informative Hypotheses in {{SEM}} Using {{Mplus}}: {{A}} Black Bear Story},
  shorttitle = {Bayesian Evaluation of Informative Hypotheses in {{SEM}} Using {{Mplus}}},
  author = {van de Schoot, Rens and Verhoeven, Marjolein and Hoijtink, Herbert},
  year = {2013},
  volume = {10},
  pages = {81--98},
  issn = {1740-5629},
  doi = {10.1080/17405629.2012.732719},
  abstract = {Half in jest we use a story about a black bear to illustrate that there are some discrepancies between the formal use of the p-value and the way it is often used in practice. We argue that more can be learned from data by evaluating informative hypotheses, than by testing the traditional null hypothesis. All criticisms of classical null hypothesis testing aside, the best argument for evaluating informative hypotheses is that many researchers want to evaluate their expectations directly, but have been unable to do so because the statistical tools were not yet available. It will be shown that a Bayesian model selection procedure can be used to evaluate informative hypotheses in structural equation models using the software Mplus. In the current paper we introduce the methodology using a real-life example taken from the field of developmental psychology about depressive symptoms in adolescence and provide a step-by-step description so that the procedure becomes more comprehensible for applied researchers. As this paper illustrates, this methodology is ready to be used by any researcher within the social sciences.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HW7EI2RL\\Schoot et al. - 2013 - Bayesian evaluation of informative hypotheses in S.pdf;C\:\\Users\\josue\\Zotero\\storage\\W6YYXH84\\17405629.2012.html},
  journal = {European Journal of Developmental Psychology},
  keywords = {Bayes factor,Corrigendum,Depression,Informative hypothesis,Mplus,Order restricted inference,Structural equation modelling},
  number = {1}
}

@article{schootintroduction2011,
  title = {An Introduction to {{Bayesian}} Model Selection for Evaluating Informative Hypotheses},
  author = {van de Schoot, Rens and Mulder, Joris and Hoijtink, Herbert and Aken, Marcel A. G. Van and Dubas, Judith Semon and de Castro, Bram Orobio and Meeus, Wim and Romeijn, Jan-Willem},
  year = {2011},
  volume = {8},
  pages = {713--729},
  issn = {1740-5629},
  doi = {10.1080/17405629.2011.621799},
  abstract = {Most researchers have specific expectations concerning their research questions. These may be derived from theory, empirical evidence, or both. Yet despite these expectations, most investigators still use null hypothesis testing to evaluate their data, that is, when analysing their data they ignore the expectations they have. In the present article, Bayesian model selection is presented as a means to evaluate the expectations researchers have, that is, to evaluate so called informative hypotheses. Although the methodology to do this has been described in previous articles, these are rather technical and havemainly been published in statistical journals. The main objective of thepresent article is to provide a basic introduction to the evaluation of informative hypotheses using Bayesian model selection. Moreover, what is new in comparison to previous publications on this topic is that we provide guidelines on how to interpret the results. Bayesian evaluation of informative hypotheses is illustrated using an example concerning psychosocial functioning and the interplay between personality and support from family.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\WX7I3S9D\\Schoot et al. - 2011 - An introduction to Bayesian model selection for ev.pdf;C\:\\Users\\josue\\Zotero\\storage\\2CVZRW5R\\17405629.2011.html},
  journal = {European Journal of Developmental Psychology},
  keywords = {Bayes factors,Bayesian model selection,Inequality constraints,Informative hypothesis,Personality,Psychosocial functioning},
  number = {6}
}

@book{silvapulleConstrained2005,
  title = {Constrained Statistical Inference: {{Inequality}}, Order and Shape Restrictions},
  shorttitle = {Constrained Statistical Inference},
  author = {Silvapulle, Mervyn J. and Sen, Pranab Kumar},
  year = {2005},
  publisher = {{John Wiley \& Sons}},
  doi = {10.1002/9781118165614},
  file = {C\:\\Users\\josue\\Zotero\\storage\\Z6LZW3E4\\constrained-statistical-inference-inequality-order-and-shape-rest.html},
  isbn = {978-0-471-20827-3 978-1-118-16561-4},
  language = {English}
}

@book{spirtesCausation2000,
  title = {Causation, {{Prediction}}, and {{Search}}},
  author = {Spirtes, Peter and Glymour, Clark N. and Scheines, Richard and Heckerman, David},
  year = {2000},
  publisher = {{MIT Press}},
  abstract = {What assumptions and methods allow us to turn observations into causal knowledge, and how can even incomplete causal knowledge be used in planning and prediction to influence and control our environment? In this book Peter Spirtes, Clark Glymour, and Richard Scheines address these questions using the formalism of Bayes networks, with results that have been applied in diverse areas of research in the social, behavioral, and physical sciences. The authors show that although experimental and observational study designs may not always permit the same inferences, they are subject to uniform principles. They axiomatize the connection between causal structure and probabilistic independence, explore several varieties of causal indistinguishability, formulate a theory of manipulation, and develop asymptotically reliable procedures for searching over equivalence classes of causal models, including models of categorical data and structural equation models with and without latent variables. The authors show that the relationship between causality and probability can also help to clarify such diverse topics in statistics as the comparative power of experimentation versus observation, Simpson's paradox, errors in regression models, retrospective versus prospective sampling, and variable selection. The second edition contains a new introduction and an extensive survey of advances and applications that have appeared since the first edition was published in 1993.},
  isbn = {978-0-262-19440-2},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {en}
}

@article{spitzerBrief2006,
  title = {A {{Brief Measure}} for {{Assessing Generalized Anxiety Disorder}}: {{The GAD}}-7},
  shorttitle = {A {{Brief Measure}} for {{Assessing Generalized Anxiety Disorder}}},
  author = {Spitzer, Robert L. and Kroenke, Kurt and Williams, Janet B. W. and L{\"o}we, Bernd},
  year = {2006},
  volume = {166},
  pages = {1092--1097},
  publisher = {{American Medical Association}},
  issn = {0003-9926},
  doi = {10.1001/archinte.166.10.1092},
  abstract = {{$<$}h3{$>$}Background{$<$}/h3{$><$}p{$>$}Generalized anxiety disorder (GAD) is one of the most common mental disorders; however, there is no brief clinical measure for assessing GAD. The objective of this study was to develop a brief self-report scale to identify probable cases of GAD and evaluate its reliability and validity.{$<$}/p{$><$}h3{$>$}Methods{$<$}/h3{$><$}p{$>$}A criterion-standard study was performed in 15 primary care clinics in the United States from November 2004 through June 2005. Of a total of 2740 adult patients completing a study questionnaire, 965 patients had a telephone interview with a mental health professional within 1 week. For criterion and construct validity, GAD self-report scale diagnoses were compared with independent diagnoses made by mental health professionals; functional status measures; disability days; and health care use.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}A 7-item anxiety scale (GAD-7) had good reliability, as well as criterion, construct, factorial, and procedural validity. A cut point was identified that optimized sensitivity (89\%) and specificity (82\%). Increasing scores on the scale were strongly associated with multiple domains of functional impairment (all 6 Medical Outcomes Study Short-Form General Health Survey scales and disability days). Although GAD and depression symptoms frequently co-occurred, factor analysis confirmed them as distinct dimensions. Moreover, GAD and depression symptoms had differing but independent effects on functional impairment and disability. There was good agreement between self-report and interviewer-administered versions of the scale.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}The GAD-7 is a valid and efficient tool for screening for GAD and assessing its severity in clinical practice and research.{$<$}/p{$>$}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\5VGW5S4R\\Spitzer et al. - 2006 - A Brief Measure for Assessing Generalized Anxiety .pdf;C\:\\Users\\josue\\Zotero\\storage\\ZLX5KXHK\\410326.html},
  journal = {Archives of Internal Medicine},
  language = {en},
  number = {10}
}

@article{stevensFunctional2012,
  title = {Functional {{Brain Network Modularity Captures Inter}}- and {{Intra}}-{{Individual Variation}} in {{Working Memory Capacity}}},
  author = {Stevens, Alexander A. and Tappon, Sarah C. and Garg, Arun and Fair, Damien A.},
  year = {2012},
  volume = {7},
  pages = {e30468},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0030468},
  abstract = {Background Cognitive abilities, such as working memory, differ among people; however, individuals also vary in their own day-to-day cognitive performance. One potential source of cognitive variability may be fluctuations in the functional organization of neural systems. The degree to which the organization of these functional networks is optimized may relate to the effective cognitive functioning of the individual. Here we specifically examine how changes in the organization of large-scale networks measured via resting state functional connectivity MRI and graph theory track changes in working memory capacity. Methodology/Principal Findings Twenty-two participants performed a test of working memory capacity and then underwent resting-state fMRI. Seventeen subjects repeated the protocol three weeks later. We applied graph theoretic techniques to measure network organization on 34 brain regions of interest (ROI). Network modularity, which measures the level of integration and segregation across sub-networks, and small-worldness, which measures global network connection efficiency, both predicted individual differences in memory capacity; however, only modularity predicted intra-individual variation across the two sessions. Partial correlations controlling for the component of working memory that was stable across sessions revealed that modularity was almost entirely associated with the variability of working memory at each session. Analyses of specific sub-networks and individual circuits were unable to consistently account for working memory capacity variability. Conclusions/Significance The results suggest that the intrinsic functional organization of an a priori defined cognitive control network measured at rest provides substantial information about actual cognitive performance. The association of network modularity to the variability in an individual's working memory capacity suggests that the organization of this network into high connectivity within modules and sparse connections between modules may reflect effective signaling across brain regions, perhaps through the modulation of signal or the suppression of the propagation of noise.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\LDUF4VSF\\Stevens et al. - 2012 - Functional Brain Network Modularity Captures Inter.pdf;C\:\\Users\\josue\\Zotero\\storage\\8PNDVYLF\\article.html},
  journal = {PLOS ONE},
  keywords = {Cognition,Functional magnetic resonance imaging,Network analysis,Neural networks,Prefrontal cortex,Short-term memory,Vision,Working memory},
  language = {en},
  number = {1}
}

@article{stevensInverse1998,
  title = {On the {{Inverse}} of the {{Covariance Matrix}} in {{Portfolio Analysis}}},
  author = {Stevens, Guy V. G.},
  year = {1998},
  volume = {53},
  pages = {1821--1827},
  issn = {00221082},
  doi = {10.1111/0022-1082.00074},
  file = {C\:\\Users\\josue\\Zotero\\storage\\QUWN3ZX8\\Stevens - 1998 - On the Inverse of the Covariance Matrix in Portfol.pdf},
  journal = {The Journal of Finance},
  language = {en},
  number = {5}
}

@article{stimsonInterpreting1978,
  title = {Interpreting {{Polynomial Regression}}},
  author = {Stimson, James A. and Carmines, Edward G. and Zeller, Richard A.},
  year = {1978},
  volume = {6},
  pages = {515--524},
  issn = {0049-1241},
  doi = {10.1177/004912417800600405},
  abstract = {This paper focuses on the interpretational difficulties that confound polynomial regression analysis. While polynomial regression is statistically sound, it produces awkward equations which "describe" a curve with a series of linear slopes. An example illustrates the technique and the awkward properties of regression coefficients in the quadratic case. Finally, the paper briefly outlines an algebraic manipulation that transforms polynomial regression equations into a format that is readily interpretable.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\885ASTPU\\Stimson et al. - 1978 - Interpreting Polynomial Regression.pdf},
  journal = {Sociological Methods \& Research},
  number = {4}
}

@article{stoneAsymptotic1977,
  title = {An {{Asymptotic Equivalence}} of {{Choice}} of {{Model}} by {{Cross}}-{{Validation}} and {{Akaike}}'s {{Criterion}}},
  author = {Stone, M.},
  year = {1977},
  volume = {39},
  pages = {44--47},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1977.tb01603.x},
  abstract = {A logarithmic assessment of the performance of a predicting density is found to lead to asymptotic equivalence of choice of model by cross-validation and Akaike's criterion, when maximum likelihood estimation is used within each model.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\Y7CSQLK5\\j.2517-6161.1977.tb01603.html},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  keywords = {akaike's information criterion,cross-validation,model choice,predicting density},
  language = {en},
  number = {1}
}

@article{stoneCrossValidatory1974,
  title = {Cross-{{Validatory Choice}} and {{Assessment}} of {{Statistical Predictions}}},
  author = {Stone, M.},
  year = {1974},
  volume = {36},
  pages = {111--147},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  abstract = {A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  number = {2}
}

@article{sugarmanPerformance2014,
  title = {Performance Variability during a Multitrial List-Learning Task as a Predictor of Future Cognitive Decline in Healthy Elders},
  author = {Sugarman, Michael A. and Woodard, John L. and Nielson, Kristy A. and Smith, J. Carson and Seidenberg, Michael and Durgerian, Sally and Norman, Andria L. and Hantke, Nathan C. and Rao, Stephen M.},
  year = {2014},
  volume = {36},
  pages = {236--243},
  issn = {1380-3395},
  doi = {10.1080/13803395.2013.877875},
  abstract = {Introduction: In clinical settings, neuropsychological test performance is traditionally evaluated with total summary scores (TSS). However, recent studies demonstrated that indices of intraindividual variability (IIV) yielded unique information complementing TSS. This 18-month longitudinal study sought to determine whether IIV indices derived from a multitrial list-learning test (the Rey Auditory Verbal Learning Test) provided incremental utility in predicting cognitive decline in older adults compared to TSS. Method: Ninety-nine cognitively intact older adults (aged 65 to 89 years) underwent neuropsychological testing (including the Rey Auditory Verbal Learning Test) at baseline and 18-month follow-up. Participants were classified as cognitively stable (n = 65) or declining (n = 34) based on changes in their neuropsychological test performance. Logistic regression modeling tested the ability of baseline TSS indices (sum of Trials 1\textendash{}5, immediate recall, and delayed recall) and IIV indices (lost access and gained access) to discriminate between stable and declining individuals. Results: Higher values of both lost access and gained access at baseline were associated with an increased risk for decline at 18-month follow-up. Further, the IIV indices provided predictive utility above and beyond the TSS indices. Conclusion: These results highlight the value of analyzing IIV in addition to TSS during neuropsychological evaluation in older adults. High levels of IIV may reflect impairment in anterograde memory systems and/or executive dysfunction that may serve as a prognostic indicator of cognitive decline.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\UY4FTGAR\\Sugarman et al. - 2014 - Performance variability during a multitrial list-l.pdf;C\:\\Users\\josue\\Zotero\\storage\\LZZB6IYR\\13803395.2013.html},
  journal = {Journal of Clinical and Experimental Neuropsychology},
  keywords = {Cognitive aging,Intraindividual variability,Prediction of decline,Rey Auditory Verbal Learning Test},
  number = {3},
  pmid = {24552205}
}

@article{szatkowskidynamic1982,
  title = {On the Dynamic Spaces and on the Equations of Motion of Non-Linear},
  author = {Szatkowski, Andrzej},
  year = {1982},
  volume = {10},
  pages = {99--122},
  issn = {1097-007X},
  doi = {10.1002/cta.4490100202},
  abstract = {The problems of the qualitative theory of non-linear RLC networks are considered from a geometric point of view. Several general properties of the dynamic space of the network are presented. The concept of the vector field generated by the network on its dynamic space is introduced and discussed. The equations of motion are formulated in the forms which are useful in the qualitative analysis of the solutions.},
  copyright = {Copyright \textcopyright{} 1982 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\CPIFM6G7\\cta.html},
  journal = {International Journal of Circuit Theory and Applications},
  language = {en},
  number = {2}
}

@article{trottaBayes2008,
  title = {Bayes in the Sky: {{Bayesian}} Inference and Model Selection in Cosmology},
  shorttitle = {Bayes in the Sky},
  author = {Trotta, Roberto},
  year = {2008},
  volume = {49},
  pages = {71--104},
  issn = {0010-7514, 1366-5812},
  doi = {10.1080/00107510802066753},
  abstract = {The application of Bayesian methods in cosmology and astrophysics has flourished over the past decade, spurred by data sets of increasing size and complexity. In many respects, Bayesian methods have proven to be vastly superior to more traditional statistical tools, offering the advantage of higher efficiency and of a consistent conceptual basis for dealing with the problem of induction in the presence of uncertainty. This trend is likely to continue in the future, when the way we collect, manipulate and analyse observations and compare them with theoretical models will assume an even more central role in cosmology. This review is an introduction to Bayesian methods in cosmology and astrophysics and recent results in the field. I first present Bayesian probability theory and its conceptual underpinnings, Bayes' Theorem and the role of priors. I discuss the problem of parameter inference and its general solution, along with numerical techniques such as Monte Carlo Markov Chain methods. I then review the theory and application of Bayesian model comparison, discussing the notions of Bayesian evidence and effective model complexity, and how to compute and interpret those quantities. Recent developments in cosmological parameter extraction and Bayesian cosmological model building are summarized, highlighting the challenges that lie ahead.},
  archivePrefix = {arXiv},
  eprint = {0803.4089},
  eprinttype = {arxiv},
  file = {C\:\\Users\\josue\\Zotero\\storage\\6G36ZS43\\Trotta - 2008 - Bayes in the sky Bayesian inference and model sel.pdf;C\:\\Users\\josue\\Zotero\\storage\\VE3EDNDJ\\0803.html},
  journal = {Contemporary Physics},
  keywords = {Astrophysics},
  number = {2}
}

@misc{Unity,
  title = {The {{Unity}} and {{Diversity}} of {{Executive Functions}} and {{Their Contributions}} to {{Complex}} ``{{Frontal Lobe}}'' {{Tasks}}: {{A Latent Variable Analysis}} | {{Elsevier Enhanced Reader}}},
  shorttitle = {The {{Unity}} and {{Diversity}} of {{Executive Functions}} and {{Their Contributions}} to {{Complex}} ``{{Frontal Lobe}}'' {{Tasks}}},
  doi = {10.1006/cogp.1999.0734},
  file = {C\:\\Users\\josue\\Zotero\\storage\\2FNLWX6G\\The Unity and Diversity of Executive Functions and.pdf;C\:\\Users\\josue\\Zotero\\storage\\DLBJHKYM\\S001002859990734X.html},
  language = {en}
}

@article{vanborkuloAssociation2015,
  title = {Association of {{Symptom Network Structure With}} the {{Course}} of {{Depression}}},
  author = {{van Borkulo}, Claudia D. and Boschloo, Lynn and Borsboom, Denny and Penninx, Brenda W. J. H. and Waldorp, Lourens J. and Schoevers, Robert A.},
  year = {2015},
  volume = {72},
  pages = {1219--1226},
  publisher = {{American Medical Association}},
  issn = {2168-622X},
  doi = {10.1001/jamapsychiatry.2015.2079},
  abstract = {{$<$}h3{$>$}Importance{$<$}/h3{$><$}p{$>$}Major depressive disorder (MDD) is a heterogeneous condition in terms of symptoms, course, and underlying disease mechanisms. Current classifications do not adequately address this complexity. In novel network approaches to psychopathology, psychiatric disorders are conceptualized as complex dynamic systems of mutually interacting symptoms. This perspective implies that a more densely connected network of symptoms is indicative of a poorer prognosis, but, to date, no previous study has examined whether network structure is indeed associated with the longitudinal course of MDD.{$<$}/p{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To examine whether the baseline network structure of MDD symptoms is associated with the longitudinal course of MDD.{$<$}/p{$><$}h3{$>$}Design, Setting, and Participants{$<$}/h3{$><$}p{$>$}In this prospective study, in which remittent and persistent MDD was defined on the basis of a follow-up assessment after 2 years, 515 patients from the Netherlands Study of Depression and Anxiety with past-year MDD (established with the Composite International Diagnostic Interview) and at least moderate depressive symptoms (assessed with the Inventory of Depressive Symptomatology [IDS]) at baseline were studied. Baseline starting and ending dates were September 1, 2004, through February 28, 2007. Follow-up starting and ending dates were September 1, 2006, through February 28, 2009. Analysis was conducted August 2015. The MDD was considered persistent if patients had at least moderate depressive symptoms (IDS) at 2-year follow-up; otherwise, the MDD was considered remitted.{$<$}/p{$><$}h3{$>$}Main Outcomes and Measures{$<$}/h3{$><$}p{$>$}Sparse network structures of baseline MDD symptoms assessed via IDS were computed. Global and local connectivity of network structures were compared across persisters and remitters using a permutation test.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Among the 515 patients, 335 (65.1\%) were female, mead (SD) age was 40.9 (12.1) years, and 253 (49.1\%) had persistent MDD at 2-year follow-up. Persisters (n = 253) had a higher baseline IDS sum score than remitters (n = 262) (mean [SD] score, 40.2 [8.9] vs 35.1 [7.1]; the test statistic for the difference in IDS sum score was 22 027;\emph{P} \&lt; .001). The test statistic for the difference in network connectivity was 1.79 (\emph{P}= .01) for the original data, 1.55 for data matched on IDS sum score (\emph{P}= .04), and 1.65 for partialed out data (\emph{P}= .02). At the symptom level, fatigue or loss of energy and feeling guilty had the largest difference in importance in persisters' network compared with that of remitters (Cohen\emph{d} = 1.13 and 1.18, respectively).{$<$}/p{$><$}h3{$>$}Conclusions and Relevance{$<$}/h3{$><$}p{$>$}This study reports that symptom networks of patients with MDD are related to longitudinal course: persisters exhibited a more densely connected network at baseline than remitters. More pronounced associations between symptoms may be an important determinant of persistence in MDD.{$<$}/p{$>$}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VKL7BTMQ\\Borkulo et al. - 2015 - Association of Symptom Network Structure With the .pdf;C\:\\Users\\josue\\Zotero\\storage\\VHCLHGB7\\2469105.html},
  journal = {JAMA Psychiatry},
  language = {en},
  number = {12}
}

@unpublished{vanborkuloComparing2016,
  title = {Comparing Network Structures on Three Aspects: {{A}} Permutation Test},
  author = {{van Borkulo}, Claudia D. and Boschloo, Lynn and Kossakowski, J.  J. and Tio, P. and Schoevers, Robert A. and Borsboom, Denny and Waldorp, Lourens J.},
  year = {2016},
  doi = {10.13140/RG.2.2.29455.38569},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IGTCEK4A\\van Borkulo et al. - 2016 - Comparing network structures on three aspects A p.pdf},
  type = {Submitted for Publication}
}

@article{vandeschootBayesian2012,
  title = {Bayesian {{Evaluation}} of Inequality-Constrained {{Hypotheses}} in {{SEM Models}} Using {{Mplus}}},
  author = {{van de Schoot}, Rens and Hoijtink, Herbert and Hallquist, Michael N. and Boelen, Paul A.},
  year = {2012},
  volume = {19},
  issn = {1070-5511},
  doi = {10.1080/10705511.2012.713267},
  abstract = {Researchers in the behavioural and social sciences often have expectations that can be expressed in the form of inequality constraints among the parameters of a structural equation model resulting in an informative hypothesis. The question they would like an answer to is ``Is the Hypothesis Correct'' or ``Is the hypothesis incorrect?''. We demonstrate a Bayesian approach to compare an inequality-constrained hypothesis with its complement in an SEM framework. The method is introduced and its utility is illustrated by means of an example. Furthermore, the influence of the specification of the prior distribution is examined. Finally, it is shown how the approach proposed can be implemented using Mplus.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\A6H4S53S\\van de Schoot et al. - 2012 - Bayesian Evaluation of inequality-constrained Hypo.pdf},
  journal = {Structural equation modeling : a multidisciplinary journal},
  number = {4},
  pmcid = {PMC3868481},
  pmid = {24363548}
}

@article{vanerpPrior2018,
  title = {Prior {{Sensitivity Analysis}} in {{Default Bayesian Structural Equation Modeling}}},
  author = {{van Erp}, Sara and Mulder, Joris and Oberski, Daniel L},
  year = {2018},
  volume = {23},
  pages = {363--388},
  doi = {10.1037/met0000162},
  abstract = {Bayesian structural equation modeling (BSEM) has recently gained popularity because it enables researchers to fit complex models and solve some of the issues often encountered in classical maximum likelihood estimation, such as nonconvergence and inadmissible solutions. An important component of any Bayesian analysis is the prior distribution of the unknown model parameters. Often, researchers rely on default priors, which are constructed in an automatic fashion without requiring substantive prior information. However, the prior can have a serious influence on the estimation of the model parameters, which affects the mean squared error, bias, coverage rates, and quantiles of the estimates. In this article, we investigate the performance of three different default priors: noninformative improper priors, vague proper priors, and empirical Bayes priors\textemdash{}with the latter being novel in the BSEM literature. Based on a simulation study, we find that these three default BSEM methods may perform very differently, especially with small samples. A careful prior sensitivity analysis is therefore needed when performing a default BSEM analysis. For this purpose, we provide a practical step-by-step guide for practitioners to conducting a prior sensitivity analysis in default BSEM. Our recommendations are illustrated using a well-known case study from the structural equation modeling literature, and all code for conducting the prior sensitivity analysis is available in the online supplemental materials.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HFT29TZU\\van Erp et al. - Prior Sensitivity Analysis in Default Bayesian Str.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {2}
}

@article{vanerpShrinkage2019,
  title = {Shrinkage Priors for {{Bayesian}} Penalized Regression},
  author = {{van Erp}, Sara and Oberski, Daniel L. and Mulder, Joris},
  year = {2019},
  volume = {89},
  pages = {31--50},
  issn = {00222496},
  doi = {10.1016/j.jmp.2018.12.004},
  file = {C\:\\Users\\josue\\Zotero\\storage\\WRPDB5B3\\van Erp et al. - 2019 - Shrinkage priors for Bayesian penalized regression.pdf},
  journal = {Journal of Mathematical Psychology},
  language = {en}
}

@article{vaurioIncreased2009,
  title = {Increased Intra-Individual Reaction Time Variability in Attention-Deficit/Hyperactivity Disorder across Response Inhibition Tasks with Different Cognitive Demands},
  author = {Vaurio, Rebecca G. and Simmonds, Daniel J. and Mostofsky, Stewart H.},
  year = {2009},
  volume = {47},
  pages = {2389--2396},
  issn = {0028-3932},
  doi = {10.1016/j.neuropsychologia.2009.01.022},
  abstract = {One of the most consistent findings in children with ADHD is increased moment-to-moment variability in reaction time (RT). The source of increased RT variability can be examined using ex-Gaussian analyses that divide variability into normal and exponential components and Fast Fourier transform (FFT) that allow for detailed examination of the frequency of responses in the exponential distribution. Prior studies of ADHD using these methods have produced variable results, potentially related to differences in task demand. The present study sought to examine the profile of RT variability in ADHD using two Go/No-go tasks with differing levels of cognitive demand. A total of 140 children (57 with ADHD and 83 typically developing controls), ages 8\textendash{}13 years, completed both a ``simple'' Go/No-go task and a more ``complex'' Go/No-go task with increased working memory load. Repeated measures ANOVA of ex-Gaussian functions revealed for both tasks children with ADHD demonstrated increased variability in both the normal/Gaussian (significantly elevated sigma) and the exponential (significantly elevated tau) components. In contrast, FFT analysis of the exponential component revealed a significant task\texttimes{}diagnosis interaction, such that infrequent slow responses in ADHD differed depending on task demand (i.e., for the simple task, increased power in the 0.027\textendash{}0.074Hz frequency band; for the complex task, decreased power in the 0.074\textendash{}0.202Hz band). The ex-Gaussian findings revealing increased variability in both the normal (sigma) and exponential (tau) components for the ADHD group, suggest that both impaired response preparation and infrequent ``lapses in attention'' contribute to increased variability in ADHD. FFT analyses reveal that the periodicity of intermittent lapses of attention in ADHD varies with task demand. The findings provide further support for intra-individual variability as a candidate intermediate endophenotype of ADHD.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ANXI4E5L\\Vaurio et al. - 2009 - Increased intra-individual reaction time variabili.pdf;C\:\\Users\\josue\\Zotero\\storage\\J6EVH8SN\\S0028393209000050.html},
  journal = {Neuropsychologia},
  keywords = {“pre-SMA”,Ex-Gaussian,Fast Fourier transform,Response inhibition,Response preparation,Response selection,Supplementary motor area},
  number = {12}
}

@article{verbekeConditional2001,
  title = {Conditional {{Linear Mixed Models}}},
  author = {Verbeke, Geert and Spiessens, Bart and Lesaffre, Emmanuel},
  year = {2001},
  volume = {55},
  pages = {25--34},
  issn = {0003-1305},
  abstract = {The main advantage of longitudinal studies is that they can distinguish changes over time within individuals (longitudinal effects) from differences among subjects at the start of the study (cross-sectional effects). In observational studies, however, longitudinal changes need to be studied after correction for potential important cross-sectional differences between subjects. It will be shown that, in the context of linear mixed models, the estimation of longitudinal effects may be highly influenced by the assumptions about cross-sectional effects. Furthermore, aspects from conditional and mixture inference will be combined, yielding so-called conditional linear mixed models that allow estimation of longitudinal effects (average trends as well as subject-specific trends), independent of any cross-sectional assumptions. These models will be introduced and justified, and extensively illustrated in the analysis of longitudinal data from 680 participants in the Baltimore Longitudinal Study of Aging.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\3FFMUCTW\\Verbeke et al. - 2001 - Conditional Linear Mixed Models.pdf},
  journal = {The American Statistician},
  number = {1}
}

@article{verdinelliComputing1995,
  title = {Computing {{Bayes Factors Using}} a {{Generalization}} of the {{Savage}}-{{Dickey Density Ratio}}},
  author = {Verdinelli, Isabella and Wasserman, Larry},
  year = {1995},
  volume = {90},
  pages = {614--618},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1995.10476554},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KCCZ2GFG\\Verdinelli and Wasserman - 1995 - Computing Bayes Factors Using a Generalization of .pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {430}
}

@article{vettel20182018,
  title = {2018 {{Human Variability Workshop}}: {{Insights}} to {{Drive Scientific Innovations}} for {{Human State Detection}} and {{Prediction}}},
  author = {Vettel, Jean M and Gamble, Katherine R and Booker, Janice and Carter, Evan C and Fitzhugh, Sean M and Rubinstein, Joshua S and Spangler, Derek P and Thurman, Steven M and DeCostanza, Arwen H and Brooks, Justin R},
  year = {2018},
  pages = {184},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KC7BSC9P\\Vettel et al. - 2018 - 2018 Human Variability Workshop Insights to Drive.pdf},
  language = {en}
}

@article{votawTesting1948,
  title = {Testing {{Compound Symmetry}} in a {{Normal Multivariate Distribution}}},
  author = {Votaw, David F.},
  year = {1948},
  volume = {19},
  pages = {447--473},
  issn = {0003-4851},
  abstract = {In this paper test criteria are developed for testing hypotheses of "compound symmetry" in a normal multivariate population of t variates (t {$\geq$} 3) on basis of samples. A feature common to the twelve hypotheses considered is that the set of t variates is partitioned into mutually exclusive subsets of variates. In regard to the partitioning, the twelve hypotheses can be divided into two contrasting but very similar types, and the six in one type can be paired off in a natural way with the six in the other type. Three of the hypotheses within a given type are associated with the case of a single sample and moreover are simple modifications of one another; the remaining three are direct extensions of the first three, respectively, to the case of k samples (k {$\geq$} 2). The gist of any of the hypotheses is indicated in the following statement of one, denoted by H1(mvc): within each subset of variates the means are equal, the variances are equal and the covariances are equal and between any two distinct subsets the covariances are equal. The twelve sample criteria for testing the hypotheses are developed by the Neyman-Pearson likelihood-ratio method. The following results are obtained for each criterion (assuming that the respective null hypotheses are true) for any admissible partition of the t variates into subsets and for any sample size, N, for which the criterion's distribution exists: (i) the exact moments; (ii) an identification of the exact distribution as the distribution of a product of independent beta variates; (iii) the approximate distribution for large N. Exact distributions of the single-sample criteria are given explicitly for special values of t and special partitionings. Certain psychometric and medical research problems in which hypotheses of compound symmetry are relevant are discussed in section 1. Sections 2-6 give statements of the hypotheses and an illustration, for H1(mvc), of the technique of obtaining the moments and identifying the distributions. Results for the other criteria are given in sections 7-8. Illustrative examples showing applications of the results are given in section 9.},
  journal = {The Annals of Mathematical Statistics},
  number = {4}
}

@article{wagenmakersAgenda2012,
  title = {An {{Agenda}} for {{Purely Confirmatory Research}}},
  author = {Wagenmakers, Eric-Jan and Wetzels, Ruud and Borsboom, Denny and {van der Maas}, Han L. J. and Kievit, Rogier A.},
  year = {2012},
  volume = {7},
  pages = {632--638},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691612463078},
  abstract = {The veracity of substantive research claims hinges on the way experimental data are collected and analyzed. In this article, we discuss an uncomfortable fact that threatens the core of psychology's academic enterprise: almost without exception, psychologists do not commit themselves to a method of data analysis before they see the actual data. It then becomes tempting to fine tune the analysis to the data in order to obtain a desired result\textemdash{}a procedure that invalidates the interpretation of the common statistical tests. The extent of the fine tuning varies widely across experiments and experimenters but is almost impossible for reviewers and readers to gauge. To remedy the situation, we propose that researchers preregister their studies and indicate in advance the analyses they intend to conduct. Only these analyses deserve the label ``confirmatory,'' and only for these analyses are the common statistical tests valid. Other analyses can be carried out but these should be labeled ``exploratory.'' We illustrate our proposal with a confirmatory replication attempt of a study on extrasensory perception.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\4BEBQNWS\\Wagenmakers et al. - 2012 - An Agenda for Purely Confirmatory Research.pdf},
  journal = {Perspectives on Psychological Science},
  language = {en},
  number = {6}
}

@article{wagenmakersWhy2011,
  title = {Why Psychologists Must Change the Way They Analyze Their Data: {{The}} Case of Psi: {{Comment}} on {{Bem}} (2011).},
  shorttitle = {Why Psychologists Must Change the Way They Analyze Their Data},
  author = {Wagenmakers, Eric-Jan and Wetzels, Ruud and Borsboom, Denny and {van der Maas}, Han L. J.},
  year = {2011},
  volume = {100},
  pages = {426--432},
  issn = {1939-1315, 0022-3514},
  doi = {10.1037/a0022790},
  journal = {Journal of Personality and Social Psychology},
  language = {en},
  number = {3}
}

@article{waltersPower2018,
  title = {The {{Power}} to {{Detect}} and {{Predict Individual Differences}} in {{Intra}}-{{Individual Variability Using}} the {{Mixed}}-{{Effects Location}}-{{Scale Model}}},
  author = {Walters, Ryan W. and Hoffman, Lesa and Templin, Jonathan},
  year = {2018},
  volume = {53},
  pages = {360--374},
  issn = {0027-3171, 1532-7906},
  doi = {10.1080/00273171.2018.1449628},
  abstract = {Our goal is to provide empirical scientists with practical tools and advice with which to test hypotheses related to individual differences in intra-individual variability using the mixed-effects location-scale model. To that end, we evaluate Type I error rates and power to detect and predict individual differences in intra-individual variability using this model and provide empirically-based guidelines for building scale models that include random and/or systematically-varying fixed effects. We also provide two power simulation programs that allow researchers to conduct a priori empirical power analyses. Our results aligned with statistical power theory, in that, greater power was observed for designs with more individuals, more repeated occasions, greater proportions of variance available to be explained, and larger effect sizes. In addition, our results indicated that Type I error rates were acceptable in situations when individual differences in intra-individual variability were not initially detectable as well as when the scale-model individual-level predictor explained all initially detectable individual differences in intra-individual variability. We conclude our paper by providing study design and model building advice for those interested in using the mixed-effects location-scale model in practice.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ILN9EKAC\\Walters et al. - 2018 - The Power to Detect and Predict Individual Differe.pdf},
  journal = {Multivariate Behavioral Research},
  language = {en},
  number = {3}
}

@article{wangVariable2016,
  title = {Variable {{Selection}} and {{Parameter Estimation}} with the {{Atan Regularization Method}}},
  author = {Wang, Yanxin and Zhu, Li},
  year = {2016},
  volume = {2016},
  pages = {1--12},
  issn = {1687-952X, 1687-9538},
  doi = {10.1155/2016/6495417},
  abstract = {Variable selection is fundamental to high-dimensional statistical modeling. Many variable selection techniques may be implemented by penalized least squares using various penalty functions. In this paper, an arctangent type penalty which very closely resembles
              
                
                  
                    
                      l
                    
                    
                      0
                    
                  
                
              
              penalty is proposed; we call it Atan penalty. The Atan-penalized least squares procedure is shown to consistently select the correct model and is asymptotically normal, provided the number of variables grows slower than the number of observations. The Atan procedure is efficiently implemented using an iteratively reweighted Lasso algorithm. Simulation results and data example show that the Atan procedure with BIC-type criterion performs very well in a variety of settings.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\S9S5Y87J\\Wang and Zhu - 2016 - Variable Selection and Parameter Estimation with t.pdf},
  journal = {Journal of Probability and Statistics},
  language = {en}
}

@article{watersAttentional2003,
  title = {Attentional {{Bias Predicts Outcome}} in {{Smoking Cessation}}},
  author = {Waters, Andrew J. and Shiffman, Saul and Sayette, Michael A. and Paty, Jean A. and Gwaltney, Chad J. and Balabanis, Mark H.},
  year = {2003},
  volume = {22},
  pages = {378--387},
  issn = {0278-6133},
  doi = {10.1037/0278-6133.22.4.378},
  abstract = {Most attempts to quit smoking end in failure, with many quitters relapsing in the first few days. Responses to smoking-related cues may precipitate relapse. A modified emotional Stroop task\textemdash{}which measures the extent to which smoking-related words disrupt performance on a reaction time (RT) task\textemdash{}was used to index the distracting effects of smoking-related cues. Smokers (N = 158) randomized to a high-dose nicotine patch (35 mg) or placebo patch completed the Stroop task on the 1st day of a quit attempt. Smokers using an active patch exhibited less attentional bias, making fewer errors on smoking-related words. Smokers who showed greater attentional bias (slowed RT on the first block of smoking words) were significantly more likely to lapse in the short-term, even when controlling for self-reported urges at the test session. Attentional bias measures may tap an important component of dependence.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\F8EKV3EH\\Waters et al. - 2003 - Attentional Bias Predicts Outcome in Smoking Cessa.pdf},
  journal = {Health psychology : official journal of the Division of Health Psychology, American Psychological Association},
  number = {4},
  pmcid = {PMC2244587},
  pmid = {12940394}
}

@article{wetzelsencompassing2010,
  title = {An Encompassing Prior Generalization of the {{Savage}}\textendash{{Dickey}} Density Ratio},
  author = {Wetzels, Ruud and Grasman, Raoul P. P. P. and Wagenmakers, Eric-Jan},
  year = {2010},
  volume = {54},
  pages = {2094--2102},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2010.03.016},
  abstract = {An encompassing prior (EP) approach to facilitate Bayesian model selection for nested models with inequality constraints has been previously proposed. In this approach, samples are drawn from the prior and posterior distributions of an encompassing model that contains an inequality restricted version as a special case. The Bayes factor in favor of the inequality restriction then simplifies to the ratio of the proportions of posterior and prior samples consistent with the inequality restriction. This formalism has been applied almost exclusively to models with inequality or ``about equality'' constraints. It is shown that the EP approach naturally extends to exact equality constraints by considering the ratio of the heights for the posterior and prior distributions at the point that is subject to test (i.e.,~the Savage\textendash{}Dickey density ratio). The EP approach generalizes the Savage\textendash{}Dickey ratio method, and can accommodate both inequality and exact equality constraints. The general EP approach is found to be a computationally efficient procedure to calculate Bayes factors for nested models. However, the EP approach to exact equality constraints is vulnerable to the Borel\textendash{}Kolmogorov paradox, the consequences of which warrant careful consideration.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\HWI5GC42\\Wetzels et al. - 2010 - An encompassing prior generalization of the Savage.pdf;C\:\\Users\\josue\\Zotero\\storage\\R6TUXZNK\\S0167947310001180.html},
  journal = {Computational Statistics \& Data Analysis},
  keywords = {Bayesian model selection,Borel–Kolmogorov paradox,Equality constraints,Hypothesis testing,Inequality constraints},
  number = {9}
}

@article{wherryUnderprediction1975,
  title = {Underprediction from {{Overfitting}}: 45 {{Years}} of {{Shrinkage1}}},
  shorttitle = {Underprediction from {{Overfitting}}},
  author = {Wherry, Robert J.},
  year = {1975},
  volume = {28},
  pages = {1--18},
  issn = {1744-6570},
  doi = {10.1111/j.1744-6570.1975.tb00387.x},
  file = {C\:\\Users\\josue\\Zotero\\storage\\IJT5BG7M\\Wherry - 1975 - Underprediction from Overfitting 45 Years of Shri.pdf;C\:\\Users\\josue\\Zotero\\storage\\IZ43P8PZ\\j.1744-6570.1975.tb00387.html},
  journal = {Personnel Psychology},
  language = {en},
  number = {1}
}

@article{williamsBack2019,
  title = {Back to the Basics: {{Rethinking}} Partial Correlation Network Methodology: {{Rethinking}} Network Methodology},
  shorttitle = {Back to the Basics},
  author = {Williams, Donald R. and Rast, Philippe},
  year = {2019},
  issn = {00071102},
  doi = {10.1111/bmsp.12173},
  file = {C\:\\Users\\josue\\Zotero\\storage\\729B587G\\Williams and Rast - 2019 - Back to the basics Rethinking partial correlation.pdf},
  journal = {British Journal of Mathematical and Statistical Psychology},
  language = {en}
}

@techreport{williamsBayesian2019,
  title = {Bayesian {{Multivariate Mixed}}-{{Effects Location Scale Modeling}} of {{Longitudinal Relations}} among {{Affective Traits}}, {{States}}, and {{Physical Activity}}},
  author = {Williams, Donald R. and Liu, Siwei and Martin, Stephen Ross and Rast, Philippe},
  year = {2019},
  doi = {10.31234/osf.io/4kfjp},
  abstract = {Intensive longitudinal studies and experience sampling methods are becoming more common in psychology. While they provide a unique opportunity to ask novel questions about withinperson processes relating to personality, there is a lack of methods specifically built to characterize the interplay between traits and states. We thus introduce a Bayesian multivariate mixed-effects location scale model (M-MELSM). The formulation can simultaneously model both personality traits (the location) and states (the scale) for multivariate data common to personality research. Variables can be included to predict either (or both) the traits and states, in addition to estimating random effects therein. This provides correlations between location and scale random effects, both across and within each outcome, which allows for characterizing relations between any number personality traits and the corresponding states. We take a fully Bayesian approach, not only to make estimation possible, but also because it provides the necessary information for use in psychological applications such as hypothesis testing. To illustrate the model we use data from 194 individuals that provided daily ratings of negative and positive affect, as well as their psychical activity in the form of step counts over 100 consecutive days. We describe the fitted model, where we emphasize, with visualization, the richness of information provided by the M-MELSM. We demonstrate Bayesian hypothesis testing for the correlations between the random effects. We conclude by discussing limitations of the MELSM in general and extensions to the M-MELSM specifically for personality research.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KXUSSLAC\\Williams et al. - 2019 - Bayesian Multivariate Mixed-Effects Location Scale.pdf},
  language = {en},
  type = {Preprint}
}

@article{williamsBayesian2019b,
  title = {A {{Bayesian}} Nonlinear Mixed-Effects Location Scale Model for Learning},
  author = {Williams, Donald R. and Zimprich, Daniel R. and Rast, Philippe},
  year = {2019},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01255-9},
  abstract = {We present a Bayesian nonlinear mixed-effects location scale model (NL-MELSM). The NL-MELSM allows for fitting nonlinear functions to the location, or individual means, and the scale, or within-person variance. Specifically, in the context of learning, this model allows the within-person variance to follow a nonlinear trajectory, where it can be determined whether variability reduces during learning. It incorporates a sub-model that can predict nonlinear parameters for both the location and scale. This specification estimates random effects for all nonlinear location and scale parameters that are drawn from a common multivariate distribution. This allows estimation of covariances among the random effects, within and across the location and the scale. These covariances offer new insights into the interplay between individual mean structures and intraindividual variability in nonlinear parameters. We take a fully Bayesian approach, not only for ease of estimation but also for inference because it provides the necessary and consistent information for use in psychological applications, such as model selection and hypothesis testing. To illustrate the model, we use data from 333 individuals, consisting of three age groups, who participated in five learning trials that assessed verbal memory. In an exploratory context, we demonstrate that fitting a nonlinear function to the within-person variance, and allowing for individual variation therein, improves predictive accuracy compared to customary modeling techniques (e.g., assuming constant variance). We conclude by discussing the usefulness, limitations, and future directions of the NL-MELSM.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\K2TE5L39\\Williams et al. - 2019 - A Bayesian nonlinear mixed-effects location scale .pdf},
  journal = {Behavior Research Methods},
  language = {en}
}

@techreport{williamsBayesian2019c,
  title = {Bayesian {{Hypothesis Testing}} for {{Gaussian Graphical Models}}:{{Conditional Independence}} and {{Order Constraints}}},
  shorttitle = {Bayesian {{Hypothesis Testing}} for {{Gaussian Graphical Models}}},
  author = {Williams, Donald Ray and Mulder, Joris},
  year = {2019},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/ypxd8},
  abstract = {Gaussian graphical models (GGM; partial correlation networks) have become increasingly popular in the social and behavioral sciences for studying conditional (in)dependencies between variables. In this work, we introduce exploratory and confirmatory Bayesian tests for partial correlations. For the former, we first extend the customary GGM formulation that focuses on conditional dependence to also consider the null hypothesis of conditional independence for each partial correlation. Here a novel testing strategy is introduced that can provide evidence for a null, negative, or positive effect. We then introduce a  test for hypotheses with order constraints on partial correlations. This allows for testing theoretical and clinical expectations in GGMs. The novel matrix\$-F\$ prior distribution is described that provides increased flexibility in specification compared to the Wishart prior. The methods are applied to PTSD symptoms. In several applications, we demonstrate how the exploratory and confirmatory approaches can work in tandem: hypotheses are formulated from an initial analysis and then tested in an independent dataset. The methodology is implemented in the R package BGGM.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\XKPSUHDZ\\Williams and Mulder - 2019 - Bayesian Hypothesis Testing for Gaussian Graphical.pdf},
  language = {en},
  type = {Preprint}
}

@article{williamsBetweenlitter2017,
  title = {Between-Litter Variation in Developmental Studies of Hormones and Behavior: {{Inflated}} False Positives and Diminished Power},
  shorttitle = {Between-Litter Variation in Developmental Studies of Hormones and Behavior},
  author = {Williams, Donald R. and Carlsson, Rickard and B{\"u}rkner, Paul-Christian},
  year = {2017},
  volume = {47},
  pages = {154--166},
  issn = {0091-3022},
  doi = {10.1016/j.yfrne.2017.08.003},
  abstract = {Developmental studies of hormones and behavior often include littermates\textemdash{}rodent siblings that share early-life experiences and genes. Due to between-litter variation (i.e., litter effects), the statistical assumption of independent observations is untenable. In two literatures\textemdash{}natural variation in maternal care and prenatal stress\textemdash{}entire litters are categorized based on maternal behavior or experimental condition. Here, we (1) review both literatures; (2) simulate false positive rates for commonly used statistical methods in each literature; and (3) characterize small sample performance of multilevel models (MLM) and generalized estimating equations (GEE). We found that the assumption of independence was routinely violated ({$>$}85\%), false positives ({$\alpha$}=0.05) exceeded nominal levels (up to 0.70), and power (1-{$\beta$}) rarely surpassed 0.80 (even for optimistic sample and effect sizes). Additionally, we show that MLMs and GEEs have adequate performance for common research designs. We discuss implications for the extant literature, the field of behavioral neuroendocrinology, and provide recommendations.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\334BZPKS\\Williams et al. - 2017 - Between-litter variation in developmental studies .pdf;C\:\\Users\\josue\\Zotero\\storage\\G3U8AZYL\\S0091302217300468.html},
  journal = {Frontiers in Neuroendocrinology},
  keywords = {Between-litter variation,False positives,Hormones and behavior,Litter effects,Maternal care,Power,Prenatal stress}
}

@article{williamsComparing2020,
  title = {Comparing {{Gaussian}} Graphical Models with the Posterior Predictive Distribution and {{Bayesian}} Model Selection},
  author = {Williams, Donald R. and Rast, Philippe and Pericchi, Luis R. and Mulder, Joris},
  year = {2020},
  issn = {1939-1463},
  doi = {10.1037/met0000254},
  abstract = {Gaussian graphical models are commonly used to characterize conditional (in)dependence structures (i.e., partial correlation networks) of psychological constructs. Recently attention has shifted from estimating single networks to those from various subpopulations. The focus is primarily to detect differences or demonstrate replicability. We introduce two novel Bayesian methods for comparing networks that explicitly address these aims. The first is based on the posterior predictive distribution, with a symmetric version of Kullback-Leibler divergence as the discrepancy measure, that tests differences between two (or more) multivariate normal distributions. The second approach makes use of Bayesian model comparison, with the Bayes factor, and allows for gaining evidence for invariant network structures. This overcomes limitations of current approaches in the literature that use classical hypothesis testing, where it is only possible to determine whether groups are significantly different from each other. With simulation we show the posterior predictive method is approximately calibrated under the null hypothesis ({$\alpha$} = .05) and has more power to detect differences than alternative approaches. We then examine the necessary sample sizes for detecting invariant network structures with Bayesian hypothesis testing, in addition to how this is influenced by the choice of prior distribution. The methods are applied to posttraumatic stress disorder symptoms that were measured in 4 groups. We end by summarizing our major contribution, that is proposing 2 novel methods for comparing Gaussian graphical models (GGMs), which extends beyond the social-behavioral sciences. The methods have been implemented in the R package BGGM. (PsycINFO Database Record (c) 2020 APA, all rights reserved).},
  file = {C\:\\Users\\josue\\Zotero\\storage\\J2VN66NG\\Williams et al. - 2020 - Comparing Gaussian graphical models with the poste.pdf},
  journal = {Psychological Methods},
  language = {eng},
  pmid = {32077709}
}

@techreport{williamsFineTooth2019,
  title = {A {{Fine}}-{{Tooth Comb}} for {{Measurement Reliability}}: {{Predicting Variance Components}} in {{Bayesian Hierarchical Models}}},
  author = {Williams, Donald R. and Martin, Stephen R., Martin and DeBolt, Michaela and Oakes, Lisa M. and Rast, Philippe},
  year = {2019},
  institution = {{PsyArXiv}},
  file = {C\:\\Users\\josue\\Zotero\\storage\\NDJYXBQA\\iccier_paper (1).pdf},
  type = {Preprint}
}

@techreport{williamsLearning2020,
  title = {Learning to {{Live}} with {{Sampling Variability}}: {{Expected Replicability}} in {{Partial Correlation Networks}}},
  shorttitle = {Learning to {{Live}} with {{Sampling Variability}}},
  author = {Williams, Donald Ray},
  year = {2020},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/fb4sa},
  abstract = {The topic of replicability has recently captivated the emerging field of network psychometrics. Although methodological practice (e.g., p-hacking) has been identified as a root cause of unreliable research findings in psychological science, the statistical model itself has come under attack in the partial correlation network literature. In a motivating example, I first describe how sampling variability inherent to partial correlations can merely give the appearance of unreliability. For example, when going from zero-order to partial correlations there is necessarily more sampling variability that translates into reduced statistical power. I then introduce novel methodology for deriving expected network replicability. This analytic solution can be used with Pearson, Spearman, and polychoric partial correlations. I employ the method to highlight an additional source of sampling variability, that is, when going from continuous to ordinal data with few categories: in networks with 20 variables (N = 500) replicability can exceed 50\% for continuous data but this decreases to less than 25\% for ordinal data! Additionally, I propose using the smallest edge size of interest to achieve a desired level of replicability in network models. I end with recommendations that include the importance of the network literature repositioning itself with gold-standard approaches for assessing replication (e.g., by using methods with defined error rates). I have implemented the method for computing expected network replicability in the R package GGMnonreg.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\GAFPRXL5\\Williams - 2020 - Learning to Live with Sampling Variability Expect.pdf},
  language = {en},
  type = {Preprint}
}

@article{williamsNonregularized2019,
  title = {On {{Nonregularized Estimation}} of {{Psychological Networks}}},
  author = {Williams, Donald R. and Rhemtulla, Mijke and Wysocki, Anna C. and Rast, Philippe},
  year = {2019},
  volume = {54},
  pages = {719--750},
  issn = {0027-3171},
  doi = {10.1080/00273171.2019.1575716},
  abstract = {An important goal for psychological science is developing methods to characterize relationships between variables. Customary approaches use structural equation models to connect latent factors to a number of observed measurements, or test causal hypotheses between observed variables. More recently, regularized partial correlation networks have been proposed as an alternative approach for characterizing relationships among variables through off-diagonal elements in the precision matrix. While the graphical Lasso (glasso) has emerged as the default network estimation method, it was optimized in fields outside of psychology with very different needs, such as high dimensional data where the number of variables (p) exceeds the number of observations (n). In this article, we describe the glasso method in the context of the fields where it was developed, and then we demonstrate that the advantages of regularization diminish in settings where psychological networks are often fitted (p{$\ll$}n). We first show that improved properties of the precision matrix, such as eigenvalue estimation, and predictive accuracy with cross-validation are not always appreciable. We then introduce nonregularized methods based on multiple regression and a nonparametric bootstrap strategy, after which we characterize performance with extensive simulations. Our results demonstrate that the nonregularized methods can be used to reduce the false-positive rate, compared to glasso, and they appear to provide consistent performance across sparsity levels, sample composition (p/n), and partial correlation size. We end by reviewing recent findings in the statistics literature that suggest alternative methods often have superior performance than glasso, as well as suggesting areas for future research in psychology. The nonregularized methods have been implemented in the R package GGMnonreg.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\AR5YYTVF\\Williams et al. - 2019 - On Nonregularized Estimation of Psychological Netw.pdf;C\:\\Users\\josue\\Zotero\\storage\\64YMS7SC\\00273171.2019.html},
  journal = {Multivariate Behavioral Research},
  keywords = {<img src="/na101/home/literatum/publisher/tandf/journals/content/hmbr20/2019/hmbr20.v054.i05/00273171.2019.1575716/20190910/images/hmbr_a_1575716_ilm0001.gif" alt="" />ℓ1-regularization,model selection,multiple regression,Network models,nonregularized,partial correlation},
  number = {5},
  pmid = {30957629}
}

@techreport{williamsPutting2019,
  title = {Putting the {{Individual}} into {{Reliability}}: {{Bayesian Testing}} of {{Homogeneous Within}}-{{Person Variance}} in {{Hierarchical Models}}},
  shorttitle = {Putting the {{Individual}} into {{Reliability}}},
  author = {Williams, Donald R. and Martin, Stephen Ross and Rast, Philippe},
  year = {2019},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/hpq7w},
  abstract = {Measurement reliability is a fundamental concept in psychology. It is traditionally considered a stable property of a questionnaire, measurement device, or experimental task. Although intraclass correlation coefficients (ICC) are often used to assess reliability in repeated measure designs, their descriptive nature depends upon the assumption of a commonwithin-person variance.This work focuses on the presumption that each individual is adequately described by the average within-person variance in hierarchical models. And thus whether reliability generalizes to the individual level, which leads directly into the notion of individually varying ICCs. In particular, we introduce a novel approach, using the Bayes factor, wherein a researcher can directly test for homogeneous within-person variance in hierarchical models. Additionally, we introduce a membership model that allows for classifying which (and how many) individuals belong to the common variance model. The utility of our methodology is demonstrated on cognitive inhibition tasks. We find that heterogeneous within-person variance is a defining feature of these tasks, and in one case, the ratio between the largest to smallest within-person variance exceeded 20. This translates into a 10 fold difference in person-specific reliability! We also find that few individuals belong to the common variance model, and thus traditional reliability indices are potentially masking important individual variation. We discuss the implications of our findings and possible future directions. The methods are implemented in the R package vICC.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\8GHTNG9R\\Williams et al. - 2019 - Putting the Individual into Reliability Bayesian .pdf},
  type = {Preprint}
}

@techreport{williamsSurface2019,
  title = {Beneath the {{Surface}}: {{Unearthing Within}}-{{Person Variability}} and {{Mean Relations}} with {{Bayesian Mixed Models}}},
  shorttitle = {Beneath the {{Surface}}},
  author = {Williams, Donald Ray and Rouder, Jeffrey and Rast, Philippe},
  year = {2019},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/gwatq},
  abstract = {Mixed-effects models are becoming common in psychological science. Although they have many desirable features, there is still untapped potential . It is customary to view homogeneous variance as an assumption to satisfy. We argue to move beyond that perspective, and to view modeling within-person variance (``noise'') as an opportunity to gain a richer understanding of psychological processes. The technique to do so is based on the mixed-effects location scale model that can simultaneously estimate mixed-effects sub-models to both the mean (location) and within-person variance (scale). We develop a framework that goes beyond assessing the sub-models in isolation of one another, and provide a novel testing strategy for the correlations between individual difference parameters across the mean and within-person variance sub-models with the Bayes factor. We first present a motivating example, which makes clear our testing strategy for mean\textendash{}variance relations. We then apply the method to reaction times gathered from two cognitive inhibition tasks. We find there are more individual differences in the within-person variance than the mean structure, as well as a complex web of structural mean\textendash{}variance relations in the distribution of random effects. This stands in contrast to the dominant view of within-person variance\textendash{}i.e., measurement ``error'' or ``noise.'' The results also point towards paradoxical within-person, as opposed to between-person, effects: several people had slower and less variable incongruent responses which contradicts the typical pattern, wherein larger means are expected to be more variable. We conclude with future directions that span from methodological to theoretical inquires that can be answered with the presented methodology.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\8MITGXI5\\Williams et al. - 2019 - Beneath the Surface Unearthing Within-Person Vari.pdf},
  language = {en},
  type = {Preprint}
}

@techreport{williamsWhy2020,
  title = {Why {{Overfitting}} Is {{Not}} ({{Usually}}) a {{Problem}} in {{Partial Correlation Networks}}},
  author = {Williams, Donald Ray and Rodriguez, Josue E.},
  year = {2020},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/8pr9b},
  abstract = {Network psychometrics is undergoing a time of methodological reflection. In part, this was spurred by the revelation that l1-regularization does not reduce spurious associations in partial correlation networks. In this work, we address another motivation for the widespread use of regularized estimation: the thought that it is needed to mitigate overfitting. We first clarify important aspects of overfitting and the bias-variance tradeoff that are especially relevant for the network literature, where the number of nodes or items in a psychometric scale are not largecompared to the number of observations (i.e., a low p/n ratio). This revealed that bias and especially variance are most problematic in p=n ratios rarely encountered. We then introduce a nonregularized method, based on classical hypothesis testing, that fulfills two desiderata: (1) reducing or controlling the false positives rate and (2) quelling concerns of overfitting by providing accurate predictions. These were the primary motivations for initially adopting the graphical lasso (glasso). In several simulation studies, our nonregularized method provided more than competitive predictive performance, and, in many cases, outperformed glasso. Itappears to be nonregularized, as opposed to regularized estimation, that best satisfies these desiderata. We then provide insights into using our methodology. Here we discuss the multiple comparisons problem in relation to prediction: stringent alpha levels, resulting in a sparse network, can deteriorate predictive accuracy. We end by emphasizing key advantages of our approach that make it ideal for both inference and prediction in network analysis.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\FWVFVJ9E\\Williams and Rodriguez - 2020 - Why Overfitting is Not (Usually) a Problem in Part.pdf},
  type = {Preprint}
}

@article{wolsieferModeling2017,
  title = {Modeling Stimulus Variation in Three Common Implicit Attitude Tasks},
  author = {Wolsiefer, Katie and Westfall, Jacob and Judd, Charles M.},
  year = {2017},
  volume = {49},
  pages = {1193--1209},
  issn = {1554-3528},
  doi = {10.3758/s13428-016-0779-0},
  abstract = {We explored the consequences of ignoring the sampling variation due to stimuli in the domain of implicit attitudes. A large literature in psycholinguistics has examined the statistical treatment of random stimulus materials, but the recommendations from this literature have not been applied to the social psychological literature on implicit attitudes. This is partly because of inherent complications in applying crossed random-effect models to some of the most common implicit attitude tasks, and partly because no work to date has demonstrated that random stimulus variation is in fact consequential in implicit attitude measurement. We addressed this problem by laying out statistically appropriate and practically feasible crossed random-effect models for three of the most commonly used implicit attitude measures\textemdash{}the Implicit Association Test, affect misattribution procedure, and evaluative priming task\textemdash{}and then applying these models to large datasets (average N = 3,206) that assess participants' implicit attitudes toward race, politics, and self-esteem. We showed that the test statistics from the traditional analyses are substantially (about 60 \%) inflated relative to the more-appropriate analyses that incorporate stimulus variation. Because all three tasks used the same stimulus words and faces, we could also meaningfully compare the relative contributions of stimulus variation across the tasks. In an appendix, we give syntax in R, SAS, and SPSS for fitting the recommended crossed random-effects models to data from all three tasks, as well as instructions on how to structure the data file.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\RQHTKMJX\\Wolsiefer et al. - 2017 - Modeling stimulus variation in three common implic.pdf},
  journal = {Behavior Research Methods},
  keywords = {Implicit attitudes,Mixed models,Stimulus sampling},
  language = {en},
  number = {4}
}

@article{worksPower1987,
  title = {Power and {{Centrality}}: {{A Family}} of {{Measures}}},
  author = {{work(s):}, Phillip Bonacich Reviewed},
  year = {1987},
  volume = {92},
  pages = {1170--1182},
  file = {C\:\\Users\\josue\\Zotero\\storage\\M38NAI3R\\work(s) - 1987 - Power and Centrality A Family of Measures.pdf},
  journal = {American Journal of Sociology},
  language = {en},
  number = {5}
}

@article{wysockiPenalty2019,
  title = {On {{Penalty Parameter Selection}} for {{Estimating Network Models}}},
  author = {Wysocki, Anna C. and Rhemtulla, Mijke},
  year = {2019},
  volume = {0},
  pages = {1--15},
  publisher = {{Routledge}},
  issn = {0027-3171},
  doi = {10.1080/00273171.2019.1672516},
  abstract = {Network models are gaining popularity as a way to estimate direct effects among psychological variables and investigate the structure of constructs. A key feature of network estimation is determining which edges are likely to be non-zero. In psychology, this is commonly achieved through the graphical lasso regularization method that estimates a precision matrix of Gaussian variables using an {$\mathscr{l}$}1-penalty to push small values to zero. A tuning parameter, {$\lambda$}, controls the sparsity of the network. There are many methods to select {$\lambda$}, which can lead to vastly different graphs. The most common approach in psychological network applications is to minimize the extended Bayesian information criterion, but the consistency of this method for model selection has primarily been examined in high dimensional settings (i.e., n {$<$} p) that are uncommon in psychology. Further, there is some evidence that alternative selection methods may have superior performance. Here, using simulation, we compare four different methods for selecting {$\lambda$}, including the stability approach to regularization selection (StARS), K-fold cross-validation, the rotation information criterion (RIC), and the extended Bayesian information criterion (EBIC). Our results demonstrate that penalty parameter selection should be made based on data characteristics and the inferential goal (e.g., to increase sensitivity versus to avoid false positives). We end with recommendations for selecting the penalty parameter when using the graphical lasso.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\KR7QVFID\\Wysocki and Rhemtulla - 2019 - On Penalty Parameter Selection for Estimating Netw.pdf;C\:\\Users\\josue\\Zotero\\storage\\BM576DGU\\00273171.2019.html},
  journal = {Multivariate Behavioral Research},
  keywords = {Network analysis,partial correlation networks,penalty selection,regularization,simulation study},
  note = {\_eprint: https://doi.org/10.1080/00273171.2019.1672516},
  number = {0},
  pmid = {31672065}
}

@article{yarkoniChoosing2017,
  title = {Choosing {{Prediction Over Explanation}} in {{Psychology}}: {{Lessons From Machine Learning}}},
  shorttitle = {Choosing {{Prediction Over Explanation}} in {{Psychology}}},
  author = {Yarkoni, Tal and Westfall, Jacob},
  year = {2017},
  volume = {12},
  pages = {1100--1122},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691617693393},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology's near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\P49JXYBU\\Yarkoni and Westfall - 2017 - Choosing Prediction Over Explanation in Psychology.pdf},
  journal = {Perspectives on Psychological Science},
  language = {en},
  number = {6}
}

@techreport{yarkoniGeneralizability2019,
  title = {The {{Generalizability Crisis}}},
  author = {Yarkoni, Tal},
  year = {2019},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/jqw35},
  abstract = {Most theories and hypotheses in psychology are verbal in nature, yet their evaluation overwhelmingly relies on inferential statistical procedures. The validity of the move from qualitative to quantitative analysis depends on the verbal and statistical expressions of a hypothesis being closely aligned\textemdash{}that is, that the two must refer to roughly the same set of hypothetical observations. Here I argue that most inferential statistical tests in psychology fail to meet this basic condition. I demonstrate how foundational assumptions of the "random effects" model used pervasively in psychology impose far stronger constraints on the generalizability of results than most researchers appreciate. Ignoring these constraints dramatically inflates false positive rates and routinely leads researchers to draw sweeping verbal generalizations that lack any meaningful connection to the statistical quantities they are putatively based on. I argue that failure to consider generalizability from a statistical perspective lies at the root of many of psychology's ongoing problems (e.g., the replication crisis), and conclude with a discussion of several potential avenues for improvement.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\ZFWZAYGC\\Yarkoni - 2019 - The Generalizability Crisis.pdf},
  language = {en},
  type = {Preprint}
}

@article{yuleTheory1897,
  title = {On the {{Theory}} of {{Correlation}}},
  author = {Yule, G. Udny},
  year = {1897},
  volume = {60},
  pages = {812--854},
  publisher = {{[Wiley, Royal Statistical Society]}},
  issn = {0952-8385},
  doi = {10.2307/2979746},
  file = {C\:\\Users\\josue\\Zotero\\storage\\BW77IRIG\\Yule - 1897 - On the Theory of Correlation.pdf},
  journal = {Journal of the Royal Statistical Society},
  number = {4}
}

@article{zacharPopper2015,
  title = {Popper, {{Meehl}}, and {{Progress}}: {{The Evolving Concept}} of {{Risky Test}} in the {{Science}} of {{Psychopathology}}},
  shorttitle = {Popper, {{Meehl}}, and {{Progress}}},
  author = {Zachar, Peter},
  year = {2015},
  volume = {26},
  pages = {279--285},
  issn = {1047-840X, 1532-7965},
  doi = {10.1080/1047840X.2015.1037819},
  file = {C\:\\Users\\josue\\Zotero\\storage\\YACE664Q\\Zachar - 2015 - Popper, Meehl, and Progress The Evolving Concept .pdf},
  journal = {Psychological Inquiry},
  language = {en},
  number = {3}
}

@article{zandscholtenreanalysis2009,
  title = {A Reanalysis of {{Lord}}'s Statistical Treatment of Football Numbers},
  author = {Zand Scholten, Annemarie and Borsboom, Denny},
  year = {2009},
  volume = {53},
  pages = {69--75},
  issn = {00222496},
  doi = {10.1016/j.jmp.2009.01.002},
  abstract = {Stevens' theory of admissible statistics [Stevens, S. S. (1946). On the theory of scales of measurement. Science, 103, 677680] states that measurement levels should guide the choice of statistical test, such that the truth value of statements based on a statistical analysis remains invariant under admissible transformations of the data. Lord [Lord, F. M. (1953). On the statistical treatment of football numbers. American Psychologist, 8, 750\textendash{}751] challenged this theory. In a thought experiment, a parametric test is performed on football numbers (identifying players: a nominal representation) to decide whether a sample from the machine issuing these numbers should be considered non-random. This is an apparently illegal test, since its outcomes are not invariant under admissible transformations for the nominal measurement level. Nevertheless, it results in a sensible conclusion: the number-issuing machine was tampered with. In the ensuing measurement-statistics debate Lord's contribution has been influential, but has also led to much confusion. The present aim is to show that the thought experiment contains a serious flaw. First it is shown that the implicit assumption that the numbers are nominal is false. This disqualifies Lord's argument as a valid counterexample to Stevens' dictum. Second, it is argued that the football numbers do not represent just the nominal property of non-identity of the players; they also represent the amount of bias in the machine. It is a question about this property \textendash{} not a property that relates to the identity of the football players \textendash{} that the statistical test is concerned with. Therefore, only this property is relevant to Lord's argument. We argue that the level of bias in the machine, indicated by the population mean, conforms to a bisymmetric structure, which means that it lies on an interval scale. In this light, Lord's thought experiment \textendash{} interpreted by many as a problematic counterexample to Stevens' theory of admissible statistics \textendash{} conforms perfectly to Stevens' dictum.},
  file = {C\:\\Users\\josue\\Zotero\\storage\\8FSR5U7N\\Zand Scholten and Borsboom - 2009 - A reanalysis of Lord’s statistical treatment of fo.pdf},
  journal = {Journal of Mathematical Psychology},
  language = {en},
  number = {2}
}

@article{zimmermanResolving2015,
  title = {Resolving the {{Issue}} of {{How Reliability}} Is {{Related}} to {{Statistical Power}}: {{Adhering}} to {{Mathematical Definitions}}},
  shorttitle = {Resolving the {{Issue}} of {{How Reliability}} Is {{Related}} to {{Statistical Power}}},
  author = {Zimmerman, Donald W. and Zumbo, Bruno D.},
  year = {2015},
  volume = {14},
  pages = {9--26},
  issn = {1538-9472},
  doi = {10.22237/jmasm/1446350640},
  file = {C\:\\Users\\josue\\Zotero\\storage\\VGYLDSUN\\Zimmerman and Zumbo - 2015 - Resolving the Issue of How Reliability is Related .pdf},
  journal = {Journal of Modern Applied Statistical Methods},
  language = {en},
  number = {2}
}


